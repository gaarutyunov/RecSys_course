{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6238b8d",
   "metadata": {},
   "source": [
    "# Последовательные модели в Recsys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac9a92",
   "metadata": {},
   "source": [
    "## I. Зачем мы хотим использовать факт последовательности ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85838aea",
   "metadata": {},
   "source": [
    "\n",
    "Утверждения\n",
    "\n",
    "- Зачастую интеракции пользователей можно отсортировать по времени\n",
    "\n",
    "\n",
    "- Если между интеракциями прошло МАЛО времени, они могут быть связаны некоторой логикой взаимодействия\n",
    "\n",
    "\n",
    "- Если пользователь взаимодйствовал с айтемом давно, это может мало влиять на его текущее поведение\n",
    "\n",
    "\n",
    "- Если мы будем учитывать порядок интеракций, мы сможем лучше понимать динамику интересов пользователей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ab166",
   "metadata": {},
   "source": [
    "<b>Вопросы обсудить:</b>\n",
    "\n",
    "1) Вы недавно посмотрели фильм X, и потом после этого решили посмотреть фильм Y. Придумайте пример таких фильмов X, Y?\n",
    "\n",
    "\n",
    "2) Вы только что прослушали три подряд песни X1, X2, X3, и потом решили найти и прослушать песню X4. В каком случае так может происходить?\n",
    "\n",
    "\n",
    "3) Представьте, что вы рекомендуете человеку магазины и видите человека с такой упорядоченной историей:\n",
    "    - зоомагазин, супермаркет, метрополитен, зоомагазин, кофейня, супермаркет, развлекательный сервис\n",
    "   Порекомендуете ли совершить следующую покупку в зоомагазине?\n",
    "   \n",
    "4) Представьте, что вы рекомендуете человеку магазины и видите человека с такой упорядоченной историей:\n",
    "    - зоомагазин, супермаркет, метрополитен, зоомагазин, кофейня, супермаркет, развлекательный сервис, зоомагазин\n",
    "   Порекомендуете ли теперь совершить следующую покупку в зоомагазине?\n",
    "   \n",
    "   \n",
    "5) Представим теперь, что у наша последовательность не отсортирована и мы просто знаем, что человек покупал в магазинах\n",
    "    - зоомагазин, супермаркет, кофейня, развлекательный сервис\n",
    "    \n",
    "   Пора ли ему рекомендовать зоомагазин теперь?\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7677dc5",
   "metadata": {},
   "source": [
    "<b>Главый вывод:</b> Учет последовательности интеракций может добавить больше информации о текущих интересах пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4646a0a",
   "metadata": {},
   "source": [
    "## II. Попробуем что-то простое"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5525ff6a",
   "metadata": {},
   "source": [
    "Возьмем данные из ods соревнования от МТС по рекомендациям\n",
    "\n",
    "https://ods.ai/competitions/competition-recsys-21/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a614495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371e76d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../../recsys_course.zip\r\n",
      "caution: filename not matched:  -\r\n"
     ]
    }
   ],
   "source": [
    "!unzip ../../recsys_course.zip -d data/. -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c046e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>last_watch_dt</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864613</td>\n",
       "      <td>7638</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>14483</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964868</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>6725</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id last_watch_dt  total_dur  watched_pct\n",
       "0   176549     9506    2021-05-11       4250         72.0\n",
       "1   699317     1659    2021-05-29       8317        100.0\n",
       "2   656683     7107    2021-05-09         10          0.0\n",
       "3   864613     7638    2021-07-05      14483        100.0\n",
       "4   964868     9506    2021-04-30       6725        100.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/interactions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "085384d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = pd.to_datetime(df.last_watch_dt).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38573dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-08-22'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.last_watch_dt.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275de8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users which are included both in train/test data:  48728\n"
     ]
    }
   ],
   "source": [
    "train_df = df.loc[(df.last_watch_dt < '2021-08-08')].copy()\n",
    "valid_df = df.loc[(df.last_watch_dt >= '2021-08-08')&(df.last_watch_dt < '2021-08-15')].copy()\n",
    "test_df = df.loc[(df.last_watch_dt >= '2021-08-15')].copy()\n",
    "\n",
    "train_users = train_df.user_id.unique()\n",
    "valid_users = valid_df.user_id.unique()\n",
    "test_users = test_df.user_id.unique()\n",
    "\n",
    "\n",
    "all_included = np.intersect1d(np.intersect1d(valid_users, train_users), test_users)\n",
    "\n",
    "print('number of users which are included both in train/test data: ', all_included.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db68e61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dff84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcd0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 5000\n",
    "\n",
    "all_included = np.random.choice(all_included, size=n_users, replace=False)\n",
    "\n",
    "train_df = train_df.loc[train_df.user_id.isin(all_included)].copy()\n",
    "valid_df = valid_df.loc[valid_df.user_id.isin(all_included)].copy()\n",
    "test_df = test_df.loc[test_df.user_id.isin(all_included)].copy()\n",
    "\n",
    "assert train_df.last_watch_dt.max() < valid_df.last_watch_dt.min()\n",
    "assert valid_df.last_watch_dt.max() < test_df.last_watch_dt.min()\n",
    "assert train_df.user_id.nunique() == n_users\n",
    "assert valid_df.user_id.nunique() == n_users\n",
    "assert test_df.user_id.nunique() == n_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc9fa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>train_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>[(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>[(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576</td>\n",
       "      <td>[(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>655</td>\n",
       "      <td>[(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>[(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 train_interactions\n",
       "0       30  [(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...\n",
       "1      229  [(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...\n",
       "2      576  [(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...\n",
       "3      655  [(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...\n",
       "4      733  [(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grouped = train_df.groupby('user_id').apply(\n",
    "    lambda x: [(t1, t2, t3) for t1, t2, t3 in sorted(zip(x.item_id, \n",
    "                                                 x.last_watch_dt,\n",
    "                                                 x.weekday), key=lambda x: x[1])]\n",
    ").reset_index()\n",
    "train_grouped.rename({0:'train_interactions'}, axis=1, inplace=True)\n",
    "\n",
    "valid_grouped = valid_df.groupby('user_id').apply(\n",
    "    lambda x: [(t1, t2, t3) for t1, t2, t3 in sorted(zip(x.item_id,\n",
    "                                                         x.last_watch_dt,\n",
    "                                                         x.weekday), key=lambda x: x[1])]\n",
    ").reset_index()\n",
    "valid_grouped.rename({0:'valid_interactions'}, axis=1, inplace=True)\n",
    "\n",
    "test_grouped = test_df.groupby('user_id').apply(\n",
    "    lambda x: [(t1, t2, t3) for t1, t2, t3 in sorted(zip(x.item_id,\n",
    "                                                         x.last_watch_dt,\n",
    "                                                         x.weekday), key=lambda x: x[1])]\n",
    ").reset_index()\n",
    "test_grouped.rename({0:'test_interactions'}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "train_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df2d2845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>train_interactions</th>\n",
       "      <th>valid_interactions</th>\n",
       "      <th>test_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>[(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...</td>\n",
       "      <td>[(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...</td>\n",
       "      <td>[(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>[(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...</td>\n",
       "      <td>[(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]</td>\n",
       "      <td>[(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576</td>\n",
       "      <td>[(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...</td>\n",
       "      <td>[(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...</td>\n",
       "      <td>[(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>655</td>\n",
       "      <td>[(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...</td>\n",
       "      <td>[(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...</td>\n",
       "      <td>[(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>[(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...</td>\n",
       "      <td>[(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...</td>\n",
       "      <td>[(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 train_interactions  \\\n",
       "0       30  [(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...   \n",
       "1      229  [(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...   \n",
       "2      576  [(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...   \n",
       "3      655  [(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...   \n",
       "4      733  [(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...   \n",
       "\n",
       "                                  valid_interactions  \\\n",
       "0  [(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...   \n",
       "1   [(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]   \n",
       "2  [(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...   \n",
       "3  [(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...   \n",
       "4  [(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...   \n",
       "\n",
       "                                   test_interactions  \n",
       "0  [(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...  \n",
       "1    [(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]  \n",
       "2  [(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...  \n",
       "3  [(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...  \n",
       "4  [(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = train_grouped.merge(valid_grouped).merge(test_grouped)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320bc46",
   "metadata": {},
   "source": [
    "с этим уже можно работать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7659bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_metric(gt_items, predicted):\n",
    "    \n",
    "    at = len(predicted)\n",
    "    relevance = np.array([1 if x in predicted else 0 for x in gt_items])\n",
    "    # DCG uses the relevance of the recommended items\n",
    "    rank_dcg = dcg(relevance)\n",
    "\n",
    "    if rank_dcg == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    # IDCG has all relevances to 1 (or the values provided), up to the number of items in the test set that can fit in the list length\n",
    "    ideal_dcg = dcg(np.sort(relevance)[::-1][:at])\n",
    "\n",
    "    if ideal_dcg == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    ndcg_ = rank_dcg / ideal_dcg\n",
    "\n",
    "    return ndcg_\n",
    "\n",
    "\n",
    "def dcg(scores):\n",
    "    return np.sum(np.divide(np.power(2, scores) - 1, np.log2(np.arange(scores.shape[0], dtype=np.float64) + 2)),\n",
    "                  dtype=np.float64)\n",
    "\n",
    "\n",
    "def recall_metric(gt_items, predicted):\n",
    "    \n",
    "    n_gt = len(gt_items)\n",
    "    intersection = len(set(gt_items).intersection(set(predicted)))\n",
    "    return intersection / n_gt\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_recommender(df, model_preds, gt_col='test_interactions', topn=10):\n",
    "    \n",
    "    metric_values = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        gt_items = [x[0] for x in row[gt_col]]\n",
    "        metric_values.append((ndcg_metric(gt_items, row[model_preds]),\n",
    "                              recall_metric(gt_items, row[model_preds])))\n",
    "        \n",
    "    return {'ndcg':np.mean([x[0] for x in metric_values]),\n",
    "            'recall':np.mean([x[1] for x in metric_values])}\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ebbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df, model_preds, gt_col='test_interactions', topn=10):\n",
    "    \n",
    "    metric_values = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        gt_items = [x[0] for x in row[gt_col]]\n",
    "        metric_values.append((ndcg_metric(gt_items, row[model_preds]),\n",
    "                              recall_metric(gt_items, row[model_preds])))\n",
    "        \n",
    "    return metric_values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ccd46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>train_interactions</th>\n",
       "      <th>valid_interactions</th>\n",
       "      <th>test_interactions</th>\n",
       "      <th>toppopular_recs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>[(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...</td>\n",
       "      <td>[(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...</td>\n",
       "      <td>[(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...</td>\n",
       "      <td>[9728, 10440, 15297, 13865, 3734, 4151, 4880, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>[(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...</td>\n",
       "      <td>[(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]</td>\n",
       "      <td>[(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]</td>\n",
       "      <td>[9728, 10440, 15297, 13865, 3734, 4151, 4880, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576</td>\n",
       "      <td>[(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...</td>\n",
       "      <td>[(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...</td>\n",
       "      <td>[(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...</td>\n",
       "      <td>[9728, 10440, 15297, 13865, 3734, 4151, 4880, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>655</td>\n",
       "      <td>[(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...</td>\n",
       "      <td>[(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...</td>\n",
       "      <td>[(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...</td>\n",
       "      <td>[9728, 10440, 15297, 13865, 3734, 4151, 4880, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>[(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...</td>\n",
       "      <td>[(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...</td>\n",
       "      <td>[(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...</td>\n",
       "      <td>[9728, 10440, 15297, 13865, 3734, 4151, 4880, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 train_interactions  \\\n",
       "0       30  [(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...   \n",
       "1      229  [(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...   \n",
       "2      576  [(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...   \n",
       "3      655  [(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...   \n",
       "4      733  [(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...   \n",
       "\n",
       "                                  valid_interactions  \\\n",
       "0  [(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...   \n",
       "1   [(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]   \n",
       "2  [(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...   \n",
       "3  [(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...   \n",
       "4  [(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...   \n",
       "\n",
       "                                   test_interactions  \\\n",
       "0  [(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...   \n",
       "1    [(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]   \n",
       "2  [(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...   \n",
       "3  [(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...   \n",
       "4  [(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...   \n",
       "\n",
       "                                     toppopular_recs  \n",
       "0  [9728, 10440, 15297, 13865, 3734, 4151, 4880, ...  \n",
       "1  [9728, 10440, 15297, 13865, 3734, 4151, 4880, ...  \n",
       "2  [9728, 10440, 15297, 13865, 3734, 4151, 4880, ...  \n",
       "3  [9728, 10440, 15297, 13865, 3734, 4151, 4880, ...  \n",
       "4  [9728, 10440, 15297, 13865, 3734, 4151, 4880, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TopPopular:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.trained = False\n",
    "    \n",
    "    def fit(self, df, col='train_interactions'):\n",
    "        \n",
    "        counts = {}\n",
    "        for _, row in df.iterrows():\n",
    "            for item, _, _ in row[col]:\n",
    "                if item in counts:\n",
    "                    counts[item] += 1\n",
    "                else:\n",
    "                    counts[item] = 1\n",
    "                    \n",
    "        counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        self.recommenations = [x[0] for x in counts]\n",
    "        self.trained = True\n",
    "        \n",
    "    def predict(self, df, topn=10)  -> List[np.ndarray]:\n",
    "        \n",
    "        assert self.trained\n",
    "        return [self.recommenations[:topn]]*len(df)\n",
    "\n",
    "    \n",
    "toppop = TopPopular()\n",
    "toppop.fit(joined)\n",
    "joined['toppopular_recs'] = toppop.predict(joined)\n",
    "joined.head()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "408a39e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg': 0.15494205816767317, 'recall': 0.09707992750089679}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_recommender(joined, model_preds='toppopular_recs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d9b724",
   "metadata": {},
   "source": [
    "В нашем алгоритме есть маленький недостаток: какой?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40cd46a2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e44fa2",
   "metadata": {},
   "source": [
    "Он может порекомендовать то, что уже было в истории. В recsys всегда стоит сразу смотреть на то, есть ли дубли в датасете по user-item парам. Если нет, то надо удалять в рекомендациях. Если есть, то скорее всего оставлять\n",
    "\n",
    "Поэтому отредактируем predict метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d77a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a75b249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>train_interactions</th>\n",
       "      <th>valid_interactions</th>\n",
       "      <th>test_interactions</th>\n",
       "      <th>toppopular_recs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>[(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...</td>\n",
       "      <td>[(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...</td>\n",
       "      <td>[(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...</td>\n",
       "      <td>[10440, 15297, 13865, 3734, 4151, 4880, 2657, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>[(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...</td>\n",
       "      <td>[(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]</td>\n",
       "      <td>[(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4880, 2657, 142, 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576</td>\n",
       "      <td>[(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...</td>\n",
       "      <td>[(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...</td>\n",
       "      <td>[(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...</td>\n",
       "      <td>[10440, 15297, 3734, 4151, 4880, 142, 9996, 44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>655</td>\n",
       "      <td>[(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...</td>\n",
       "      <td>[(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...</td>\n",
       "      <td>[(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>[(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...</td>\n",
       "      <td>[(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...</td>\n",
       "      <td>[(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 train_interactions  \\\n",
       "0       30  [(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...   \n",
       "1      229  [(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...   \n",
       "2      576  [(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...   \n",
       "3      655  [(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...   \n",
       "4      733  [(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...   \n",
       "\n",
       "                                  valid_interactions  \\\n",
       "0  [(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...   \n",
       "1   [(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]   \n",
       "2  [(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...   \n",
       "3  [(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...   \n",
       "4  [(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...   \n",
       "\n",
       "                                   test_interactions  \\\n",
       "0  [(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...   \n",
       "1    [(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]   \n",
       "2  [(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...   \n",
       "3  [(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...   \n",
       "4  [(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...   \n",
       "\n",
       "                                     toppopular_recs  \n",
       "0  [10440, 15297, 13865, 3734, 4151, 4880, 2657, ...  \n",
       "1  [9728, 10440, 13865, 3734, 4880, 2657, 142, 86...  \n",
       "2  [10440, 15297, 3734, 4151, 4880, 142, 9996, 44...  \n",
       "3  [9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...  \n",
       "4  [9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ModifiedTopPopular(TopPopular):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.trained = False\n",
    "\n",
    "        \n",
    "    def predict(self, df, topn=10)  -> List[np.ndarray]:\n",
    "        \n",
    "        assert self.trained\n",
    "        \n",
    "        all_recs = []\n",
    "        \n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            \n",
    "            user_recs = []\n",
    "            \n",
    "            user_interactions = [x[0] for x in row['train_interactions']]\n",
    "            user_interactions += [x[0] for x in row['valid_interactions']]\n",
    "            \n",
    "            user_interactions = set(user_interactions)\n",
    "            \n",
    "            for elem in self.recommenations:\n",
    "                if elem not in user_interactions:\n",
    "                    user_recs.append(elem)\n",
    "                    \n",
    "                if len(user_recs) == topn:\n",
    "                    break\n",
    "                    \n",
    "            all_recs.append(user_recs)\n",
    "                \n",
    "        return all_recs\n",
    "\n",
    "    \n",
    "toppop = ModifiedTopPopular()\n",
    "toppop.fit(joined)\n",
    "joined['toppopular_recs'] = toppop.predict(joined)\n",
    "joined.head()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ceff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg': 0.18407826659038715, 'recall': 0.11809654507778314}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_recommender(joined, model_preds='toppopular_recs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f81afd9",
   "metadata": {},
   "source": [
    "Качество ожидаемо улучшилось"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b6901",
   "metadata": {},
   "source": [
    "## III. Начинаем учитывать последовательности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3066c",
   "metadata": {},
   "source": [
    "давайте реализуем пример, когда мы рекомендуем \"следующий фильм\" по предыдущему\n",
    "\n",
    "Идея простая. Давайте для каждого фильма посчитаем, какие фильмы пользователи смотрят сразу после? И эти фильмы будем рекомендовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d454125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:00, 8762.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def increase_value_in_dict(d, key):\n",
    "\n",
    "    if key in d:\n",
    "        d[key] += 1\n",
    "    else:\n",
    "        d[key] = 1\n",
    "        \n",
    "\n",
    "\n",
    "class LastPopular:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.trained = False\n",
    "    \n",
    "    def fit(self, df, col='train_interactions'):\n",
    "        \n",
    "        overall_popularity = {}\n",
    "        \n",
    "        transition_matrix = defaultdict(list)\n",
    "        for _, row in df.iterrows():\n",
    "            \n",
    "            if len(row[col]) == 1:\n",
    "                continue\n",
    "\n",
    "            increase_value_in_dict(overall_popularity, row[col][0][0])\n",
    "                \n",
    "            for inter_prev, inter_next in zip(row[col][:-1], row[col][1:]):\n",
    "                item_prev, item_next = inter_prev[0], inter_next[0]\n",
    "                \n",
    "                transition_matrix[item_prev].append(item_next)\n",
    "\n",
    "                increase_value_in_dict(overall_popularity, item_next)\n",
    "\n",
    "\n",
    "        item2recs = {}\n",
    "        for item in transition_matrix:\n",
    "            \n",
    "            temp_counts = Counter(transition_matrix[item]).most_common() \n",
    "            item2recs[item] = [x[0] for x in temp_counts]\n",
    "                \n",
    "                \n",
    "        self.item2recs = item2recs.copy()\n",
    "        self.overall_popularity = [x[0] for x in sorted(overall_popularity.items(),\n",
    "                                                        key=lambda x: x[1],\n",
    "                                                        reverse=True)]\n",
    "        self.trained = True\n",
    "        \n",
    "    def predict(self, df, topn=10) -> List[np.ndarray]:\n",
    "        \n",
    "        assert self.trained\n",
    "         \n",
    "        all_recs = []\n",
    "        \n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows()):\n",
    "            \n",
    "            user_recs = []\n",
    "            \n",
    "            user_interactions = [x[0] for x in row['train_interactions']]\n",
    "            user_interactions += [x[0] for x in row['valid_interactions']]\n",
    "            \n",
    "            for item in user_interactions[::-1]:\n",
    "                \n",
    "                if item in self.item2recs:\n",
    "                    user_recs.extend([x for x in self.item2recs[item] \\\n",
    "                                      if x not in user_interactions and  x not in user_recs])\n",
    "                    \n",
    "                if len(user_recs) >= topn:\n",
    "                    break\n",
    "                    \n",
    "            user_interactions = set(user_interactions)\n",
    "            if len(user_recs) < topn:\n",
    "\n",
    "                for el in self.overall_popularity:\n",
    "                    if el not in user_recs and el not in user_interactions:\n",
    "                        user_recs.append(el)\n",
    "\n",
    "                    if len(user_recs) >= topn:\n",
    "                        break\n",
    "\n",
    "            all_recs.append(user_recs[:topn])\n",
    "                \n",
    "        return all_recs\n",
    "\n",
    "\n",
    "lp1 = LastPopular()\n",
    "lp1.fit(joined)\n",
    "joined['last_popular'] = lp1.predict(joined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa97481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg': 0.12486415315014132, 'recall': 0.078244659274838}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_recommender(joined, model_preds='last_popular')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a37da35",
   "metadata": {},
   "source": [
    "Есть ли идеи, как улучшить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a64c719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>train_interactions</th>\n",
       "      <th>valid_interactions</th>\n",
       "      <th>test_interactions</th>\n",
       "      <th>toppopular_recs</th>\n",
       "      <th>last_popular</th>\n",
       "      <th>ndcg_last_pop</th>\n",
       "      <th>recall_last_pop</th>\n",
       "      <th>ndcg_pop</th>\n",
       "      <th>recall_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>[(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...</td>\n",
       "      <td>[(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...</td>\n",
       "      <td>[(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...</td>\n",
       "      <td>[10440, 15297, 13865, 3734, 4151, 4880, 2657, ...</td>\n",
       "      <td>[2351, 11112, 657, 12623, 1290, 11754, 16361, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>[(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...</td>\n",
       "      <td>[(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]</td>\n",
       "      <td>[(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4880, 2657, 142, 86...</td>\n",
       "      <td>[15739, 6965, 10772, 16442, 7102, 2296, 10994,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576</td>\n",
       "      <td>[(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...</td>\n",
       "      <td>[(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...</td>\n",
       "      <td>[(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...</td>\n",
       "      <td>[10440, 15297, 3734, 4151, 4880, 142, 9996, 44...</td>\n",
       "      <td>[5311, 7019, 15679, 760, 6033, 5434, 14488, 12...</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>655</td>\n",
       "      <td>[(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...</td>\n",
       "      <td>[(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...</td>\n",
       "      <td>[(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...</td>\n",
       "      <td>[13218, 9628, 1215, 12192, 16152, 7408, 7793, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>[(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...</td>\n",
       "      <td>[(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...</td>\n",
       "      <td>[(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...</td>\n",
       "      <td>[4151, 10440, 9728, 3734, 2657, 13865, 9996, 1...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 train_interactions  \\\n",
       "0       30  [(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...   \n",
       "1      229  [(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...   \n",
       "2      576  [(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...   \n",
       "3      655  [(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...   \n",
       "4      733  [(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...   \n",
       "\n",
       "                                  valid_interactions  \\\n",
       "0  [(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...   \n",
       "1   [(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]   \n",
       "2  [(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...   \n",
       "3  [(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...   \n",
       "4  [(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...   \n",
       "\n",
       "                                   test_interactions  \\\n",
       "0  [(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...   \n",
       "1    [(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]   \n",
       "2  [(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...   \n",
       "3  [(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...   \n",
       "4  [(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...   \n",
       "\n",
       "                                     toppopular_recs  \\\n",
       "0  [10440, 15297, 13865, 3734, 4151, 4880, 2657, ...   \n",
       "1  [9728, 10440, 13865, 3734, 4880, 2657, 142, 86...   \n",
       "2  [10440, 15297, 3734, 4151, 4880, 142, 9996, 44...   \n",
       "3  [9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...   \n",
       "4  [9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...   \n",
       "\n",
       "                                        last_popular  ndcg_last_pop  \\\n",
       "0  [2351, 11112, 657, 12623, 1290, 11754, 16361, ...       0.000000   \n",
       "1  [15739, 6965, 10772, 16442, 7102, 2296, 10994,...       0.000000   \n",
       "2  [5311, 7019, 15679, 760, 6033, 5434, 14488, 12...       0.430677   \n",
       "3  [13218, 9628, 1215, 12192, 16152, 7408, 7793, ...       0.000000   \n",
       "4  [4151, 10440, 9728, 3734, 2657, 13865, 9996, 1...       0.000000   \n",
       "\n",
       "   recall_last_pop  ndcg_pop  recall_pop  \n",
       "0              0.0       0.5    0.333333  \n",
       "1              0.0       1.0    0.500000  \n",
       "2              0.2       0.0    0.000000  \n",
       "3              0.0       0.0    0.000000  \n",
       "4              0.0       0.0    0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined[['ndcg_last_pop','recall_last_pop']] = get_metrics(joined,model_preds='last_popular')\n",
    "joined[['ndcg_pop','recall_pop']] = get_metrics(joined,model_preds='toppopular_recs')\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07a9e154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_timediff_valid_test_interactions(row):\n",
    "    \n",
    "    last_valid_inter = row.valid_interactions[-1][1]\n",
    "    first_test_inter = row.test_interactions[0][1]\n",
    "    \n",
    "    days = int(first_test_inter.split('-')[2]) - int(last_valid_inter.split('-')[2])\n",
    "    return days\n",
    "    \n",
    "    \n",
    "joined['timediff'] = joined.apply(get_timediff_valid_test_interactions, axis=1)\n",
    "xy = joined.groupby('timediff').agg({'ndcg_last_pop':'mean', 'recall_last_pop':'mean',\n",
    "                                     'ndcg_pop':'mean', 'recall_pop':'mean',\n",
    "                                     'user_id':'count'})[:8]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "\n",
    "ax.plot(xy.index, xy.ndcg_last_pop, label='ndcg_lastpop')\n",
    "ax.plot(xy.index, xy.ndcg_pop, label='ndcg_pop')\n",
    "ax.set_title('NDCG/recall в зависимости от промежутка времени между\\nтестом и валидацией')\n",
    "ax.set_xlabel('timediff')\n",
    "ax.set_ylabel('ndcg/recall')\n",
    "\n",
    "ax.plot(xy.index, xy.recall_last_pop, label='recall_laspop')\n",
    "ax.plot(xy.index, xy.recall_pop, label='recall_pop')\n",
    "ax.legend()\n",
    "\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb80893f",
   "metadata": {},
   "source": [
    "Вопросы: \n",
    "\n",
    "Почему lastpop деградирует при большем timediff?\n",
    "\n",
    "Как нам поможет эта информация модифировать метод?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1851ec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:00, 8297.97it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class LastPopularDiffAware(LastPopular):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.trained = False\n",
    "    \n",
    "        \n",
    "    def predict(self, df, switch_time_diff=2,topn=10) -> List[np.ndarray]:\n",
    "        \n",
    "        assert self.trained\n",
    "         \n",
    "        all_recs = []\n",
    "        \n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows()):\n",
    "            \n",
    "            user_recs = []\n",
    "            \n",
    "            user_interactions = [x[0] for x in row['train_interactions']]\n",
    "            user_interactions += [x[0] for x in row['valid_interactions']]\n",
    "            \n",
    "            for item in user_interactions[::-1]:\n",
    "                \n",
    "                if row['timediff'] < switch_time_diff:\n",
    "                \n",
    "                    if item in self.item2recs:\n",
    "                        user_recs.extend([x for x in self.item2recs[item] \\\n",
    "                                          if x not in user_interactions and  x not in user_recs])\n",
    "\n",
    "                    if len(user_recs) >= topn:\n",
    "                        break\n",
    "                    \n",
    "            user_interactions = set(user_interactions)\n",
    "            \n",
    "            if len(user_recs) < topn:\n",
    "                \n",
    "                for el in self.overall_popularity:\n",
    "                    if el not in user_recs and el not in user_interactions:\n",
    "                        user_recs.append(el)\n",
    "                        \n",
    "                    if len(user_recs) >= topn:\n",
    "                        break\n",
    "                        \n",
    "\n",
    "                \n",
    "            all_recs.append(user_recs[:topn])\n",
    "                \n",
    "        return all_recs\n",
    "    \n",
    "    \n",
    "lp1 = LastPopularDiffAware()\n",
    "lp1.fit(joined)\n",
    "joined['last_popular_diff'] = lp1.predict(joined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d93458fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg': 0.1829229136032898, 'recall': 0.11647604506909406}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_recommender(joined, model_preds='last_popular_diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3693987",
   "metadata": {},
   "source": [
    "таким образом мы улучшили немного метрики просто на эвристики, что рекомендуем что-то похожее на последний фильм только тем, кто недавно зашел в тестовую интеракцию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac3ef39",
   "metadata": {},
   "source": [
    "## IV. Векторные представления"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d4618",
   "metadata": {},
   "source": [
    "давайте выучим айтемы и их похожести друг на друга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa92065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6590/6590 [00:03<00:00, 1665.17it/s]\n",
      "5000it [00:01, 3622.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "\n",
    "class Word2vecSimilar(LastPopular):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.trained = False\n",
    "    \n",
    "    def fit(self, df, col='train_interactions'):\n",
    "        \n",
    "        overall_popularity = {}\n",
    "        \n",
    "        sentences = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            sentences.append([x[0] for x in row[col]])\n",
    "            \n",
    "            for x in row[col]:\n",
    "                increase_value_in_dict(overall_popularity, x[0])\n",
    "                \n",
    "        self.overall_popularity = [x[0] for x in sorted(overall_popularity.items(),\n",
    "                                                key=lambda x: x[1],\n",
    "                                                reverse=True)]\n",
    "\n",
    "        model = gensim.models.Word2Vec(sentences=sentences, min_count=5, window=3, vector_size=64)\n",
    "\n",
    "        item2recs = {}\n",
    "        for item in tqdm(overall_popularity):\n",
    "            \n",
    "            if item in model.wv:\n",
    "                temp_counts = model.wv.similar_by_word(item, topn=200,)\n",
    "            else:\n",
    "                temp_counts = [(x, 0) for x in self.overall_popularity]\n",
    "            item2recs[item] = [x[0] for x in temp_counts]\n",
    "                \n",
    "                \n",
    "        self.item2recs = item2recs.copy()\n",
    "\n",
    "        self.trained = True\n",
    "        \n",
    "\n",
    "w2v_model = Word2vecSimilar()\n",
    "w2v_model.fit(joined)\n",
    "joined['w2v_preds'] = w2v_model.predict(joined) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb83f819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg': 0.07220352276755229, 'recall': 0.044180266231670484}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_recommender(joined, model_preds='w2v_preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01790eef",
   "metadata": {},
   "source": [
    "очень плохо, в чем может быть дело?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5581401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:14, 344.76it/s]\n",
      "100%|██████████| 6590/6590 [00:04<00:00, 1510.46it/s]\n",
      "5000it [00:02, 2177.75it/s]\n"
     ]
    }
   ],
   "source": [
    "class Word2vecSimilarModified(LastPopular):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.trained = False\n",
    "    \n",
    "    def fit(self, df, col='train_interactions'):\n",
    "        \n",
    "        overall_popularity = {}\n",
    "        \n",
    "        sentences = []\n",
    "        \n",
    "\n",
    "        for _, row in tqdm(df.iterrows()):\n",
    "            \n",
    "            cur_sentence = []\n",
    "            cur_day = None\n",
    "            \n",
    "            for x in row[col]:\n",
    "                if cur_day is None:\n",
    "                    cur_day = x[1]\n",
    "                    cur_sentence = [x[0]]\n",
    "                    continue\n",
    "                    \n",
    "                if (pd.to_datetime(x[1])-pd.to_datetime(cur_day)).days < 2:\n",
    "                    cur_sentence.append(x[0])\n",
    "                else:\n",
    "                    if len(cur_sentence) >1:\n",
    "                        sentences.append(cur_sentence)\n",
    "                        \n",
    "                    cur_sentence = []\n",
    "                    \n",
    "                cur_day = x[1]\n",
    "                    \n",
    "            \n",
    "            for x in row[col]:\n",
    "                increase_value_in_dict(overall_popularity, x[0])\n",
    "                \n",
    "        self.overall_popularity = [x[0] for x in sorted(overall_popularity.items(),\n",
    "                                                key=lambda x: x[1],\n",
    "                                                reverse=True)]\n",
    "\n",
    "        model = gensim.models.Word2Vec(sentences=sentences,min_count=5, window=3, vector_size=64)\n",
    "\n",
    "        item2recs = {}\n",
    "        for item in tqdm(overall_popularity):\n",
    "            \n",
    "            if item in model.wv:\n",
    "                temp_counts = model.wv.similar_by_word(item, topn=200,)\n",
    "            else:\n",
    "                temp_counts = [(x, 0) for x in self.overall_popularity]\n",
    "            item2recs[item] = [x[0] for x in temp_counts]\n",
    "                \n",
    "                \n",
    "        self.item2recs = item2recs.copy()\n",
    "\n",
    "        self.trained = True\n",
    "        \n",
    "        \n",
    "        \n",
    "w2v_model = Word2vecSimilarModified()\n",
    "w2v_model.fit(joined)\n",
    "joined['w2v_modified_preds'] = w2v_model.predict(joined) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78bd0b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg': 0.09222044827086491, 'recall': 0.05491137981080236}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_recommender(joined, model_preds='w2v_modified_preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0b951",
   "metadata": {},
   "source": [
    "Стало немного лучше, но намного хуже toppopular. Как вы думаете, почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d499202",
   "metadata": {},
   "source": [
    "Минутка саморекламы, w2v может быть неплохим recommender. Вот наша статья на хабр, как мы с помощью w2v заняли 4 из 11 мест в научном recsys-соревновании https://habr.com/ru/company/tinkoff/blog/575944/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d9a69",
   "metadata": {},
   "source": [
    "## V. Построим более менее нормальную модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad96a00",
   "metadata": {},
   "source": [
    "по факту у нас есть вот такие последовательности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ee32d",
   "metadata": {},
   "source": [
    "<img src=\"images/1.png\">\n",
    "\n",
    "поэтому мы можем решать задачу next-item recommendation через NLP-методы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68330654",
   "metadata": {},
   "source": [
    "<b>Вопросы:</b>\n",
    "\n",
    "1) Что мы можем не учесть, перенеся  nlp методs в recsys?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80ebf9",
   "metadata": {},
   "source": [
    "Сразу посмотрим в сторону transformer\n",
    "\n",
    "<img src='images/2.png'>\n",
    "<img src='images/3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c18e65e",
   "metadata": {},
   "source": [
    "SASRec - 2018 год  832 цитирований в день семинара\n",
    "\n",
    "BERT4REC - 2019 год  613 цитирований в день семинара"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4489cb1",
   "metadata": {},
   "source": [
    "<img src='images/4.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3cc37ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: catalyst==21.12 in /usr/local/lib/python3.7/site-packages (21.12)\n",
      "Requirement already satisfied: hydra-slayer>=0.1.1 in /usr/local/lib/python3.7/site-packages (from catalyst==21.12) (0.4.0)\n",
      "Requirement already satisfied: tensorboardX<2.3.0>=2.1.0 in /usr/local/lib/python3.7/site-packages (from catalyst==21.12) (2.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/site-packages (from catalyst==21.12) (1.10.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.7/site-packages (from catalyst==21.12) (4.62.2)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/site-packages (from catalyst==21.12) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/site-packages (from catalyst==21.12) (1.21.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/site-packages (from tensorboardX<2.3.0>=2.1.0->catalyst==21.12) (3.14.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorboardX<2.3.0>=2.1.0->catalyst==21.12) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch>=1.3.0->catalyst==21.12) (4.1.1)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install catalyst==21.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84a5e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catalyst \n",
    "import recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "269ef4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.1', '21.12')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recbole.__version__, catalyst.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "657d175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# flake8: noqa\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.init import constant_, xavier_normal_\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from catalyst import dl, metrics\n",
    "from catalyst.contrib.datasets import MovieLens\n",
    "from catalyst.utils import get_device, set_global_seed\n",
    "from torch.nn.utils.rnn import pad_sequence \n",
    "\n",
    "set_global_seed(42)\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648c2f7",
   "metadata": {},
   "source": [
    "надо закодировать айтемы, чтобы составлять тензоры и тд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aafba8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:00, 18112.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6590"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_items = set()\n",
    "for idx, row in tqdm(joined.iterrows()):\n",
    "    for el in row.train_interactions:\n",
    "        our_items.add(el[0])\n",
    "        \n",
    "len(our_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83f4973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item2idx = {k: i for i, k in enumerate(our_items)}\n",
    "idx2item = {i: k for k, i in item2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "024d0899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>train_interactions</th>\n",
       "      <th>valid_interactions</th>\n",
       "      <th>test_interactions</th>\n",
       "      <th>toppopular_recs</th>\n",
       "      <th>last_popular</th>\n",
       "      <th>ndcg_last_pop</th>\n",
       "      <th>recall_last_pop</th>\n",
       "      <th>ndcg_pop</th>\n",
       "      <th>recall_pop</th>\n",
       "      <th>timediff</th>\n",
       "      <th>last_popular_diff</th>\n",
       "      <th>w2v_preds</th>\n",
       "      <th>w2v_modified_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>[(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...</td>\n",
       "      <td>[(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...</td>\n",
       "      <td>[(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...</td>\n",
       "      <td>[10440, 15297, 13865, 3734, 4151, 4880, 2657, ...</td>\n",
       "      <td>[2351, 11112, 657, 12623, 1290, 11754, 16361, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>[10440, 15297, 13865, 3734, 4151, 4880, 2657, ...</td>\n",
       "      <td>[760, 4774, 11754, 10214, 5250, 14689, 5693, 1...</td>\n",
       "      <td>[6443, 7210, 12659, 16197, 10942, 14901, 10119...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 train_interactions  \\\n",
       "0       30  [(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...   \n",
       "\n",
       "                                  valid_interactions  \\\n",
       "0  [(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...   \n",
       "\n",
       "                                   test_interactions  \\\n",
       "0  [(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...   \n",
       "\n",
       "                                     toppopular_recs  \\\n",
       "0  [10440, 15297, 13865, 3734, 4151, 4880, 2657, ...   \n",
       "\n",
       "                                        last_popular  ndcg_last_pop  \\\n",
       "0  [2351, 11112, 657, 12623, 1290, 11754, 16361, ...            0.0   \n",
       "\n",
       "   recall_last_pop  ndcg_pop  recall_pop  timediff  \\\n",
       "0              0.0       0.5    0.333333         2   \n",
       "\n",
       "                                   last_popular_diff  \\\n",
       "0  [10440, 15297, 13865, 3734, 4151, 4880, 2657, ...   \n",
       "\n",
       "                                           w2v_preds  \\\n",
       "0  [760, 4774, 11754, 10214, 5250, 14689, 5693, 1...   \n",
       "\n",
       "                                  w2v_modified_preds  \n",
       "0  [6443, 7210, 12659, 16197, 10942, 14901, 10119...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cdd1e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ds, num_items, item2idx, phase='valid'):\n",
    "        super().__init__()\n",
    "        self.ds = ds\n",
    "        self.phase = phase\n",
    "        self.n_items = num_items\n",
    "        self.item2idx = item2idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        row = self.ds.iloc[idx]\n",
    "        \n",
    "        x_input = np.zeros(self.n_items+1)\n",
    "        x_input[[self.item2idx[x[0]]+1 for x in row['train_interactions'] if x[0] in self.item2idx]] = 1\n",
    "        \n",
    "        days_of_weeks = [x[2] for x in row['train_interactions'] if x[0] in self.item2idx][-99:]\n",
    "        \n",
    "        seq_input = [self.item2idx[x[0]]+1 for x in row['train_interactions'] if x[0] in self.item2idx][-99:]\n",
    "        \n",
    "        targets = np.zeros(self.n_items+1)\n",
    "        \n",
    "        dow_valid = row['valid_interactions'][0][2]\n",
    "        dow_test = row['test_interactions'][0][2]\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            return (seq_input, days_of_weeks, dow_valid)\n",
    "        elif self.phase == 'valid':\n",
    "            targets[[self.item2idx[x[0]]+1 for x in row['valid_interactions'] if x[0] in self.item2idx]] = 1\n",
    "        else:\n",
    "            return (seq_input,days_of_weeks,dow_test)\n",
    "            \n",
    "       # print(x_input.sum(), targets.sum())\n",
    "        return (targets, seq_input,days_of_weeks,dow_valid)\n",
    "     \n",
    "n_items = len(item2idx)\n",
    "\n",
    "train = MyDataset(ds=joined,\n",
    "                  num_items=n_items, \n",
    "                  item2idx=item2idx,\n",
    "                  phase='train')\n",
    "\n",
    "valid = MyDataset(ds=joined,\n",
    "                  num_items=n_items,\n",
    "                  item2idx=item2idx,\n",
    "                  phase='valid')\n",
    "\n",
    "#test = MyDataset(ds=ds_grouped, num_items=n_items, phase='test')\n",
    "\n",
    "print(len(train),len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f691fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_train(batch: List[Tuple[torch.Tensor]]) -> Dict[str, torch.Tensor]: \n",
    "    \n",
    "    seq_i,days_of_weeks,dow_valid = zip(*batch)\n",
    "    seq_len = torch.Tensor([len(x) for x in seq_i])\n",
    "    dow_valid = torch.Tensor([x for x in dow_valid])\n",
    "    seq_i = pad_sequence([torch.Tensor(t) for t in seq_i]).T    \n",
    "    days_of_weeks = pad_sequence([torch.Tensor(t) for t in days_of_weeks]).T  \n",
    "    \n",
    "    return {'seq_i': seq_i, \n",
    "            'seq_len':seq_len,\n",
    "            'dow': days_of_weeks,\n",
    "            'dow_valid': dow_valid}\n",
    "\n",
    "\n",
    "def collate_fn_valid(batch: List[Tuple[torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
    "    \n",
    "    y, seq_i, days_of_weeks, dow_valid = zip(*batch)\n",
    "    \n",
    "    seq_len = torch.Tensor([len(x) for x in seq_i]).long()\n",
    "    seq_i = pad_sequence([torch.Tensor(t) for t in seq_i]).T.long()\n",
    "    days_of_weeks = pad_sequence([torch.Tensor(t) for t in days_of_weeks]).T.long()\n",
    "    dow_valid = torch.Tensor([x for x in dow_valid])\n",
    "            \n",
    "    targets = pad_sequence([torch.Tensor(t) for t in y]).T\n",
    "\n",
    "    return {\"targets\": targets,\n",
    "            'seq_i': seq_i,\n",
    "            'seq_len':seq_len,\n",
    "            'dow': days_of_weeks,\n",
    "            'dow_valid': dow_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ab42228",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "        \"train\": DataLoader(train, batch_size=256, collate_fn=collate_fn_train),\n",
    "        \"valid\": DataLoader(valid, batch_size=256, collate_fn=collate_fn_valid),\n",
    "        #\"infer\": DataLoader(test, batch_size=32, collate_fn=collate_fn_valid),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c1b8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loaders['train']:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efd77166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq_i': tensor([[1866.,  261., 4922.,  ...,    0.,    0.,    0.],\n",
       "         [4482., 1626.,  674.,  ...,    0.,    0.,    0.],\n",
       "         [ 411., 4306.,  492.,  ..., 3897., 6350., 6021.],\n",
       "         ...,\n",
       "         [1153., 6492., 4267.,  ...,    0.,    0.,    0.],\n",
       "         [1403., 5719.,  506.,  ...,    0.,    0.,    0.],\n",
       "         [1670., 4154., 6129.,  ...,    0.,    0.,    0.]]),\n",
       " 'seq_len': tensor([10.,  8., 99., 11.,  7.,  8.,  2., 24., 13., 11.,  3.,  1.,  9., 10.,\n",
       "          6.,  2., 28., 11., 26., 16., 19.,  4., 35., 47.,  3., 28.,  9., 21.,\n",
       "          1., 17.,  9.,  5., 16.,  7., 13., 15., 15., 11., 20., 27.,  1.,  8.,\n",
       "         65., 15., 20.,  3., 20., 29.,  4., 20., 13.,  7.,  6.,  3., 43., 95.,\n",
       "          2.,  2.,  2., 24., 61., 14., 39.,  5., 82.,  3.,  2.,  4.,  2., 13.,\n",
       "          3., 45.,  8.,  8.,  3.,  4.,  5.,  7.,  9.,  1., 15., 86.,  5.,  5.,\n",
       "          1., 53., 22., 21., 13.,  3., 49., 51.,  1., 34., 99., 29.,  2., 14.,\n",
       "          5.,  5.,  5.,  9.,  1.,  3., 28., 23., 21.,  1.,  1.,  6., 14.,  2.,\n",
       "          2.,  3.,  9., 13.,  3.,  5., 17., 27.,  5.,  5.,  1.,  3., 11.,  4.,\n",
       "          2., 59., 30.,  1.,  1., 47.,  4.,  5., 39., 13., 48.,  9.,  6., 14.,\n",
       "         64.,  3.,  3., 31.,  6., 11., 35.,  1.,  7.,  3., 12.,  5.,  6.,  6.,\n",
       "         17.,  7.,  1., 12., 33.,  6., 33.,  1., 47.,  2.,  1., 28., 23., 42.,\n",
       "          4., 53.,  5., 47.,  2.,  4.,  9.,  5.,  5., 10.,  9.,  3.,  5.,  3.,\n",
       "          3., 28.,  3., 63., 14.,  6., 10.,  2.,  5.,  4.,  5., 59., 16.,  7.,\n",
       "         10.,  1.,  2., 18.,  2.,  8., 21.,  1., 11.,  1., 99., 10.,  5.,  2.,\n",
       "         23., 28.,  4.,  3.,  6.,  5.,  4., 17., 14.,  8.,  2.,  1., 12., 11.,\n",
       "          3.,  1.,  1., 11.,  1.,  2.,  3., 25., 12.,  2., 11.,  5., 26., 26.,\n",
       "         11., 40., 51., 99.,  4., 10., 16., 28.,  8.,  2.,  2., 48., 52., 14.,\n",
       "          8., 39., 33.,  3.]),\n",
       " 'dow': tensor([[2., 5., 5.,  ..., 0., 0., 0.],\n",
       "         [3., 3., 5.,  ..., 0., 0., 0.],\n",
       "         [5., 6., 6.,  ..., 6., 6., 0.],\n",
       "         ...,\n",
       "         [0., 1., 2.,  ..., 0., 0., 0.],\n",
       "         [1., 2., 2.,  ..., 0., 0., 0.],\n",
       "         [3., 6., 0.,  ..., 0., 0., 0.]]),\n",
       " 'dow_valid': tensor([2., 1., 2., 1., 0., 6., 1., 6., 0., 6., 4., 3., 2., 0., 1., 4., 3., 0.,\n",
       "         0., 6., 6., 3., 5., 6., 2., 1., 2., 6., 6., 3., 5., 6., 2., 4., 3., 0.,\n",
       "         0., 6., 6., 0., 2., 5., 3., 1., 2., 4., 1., 0., 0., 6., 0., 6., 5., 3.,\n",
       "         3., 2., 2., 6., 3., 3., 6., 0., 6., 4., 6., 0., 6., 4., 4., 1., 0., 6.,\n",
       "         0., 6., 2., 6., 5., 4., 6., 2., 5., 3., 0., 3., 5., 2., 4., 6., 0., 2.,\n",
       "         0., 0., 5., 3., 6., 6., 5., 3., 0., 6., 0., 1., 0., 2., 1., 1., 6., 1.,\n",
       "         3., 1., 3., 6., 2., 0., 0., 0., 1., 5., 6., 3., 3., 2., 3., 0., 0., 3.,\n",
       "         2., 6., 6., 3., 4., 1., 2., 3., 0., 2., 6., 6., 0., 2., 6., 2., 2., 3.,\n",
       "         2., 6., 1., 5., 3., 4., 2., 3., 6., 0., 6., 0., 4., 5., 2., 5., 1., 1.,\n",
       "         6., 0., 4., 6., 0., 1., 1., 5., 5., 6., 6., 5., 4., 5., 6., 5., 2., 0.,\n",
       "         5., 6., 6., 1., 6., 0., 4., 0., 1., 6., 6., 6., 0., 6., 5., 0., 4., 1.,\n",
       "         4., 4., 6., 1., 6., 2., 0., 2., 6., 6., 0., 0., 6., 6., 4., 5., 6., 0.,\n",
       "         0., 6., 1., 4., 6., 6., 5., 1., 6., 6., 1., 2., 1., 4., 3., 0., 2., 6.,\n",
       "         6., 0., 1., 6., 6., 6., 3., 6., 4., 2., 6., 6., 3., 0., 5., 2., 0., 0.,\n",
       "         2., 2., 4., 6.])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c0708",
   "metadata": {},
   "source": [
    "Теперь код bert4rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb30518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from recbole.model.abstract_recommender import SequentialRecommender\n",
    "from recbole.model.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b25e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head Self-attention layers, a attention score dropout layer is introduced.\n",
    "    Args:\n",
    "        input_tensor (torch.Tensor): the input of the multi-head self-attention layer\n",
    "        attention_mask (torch.Tensor): the attention mask for input tensor\n",
    "    Returns:\n",
    "        hidden_states (torch.Tensor): the output of the multi-head self-attention layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_heads,\n",
    "        hidden_size,\n",
    "        hidden_dropout_prob,\n",
    "        attn_dropout_prob,\n",
    "        layer_norm_eps,\n",
    "    ):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        if hidden_size % n_heads != 0:\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "                \"heads (%d)\" % (hidden_size, n_heads)\n",
    "            )\n",
    "\n",
    "        self.num_attention_heads = n_heads\n",
    "        self.attention_head_size = int(hidden_size / n_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "        self.sqrt_attention_head_size = math.sqrt(self.attention_head_size)\n",
    "\n",
    "        self.query = nn.Linear(hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(hidden_size, self.all_head_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout_prob)\n",
    "\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(hidden_size, eps=layer_norm_eps)\n",
    "        self.out_dropout = nn.Dropout(hidden_dropout_prob)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (\n",
    "            self.num_attention_heads,\n",
    "            self.attention_head_size,\n",
    "        )\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input_tensor, attention_mask, return_explanations=False):\n",
    "        mixed_query_layer = self.query(input_tensor)\n",
    "        mixed_key_layer = self.key(input_tensor)\n",
    "        mixed_value_layer = self.value(input_tensor)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer).permute(0, 2, 1, 3)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer).permute(0, 2, 3, 1)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer)\n",
    "\n",
    "        attention_scores = attention_scores / self.sqrt_attention_head_size\n",
    "        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "        # [batch_size heads seq_len seq_len] scores\n",
    "        # [batch_size 1 1 seq_len]\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = self.softmax(attention_scores)\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "\n",
    "        attention_probs = self.attn_dropout(attention_probs)\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        hidden_states = self.dense(context_layer)\n",
    "        hidden_states = self.out_dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        \n",
    "        if return_explanations:\n",
    "            return hidden_states, attention_probs\n",
    "        else:\n",
    "            return hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "141d2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    One transformer layer consists of a multi-head self-attention layer and a point-wise feed-forward layer.\n",
    "    Args:\n",
    "        hidden_states (torch.Tensor): the input of the multi-head self-attention sublayer\n",
    "        attention_mask (torch.Tensor): the attention mask for the multi-head self-attention sublayer\n",
    "    Returns:\n",
    "        feedforward_output (torch.Tensor): The output of the point-wise feed-forward sublayer,\n",
    "                                           is the output of the transformer layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_heads,\n",
    "        hidden_size,\n",
    "        intermediate_size,\n",
    "        hidden_dropout_prob,\n",
    "        attn_dropout_prob,\n",
    "        hidden_act,\n",
    "        layer_norm_eps,\n",
    "    ):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(\n",
    "            n_heads, hidden_size, hidden_dropout_prob, attn_dropout_prob, layer_norm_eps\n",
    "        )\n",
    "        self.feed_forward = FeedForward(\n",
    "            hidden_size,\n",
    "            intermediate_size,\n",
    "            hidden_dropout_prob,\n",
    "            hidden_act,\n",
    "            layer_norm_eps,\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask,return_explanations=False):\n",
    "        \n",
    "        if return_explanations:\n",
    "            attention_output, expl = self.multi_head_attention(hidden_states, attention_mask,\n",
    "                                                         return_explanations=return_explanations)\n",
    "            \n",
    "        else:\n",
    "            attention_output = self.multi_head_attention(hidden_states, attention_mask,\n",
    "                                                         return_explanations=return_explanations)\n",
    "        feedforward_output = self.feed_forward(attention_output)\n",
    "        \n",
    "        if return_explanations:\n",
    "            return feedforward_output, expl\n",
    "        else:\n",
    "            return feedforward_output\n",
    "    \n",
    "    \n",
    "    \n",
    "class TransformerEncoder(nn.Module):\n",
    "    r\"\"\"One TransformerEncoder consists of several TransformerLayers.\n",
    "    Args:\n",
    "        n_layers(num): num of transformer layers in transformer encoder. Default: 2\n",
    "        n_heads(num): num of attention heads for multi-head attention layer. Default: 2\n",
    "        hidden_size(num): the input and output hidden size. Default: 64\n",
    "        inner_size(num): the dimensionality in feed-forward layer. Default: 256\n",
    "        hidden_dropout_prob(float): probability of an element to be zeroed. Default: 0.5\n",
    "        attn_dropout_prob(float): probability of an attention score to be zeroed. Default: 0.5\n",
    "        hidden_act(str): activation function in feed-forward layer. Default: 'gelu'\n",
    "                      candidates: 'gelu', 'relu', 'swish', 'tanh', 'sigmoid'\n",
    "        layer_norm_eps(float): a value added to the denominator for numerical stability. Default: 1e-12\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_layers=2,\n",
    "        n_heads=2,\n",
    "        hidden_size=64,\n",
    "        inner_size=256,\n",
    "        hidden_dropout_prob=0.5,\n",
    "        attn_dropout_prob=0.5,\n",
    "        hidden_act=\"gelu\",\n",
    "        layer_norm_eps=1e-12,\n",
    "    ):\n",
    "\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        layer = TransformerLayer(\n",
    "            n_heads,\n",
    "            hidden_size,\n",
    "            inner_size,\n",
    "            hidden_dropout_prob,\n",
    "            attn_dropout_prob,\n",
    "            hidden_act,\n",
    "            layer_norm_eps,\n",
    "        )\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True,\n",
    "                return_explanations=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_states (torch.Tensor): the input of the TransformerEncoder\n",
    "            attention_mask (torch.Tensor): the attention mask for the input hidden_states\n",
    "            output_all_encoded_layers (Bool): whether output all transformer layers' output\n",
    "        Returns:\n",
    "            all_encoder_layers (list): if output_all_encoded_layers is True, return a list consists of all transformer\n",
    "            layers' output, otherwise return a list only consists of the output of last transformer layer.\n",
    "        \"\"\"\n",
    "        all_encoder_layers = []\n",
    "        for idx, layer_module in enumerate(self.layer):\n",
    "            \n",
    "            if return_explanations:\n",
    "                hidden_states, expl = layer_module(hidden_states, attention_mask, \n",
    "                                         return_explanations=return_explanations)\n",
    "            else:            \n",
    "                hidden_states = layer_module(hidden_states, attention_mask, \n",
    "                                             return_explanations=return_explanations)\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append(hidden_states)\n",
    "        if not output_all_encoded_layers:\n",
    "            all_encoder_layers.append(hidden_states)\n",
    "            \n",
    "        if return_explanations:\n",
    "            return all_encoder_layers, expl\n",
    "        else:\n",
    "            return all_encoder_layers\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd95e3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq_i': tensor([[1866.,  261., 4922.,  ...,    0.,    0.,    0.],\n",
       "         [4482., 1626.,  674.,  ...,    0.,    0.,    0.],\n",
       "         [ 411., 4306.,  492.,  ..., 3897., 6350., 6021.],\n",
       "         ...,\n",
       "         [1153., 6492., 4267.,  ...,    0.,    0.,    0.],\n",
       "         [1403., 5719.,  506.,  ...,    0.,    0.,    0.],\n",
       "         [1670., 4154., 6129.,  ...,    0.,    0.,    0.]]),\n",
       " 'seq_len': tensor([10.,  8., 99., 11.,  7.,  8.,  2., 24., 13., 11.,  3.,  1.,  9., 10.,\n",
       "          6.,  2., 28., 11., 26., 16., 19.,  4., 35., 47.,  3., 28.,  9., 21.,\n",
       "          1., 17.,  9.,  5., 16.,  7., 13., 15., 15., 11., 20., 27.,  1.,  8.,\n",
       "         65., 15., 20.,  3., 20., 29.,  4., 20., 13.,  7.,  6.,  3., 43., 95.,\n",
       "          2.,  2.,  2., 24., 61., 14., 39.,  5., 82.,  3.,  2.,  4.,  2., 13.,\n",
       "          3., 45.,  8.,  8.,  3.,  4.,  5.,  7.,  9.,  1., 15., 86.,  5.,  5.,\n",
       "          1., 53., 22., 21., 13.,  3., 49., 51.,  1., 34., 99., 29.,  2., 14.,\n",
       "          5.,  5.,  5.,  9.,  1.,  3., 28., 23., 21.,  1.,  1.,  6., 14.,  2.,\n",
       "          2.,  3.,  9., 13.,  3.,  5., 17., 27.,  5.,  5.,  1.,  3., 11.,  4.,\n",
       "          2., 59., 30.,  1.,  1., 47.,  4.,  5., 39., 13., 48.,  9.,  6., 14.,\n",
       "         64.,  3.,  3., 31.,  6., 11., 35.,  1.,  7.,  3., 12.,  5.,  6.,  6.,\n",
       "         17.,  7.,  1., 12., 33.,  6., 33.,  1., 47.,  2.,  1., 28., 23., 42.,\n",
       "          4., 53.,  5., 47.,  2.,  4.,  9.,  5.,  5., 10.,  9.,  3.,  5.,  3.,\n",
       "          3., 28.,  3., 63., 14.,  6., 10.,  2.,  5.,  4.,  5., 59., 16.,  7.,\n",
       "         10.,  1.,  2., 18.,  2.,  8., 21.,  1., 11.,  1., 99., 10.,  5.,  2.,\n",
       "         23., 28.,  4.,  3.,  6.,  5.,  4., 17., 14.,  8.,  2.,  1., 12., 11.,\n",
       "          3.,  1.,  1., 11.,  1.,  2.,  3., 25., 12.,  2., 11.,  5., 26., 26.,\n",
       "         11., 40., 51., 99.,  4., 10., 16., 28.,  8.,  2.,  2., 48., 52., 14.,\n",
       "          8., 39., 33.,  3.]),\n",
       " 'dow': tensor([[2., 5., 5.,  ..., 0., 0., 0.],\n",
       "         [3., 3., 5.,  ..., 0., 0., 0.],\n",
       "         [5., 6., 6.,  ..., 6., 6., 0.],\n",
       "         ...,\n",
       "         [0., 1., 2.,  ..., 0., 0., 0.],\n",
       "         [1., 2., 2.,  ..., 0., 0., 0.],\n",
       "         [3., 6., 0.,  ..., 0., 0., 0.]]),\n",
       " 'dow_valid': tensor([2., 1., 2., 1., 0., 6., 1., 6., 0., 6., 4., 3., 2., 0., 1., 4., 3., 0.,\n",
       "         0., 6., 6., 3., 5., 6., 2., 1., 2., 6., 6., 3., 5., 6., 2., 4., 3., 0.,\n",
       "         0., 6., 6., 0., 2., 5., 3., 1., 2., 4., 1., 0., 0., 6., 0., 6., 5., 3.,\n",
       "         3., 2., 2., 6., 3., 3., 6., 0., 6., 4., 6., 0., 6., 4., 4., 1., 0., 6.,\n",
       "         0., 6., 2., 6., 5., 4., 6., 2., 5., 3., 0., 3., 5., 2., 4., 6., 0., 2.,\n",
       "         0., 0., 5., 3., 6., 6., 5., 3., 0., 6., 0., 1., 0., 2., 1., 1., 6., 1.,\n",
       "         3., 1., 3., 6., 2., 0., 0., 0., 1., 5., 6., 3., 3., 2., 3., 0., 0., 3.,\n",
       "         2., 6., 6., 3., 4., 1., 2., 3., 0., 2., 6., 6., 0., 2., 6., 2., 2., 3.,\n",
       "         2., 6., 1., 5., 3., 4., 2., 3., 6., 0., 6., 0., 4., 5., 2., 5., 1., 1.,\n",
       "         6., 0., 4., 6., 0., 1., 1., 5., 5., 6., 6., 5., 4., 5., 6., 5., 2., 0.,\n",
       "         5., 6., 6., 1., 6., 0., 4., 0., 1., 6., 6., 6., 0., 6., 5., 0., 4., 1.,\n",
       "         4., 4., 6., 1., 6., 2., 0., 2., 6., 6., 0., 0., 6., 6., 4., 5., 6., 0.,\n",
       "         0., 6., 1., 4., 6., 6., 5., 1., 6., 6., 1., 2., 1., 4., 3., 0., 2., 6.,\n",
       "         6., 0., 1., 6., 6., 6., 3., 6., 4., 2., 6., 6., 3., 0., 5., 2., 0., 0.,\n",
       "         2., 2., 4., 6.])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02adccf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ff53df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4Rec(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_items):\n",
    "        super(BERT4Rec, self).__init__()\n",
    "\n",
    "        # load parameters info\n",
    "        self.n_layers = 2\n",
    "        self.n_heads = 2\n",
    "        self.hidden_size = 64  # same as embedding_size\n",
    "        self.inner_size = 128 # the dimensionality in feed-forward layer\n",
    "        self.hidden_dropout_prob = 0.2\n",
    "        self.attn_dropout_prob = 0.2\n",
    "        self.hidden_act = 'sigmoid'\n",
    "        self.layer_norm_eps = 1e-5\n",
    "        self.ITEM_SEQ = 'seq_i'\n",
    "        self.ITEM_SEQ_LEN = 'seq_len'\n",
    "        self.max_seq_length = 100\n",
    "        \n",
    "\n",
    "        self.mask_ratio = 0.2\n",
    "\n",
    "        self.loss_type =  'CE'\n",
    "        self.initializer_range = 1e-2\n",
    "\n",
    "        # load dataset info\n",
    "        self.n_items = n_items\n",
    "        self.mask_token = self.n_items \n",
    "        self.mask_item_length = int(self.mask_ratio * self.max_seq_length)\n",
    "\n",
    "        # define layers and loss\n",
    "        self.item_embedding = nn.Embedding(self.n_items + 1, self.hidden_size, padding_idx=0)  # mask token add 1\n",
    "        self.position_embedding = nn.Embedding(self.max_seq_length + 1, self.hidden_size)  # add mask_token at the last\n",
    "        self.trm_encoder = TransformerEncoder(\n",
    "            n_layers=self.n_layers,\n",
    "            n_heads=self.n_heads,\n",
    "            hidden_size=self.hidden_size,\n",
    "            inner_size=self.inner_size,\n",
    "            hidden_dropout_prob=self.hidden_dropout_prob,\n",
    "            attn_dropout_prob=self.attn_dropout_prob,\n",
    "            hidden_act=self.hidden_act,\n",
    "            layer_norm_eps=self.layer_norm_eps\n",
    "        )\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(self.hidden_size, eps=self.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(self.hidden_dropout_prob)\n",
    "\n",
    "        # we only need compute the loss at the masked position\n",
    "        try:\n",
    "            assert self.loss_type in ['BPR', 'CE']\n",
    "        except AssertionError:\n",
    "            raise AssertionError(\"Make sure 'loss_type' in ['BPR', 'CE']!\")\n",
    "\n",
    "        # parameters initialization\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def gather_indexes(self, output, gather_index):\n",
    "        \"\"\"Gathers the vectors at the specific positions over a minibatch\"\"\"\n",
    "        gather_index = gather_index.view(-1, 1, 1).expand(-1, -1, output.shape[-1])\n",
    "        output_tensor = output.gather(dim=1, index=gather_index)\n",
    "        return output_tensor.squeeze(1)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def get_attention_mask(self, item_seq):\n",
    "        \"\"\"Generate bidirectional attention mask for multi-head attention.\"\"\"\n",
    "        attention_mask = (item_seq > 0).long()\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)  # torch.int64\n",
    "        # bidirectional mask\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        return extended_attention_mask\n",
    "\n",
    "    def _neg_sample(self, item_set):\n",
    "        item = random.randint(1, self.n_items - 1)\n",
    "        while item in item_set:\n",
    "            item = random.randint(1, self.n_items - 1)\n",
    "        return item\n",
    "\n",
    "    def _padding_sequence(self, sequence, max_length):\n",
    "        pad_len = max_length - len(sequence)\n",
    "        sequence = [0] * pad_len + sequence\n",
    "        sequence = sequence[-max_length:]  # truncate according to the max_length\n",
    "        return sequence\n",
    "\n",
    "    def reconstruct_train_data(self, item_seq):\n",
    "        \"\"\"\n",
    "        Mask item sequence for training.\n",
    "        \"\"\"\n",
    "        device = item_seq.device\n",
    "        batch_size = item_seq.size(0)\n",
    "\n",
    "        sequence_instances = item_seq.cpu().numpy().tolist()\n",
    "\n",
    "        # Masked Item Prediction\n",
    "        # [B * Len]\n",
    "        masked_item_sequence = []\n",
    "        pos_items = []\n",
    "        neg_items = []\n",
    "        masked_index = []\n",
    "        for instance in sequence_instances:\n",
    "            masked_sequence = instance.copy()\n",
    "            pos_item = []\n",
    "            neg_item = []\n",
    "            index_ids = []\n",
    "            for index_id, item in enumerate(instance):\n",
    "                # padding is 0, the sequence is end\n",
    "                if item == 0:\n",
    "                    break\n",
    "                prob = random.random()\n",
    "                if prob < self.mask_ratio:\n",
    "                    pos_item.append(item)\n",
    "                    neg_item.append(self._neg_sample(instance))\n",
    "                    masked_sequence[index_id] = self.mask_token\n",
    "                    index_ids.append(index_id)\n",
    "\n",
    "            masked_item_sequence.append(masked_sequence)\n",
    "            pos_items.append(self._padding_sequence(pos_item, self.mask_item_length))\n",
    "            neg_items.append(self._padding_sequence(neg_item, self.mask_item_length))\n",
    "            masked_index.append(self._padding_sequence(index_ids, self.mask_item_length))\n",
    "\n",
    "        # [B Len]\n",
    "        masked_item_sequence = torch.tensor(masked_item_sequence, dtype=torch.long, device=device).view(batch_size, -1)\n",
    "        # [B mask_len]\n",
    "        pos_items = torch.tensor(pos_items, dtype=torch.long, device=device).view(batch_size, -1)\n",
    "        # [B mask_len]\n",
    "        neg_items = torch.tensor(neg_items, dtype=torch.long, device=device).view(batch_size, -1)\n",
    "        # [B mask_len]\n",
    "        masked_index = torch.tensor(masked_index, dtype=torch.long, device=device).view(batch_size, -1)\n",
    "        return masked_item_sequence, pos_items, neg_items, masked_index\n",
    "\n",
    "    def reconstruct_test_data(self, item_seq, item_seq_len):\n",
    "        \"\"\"\n",
    "        Add mask token at the last position according to the lengths of item_seq\n",
    "        \"\"\"\n",
    "        padding = torch.zeros(item_seq.size(0), dtype=torch.long, device=item_seq.device)  # [B]\n",
    "        item_seq = torch.cat((item_seq, padding.unsqueeze(-1)), dim=-1)  # [B max_len+1]\n",
    "        for batch_id, last_position in enumerate(item_seq_len):\n",
    "            item_seq[batch_id][last_position] = self.mask_token\n",
    "        return item_seq\n",
    "\n",
    "    def forward(self, item_seq, return_explanations=False):\n",
    "        \n",
    "        position_ids = torch.arange(item_seq.size(1), dtype=torch.long, device=item_seq.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(item_seq)\n",
    "        position_embedding = self.position_embedding(position_ids)\n",
    "        \n",
    "        item_emb = self.item_embedding(item_seq)\n",
    "        input_emb = item_emb + position_embedding\n",
    "        input_emb = self.LayerNorm(input_emb)\n",
    "        input_emb = self.dropout(input_emb)\n",
    "        extended_attention_mask = self.get_attention_mask(item_seq)\n",
    "        if return_explanations:\n",
    "            trm_output, explanations = self.trm_encoder(input_emb, extended_attention_mask, output_all_encoded_layers=True,\n",
    "                                         return_explanations=return_explanations)\n",
    "        else:\n",
    "            trm_output = self.trm_encoder(input_emb, extended_attention_mask, output_all_encoded_layers=True,\n",
    "                                         return_explanations=return_explanations)\n",
    "            \n",
    "        output = trm_output[-1]\n",
    "        \n",
    "        if return_explanations:\n",
    "            return output, explanations\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def multi_hot_embed(self, masked_index, max_length):\n",
    "        \"\"\"\n",
    "        For memory, we only need calculate loss for masked position.\n",
    "        Generate a multi-hot vector to indicate the masked position for masked sequence, and then is used for\n",
    "        gathering the masked position hidden representation.\n",
    "        Examples:\n",
    "            sequence: [1 2 3 4 5]\n",
    "            masked_sequence: [1 mask 3 mask 5]\n",
    "            masked_index: [1, 3]\n",
    "            max_length: 5\n",
    "            multi_hot_embed: [[0 1 0 0 0], [0 0 0 1 0]]\n",
    "        \"\"\"\n",
    "        masked_index = masked_index.view(-1)\n",
    "        multi_hot = torch.zeros(masked_index.size(0), max_length, device=masked_index.device)\n",
    "        multi_hot[torch.arange(masked_index.size(0)), masked_index] = 1\n",
    "        return multi_hot\n",
    "\n",
    "    def calculate_loss(self, interaction):\n",
    "        item_seq = interaction[self.ITEM_SEQ].long()\n",
    "        masked_item_seq, pos_items, neg_items, masked_index = self.reconstruct_train_data(item_seq)\n",
    "\n",
    "        seq_output = self.forward(masked_item_seq)\n",
    "        pred_index_map = self.multi_hot_embed(masked_index, masked_item_seq.size(-1))  # [B*mask_len max_len]\n",
    "        # [B mask_len] -> [B mask_len max_len] multi hot\n",
    "        pred_index_map = pred_index_map.view(masked_index.size(0), masked_index.size(1), -1)  # [B mask_len max_len]\n",
    "        # [B mask_len max_len] * [B max_len H] -> [B mask_len H]\n",
    "        # only calculate loss for masked position\n",
    "        seq_output = torch.bmm(pred_index_map, seq_output)  # [B mask_len H]\n",
    "\n",
    "        if self.loss_type == 'BPR':\n",
    "            pos_items_emb = self.item_embedding(pos_items)  # [B mask_len H]\n",
    "            neg_items_emb = self.item_embedding(neg_items)  # [B mask_len H]\n",
    "            pos_score = torch.sum(seq_output * pos_items_emb, dim=-1)  # [B mask_len]\n",
    "            neg_score = torch.sum(seq_output * neg_items_emb, dim=-1)  # [B mask_len]\n",
    "            targets = (masked_index > 0).float()\n",
    "            loss = - torch.sum(torch.log(1e-14 + torch.sigmoid(pos_score - neg_score)) * targets) \\\n",
    "                   / torch.sum(targets)\n",
    "            return loss\n",
    "\n",
    "        elif self.loss_type == 'CE':\n",
    "            loss_fct = nn.CrossEntropyLoss(reduction='none')\n",
    "            test_item_emb = self.item_embedding.weight[:self.n_items]  # [item_num H]\n",
    "            logits = torch.matmul(seq_output, test_item_emb.transpose(0, 1))  # [B mask_len item_num]\n",
    "            targets = (masked_index > 0).float().view(-1)  # [B*mask_len]\n",
    "\n",
    "            loss = torch.sum(loss_fct(logits.view(-1, test_item_emb.size(0)), pos_items.view(-1)) * targets) \\\n",
    "                   / torch.sum(targets)\n",
    "            return loss\n",
    "        else:\n",
    "            raise NotImplementedError(\"Make sure 'loss_type' in ['BPR', 'CE']!\")\n",
    "\n",
    "\n",
    "    def full_sort_predict(self, interaction, return_explanations=False):\n",
    "        item_seq = interaction[self.ITEM_SEQ].long()\n",
    "        item_seq_len = interaction[self.ITEM_SEQ_LEN].long()\n",
    "        item_seq = self.reconstruct_test_data(item_seq, item_seq_len)\n",
    "        \n",
    "        if return_explanations:\n",
    "            seq_output, expl = self.forward(item_seq, return_explanations=return_explanations)\n",
    "        else:\n",
    "            seq_output = self.forward(item_seq, return_explanations=return_explanations)\n",
    "            \n",
    "        \n",
    "        seq_output = self.gather_indexes(seq_output, item_seq_len - 1)  # [B H]\n",
    "        test_items_emb = self.item_embedding.weight[:self.n_items]  # delete masked token\n",
    "        scores = torch.matmul(seq_output, test_items_emb.transpose(0, 1))  # [B, item_num]\n",
    "                \n",
    "        idxs = item_seq.nonzero()\n",
    "        item_seq[item_seq==self.n_items] = 0\n",
    "        scores[idxs[:,0], item_seq[idxs[:,0],idxs[:,1]].long()] = -1000\n",
    "\n",
    "        if return_explanations:\n",
    "            return scores, expl\n",
    "        else:\n",
    "            return scores\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24e8ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSysRunner(dl.Runner):\n",
    "    def on_loader_start(self, runner):\n",
    "        super().on_loader_start(runner)\n",
    "        self.meters = {\n",
    "            key: metrics.AdditiveMetric(compute_on_call=False)\n",
    "            for key in [\"loss_ae\", \"loss_kld\", \"loss\"]\n",
    "        }\n",
    "\n",
    "    def handle_batch(self, batch):\n",
    "\n",
    "        if 'targets' in batch:\n",
    "            x_true = batch[\"targets\"]\n",
    "            \n",
    "        loss = self.model.calculate_loss(batch)\n",
    "\n",
    "        if 'targets' in batch:\n",
    "            scores = self.model.full_sort_predict(batch)\n",
    "            \n",
    "            self.batch.update({'targets': batch['targets'], 'logits':scores, 'inputs':scores})\n",
    "        else:\n",
    "            self.batch.update({\"inputs\": torch.zeros((30,30)),\n",
    "                           \"targets\": torch.zeros((30,30)),\n",
    "                           'logits': torch.zeros((30,30))})\n",
    "\n",
    "        self.batch_metrics.update({\"loss\": loss})\n",
    "        \n",
    "        for key in [\"loss\"]:\n",
    "            self.meters[key].update(self.batch_metrics[key].item(), self.batch_size)\n",
    "\n",
    "    def on_loader_end(self, runner):\n",
    "        for key in [\"loss\"]:\n",
    "            self.loader_metrics[key] = self.meters[key].compute()[0]\n",
    "        super().on_loader_end(runner)\n",
    "        \n",
    "    def predict_batch(self, batch):\n",
    "        scores = self.model.full_sort_predict(batch)\n",
    "        return scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d462f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/catalyst/core/runner.py:638: UserWarning: No ``ISchedulerCallback/SchedulerCallback`` were found while runner.scheduler is not None.Do you make scheduler step during ``runner.handle_batch``?\n",
      "  \"No ``ISchedulerCallback/SchedulerCallback`` were found \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4b6abe80f04556881f3f75f1e46586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/3 * Epoch (train):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1/3) loss: 8.425694299316406 | lr: 0.001 | map10: 0.0 | map10/std: 0.0 | momentum: 0.9 | ndcg20: 0.0 | ndcg20/std: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab90cbe092ee480dba3f912ef6f69b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/3 * Epoch (valid):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (1/3) loss: 7.862991601562499 | lr: 0.001 | map10: 0.0996933283805847 | map10/std: 0.014003936302949124 | momentum: 0.9 | ndcg20: 0.09756967151165011 | ndcg20/std: 0.01142791823888746\n",
      "* Epoch (1/3) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8234fcf2481b4a849c575e5b1dcd1f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/3 * Epoch (train):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (2/3) loss: 7.723155458831787 | lr: 0.001 | map10: 0.0 | map10/std: 0.0 | momentum: 0.9 | ndcg20: 0.0 | ndcg20/std: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da5c83544c549b7837c0f87e41fd558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/3 * Epoch (valid):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (2/3) loss: 7.437964561462402 | lr: 0.001 | map10: 0.10643977329730987 | map10/std: 0.01454751119646545 | momentum: 0.9 | ndcg20: 0.10653962582349778 | ndcg20/std: 0.011372855087534679\n",
      "* Epoch (2/3) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d30ce1531f4c0eb15fda6cfd350487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/3 * Epoch (train):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (3/3) loss: 7.498140028381348 | lr: 0.001 | map10: 0.0 | map10/std: 0.0 | momentum: 0.9 | ndcg20: 0.0 | ndcg20/std: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0926643b903a4a9780ee9beadae486d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/3 * Epoch (valid):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (3/3) loss: 7.388423115539551 | lr: 0.001 | map10: 0.11017020936012269 | map10/std: 0.016756824204828897 | momentum: 0.9 | ndcg20: 0.11258884879350663 | ndcg20/std: 0.011647774086696348\n",
      "* Epoch (3/3) \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BERT4Rec(n_items=len(item2idx)+1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "engine = dl.DeviceEngine('cpu')\n",
    "hparams = {\n",
    "    \"anneal_cap\": 0.2,\n",
    "    \"total_anneal_steps\": 6000,\n",
    "}\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    dl.NDCGCallback(\"logits\", \"targets\", [20]),\n",
    "    dl.MAPCallback(\"logits\", \"targets\", [10]),\n",
    "    #dl.MRRCallback(\"logits\", \"targets\", [20, 50, 100]),\n",
    "    #dl.HitrateCallback(\"logits\", \"targets\", [20, 50, 100]),\n",
    "    dl.OptimizerCallback(\"loss\", accumulation_steps=1),\n",
    "    dl.EarlyStoppingCallback(\n",
    "        patience=5, loader_key=\"valid\", metric_key=\"map10\", minimize=False\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "runner = RecSysRunner()\n",
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    engine=engine,\n",
    "    hparams=hparams,\n",
    "    scheduler=lr_scheduler,\n",
    "    loaders=loaders,\n",
    "    num_epochs=3,\n",
    "    verbose=True,\n",
    "    timeit=True,\n",
    "    callbacks=callbacks,\n",
    "    #logdir=\"./logs\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe0f14",
   "metadata": {},
   "source": [
    "теперь построим предсказания чтобы наконец посчитать качество от всего этого дела"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "125f9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_runner = RecSysRunner(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9855b304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:04, 22.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>train_interactions</th>\n",
       "      <th>valid_interactions</th>\n",
       "      <th>test_interactions</th>\n",
       "      <th>toppopular_recs</th>\n",
       "      <th>last_popular</th>\n",
       "      <th>ndcg_last_pop</th>\n",
       "      <th>recall_last_pop</th>\n",
       "      <th>ndcg_pop</th>\n",
       "      <th>recall_pop</th>\n",
       "      <th>timediff</th>\n",
       "      <th>last_popular_diff</th>\n",
       "      <th>w2v_preds</th>\n",
       "      <th>w2v_modified_preds</th>\n",
       "      <th>recs_bert4rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>[(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...</td>\n",
       "      <td>[(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...</td>\n",
       "      <td>[(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...</td>\n",
       "      <td>[10440, 15297, 13865, 3734, 4151, 4880, 2657, ...</td>\n",
       "      <td>[2351, 11112, 657, 12623, 1290, 11754, 16361, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>[10440, 15297, 13865, 3734, 4151, 4880, 2657, ...</td>\n",
       "      <td>[760, 4774, 11754, 10214, 5250, 14689, 5693, 1...</td>\n",
       "      <td>[6443, 7210, 12659, 16197, 10942, 14901, 10119...</td>\n",
       "      <td>[3734, 10440, 15297, 13866, 4153, 8637, 4880, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>[(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...</td>\n",
       "      <td>[(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]</td>\n",
       "      <td>[(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4880, 2657, 142, 86...</td>\n",
       "      <td>[15739, 6965, 10772, 16442, 7102, 2296, 10994,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4880, 2657, 142, 86...</td>\n",
       "      <td>[8067, 5315, 3695, 7957, 10811, 4621, 5791, 14...</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4880, 2657, 142, 86...</td>\n",
       "      <td>[3734, 10440, 9728, 13866, 4880, 2659, 4496, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576</td>\n",
       "      <td>[(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...</td>\n",
       "      <td>[(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...</td>\n",
       "      <td>[(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...</td>\n",
       "      <td>[10440, 15297, 3734, 4151, 4880, 142, 9996, 44...</td>\n",
       "      <td>[5311, 7019, 15679, 760, 6033, 5434, 14488, 12...</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[10440, 15297, 3734, 4151, 4880, 142, 9996, 44...</td>\n",
       "      <td>[799, 125, 2858, 1769, 6253, 5250, 15399, 2720...</td>\n",
       "      <td>[3940, 12981, 3182, 13018, 6443, 10440, 1844, ...</td>\n",
       "      <td>[3734, 15297, 10440, 4153, 4880, 142, 9999, 44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>655</td>\n",
       "      <td>[(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...</td>\n",
       "      <td>[(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...</td>\n",
       "      <td>[(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...</td>\n",
       "      <td>[13218, 9628, 1215, 12192, 16152, 7408, 7793, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...</td>\n",
       "      <td>[6185, 8391, 8350, 1131, 14717, 3071, 4223, 88...</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...</td>\n",
       "      <td>[3734, 9728, 10440, 4153, 13866, 4880, 2659, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>[(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...</td>\n",
       "      <td>[(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...</td>\n",
       "      <td>[(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...</td>\n",
       "      <td>[4151, 10440, 9728, 3734, 2657, 13865, 9996, 1...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...</td>\n",
       "      <td>[4880, 4151, 10440, 13865, 2657, 142, 9728, 37...</td>\n",
       "      <td>[13018, 9728, 16166, 14317, 3734, 6455, 3935, ...</td>\n",
       "      <td>[3734, 9728, 15297, 13866, 10440, 4153, 4880, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 train_interactions  \\\n",
       "0       30  [(4740, 2021-06-09, 2), (676, 2021-06-12, 5), ...   \n",
       "1      229  [(11275, 2021-07-01, 3), (4151, 2021-07-01, 3)...   \n",
       "2      576  [(1731, 2021-03-13, 5), (14703, 2021-03-13, 5)...   \n",
       "3      655  [(15942, 2021-07-19, 0), (6273, 2021-07-20, 1)...   \n",
       "4      733  [(4946, 2021-08-07, 5), (5693, 2021-08-07, 5),...   \n",
       "\n",
       "                                  valid_interactions  \\\n",
       "0  [(3031, 2021-08-11, 2), (16484, 2021-08-11, 2)...   \n",
       "1   [(11237, 2021-08-10, 1), (14910, 2021-08-13, 4)]   \n",
       "2  [(3059, 2021-08-11, 2), (956, 2021-08-11, 2), ...   \n",
       "3  [(11899, 2021-08-10, 1), (3343, 2021-08-10, 1)...   \n",
       "4  [(9343, 2021-08-09, 0), (2892, 2021-08-09, 0),...   \n",
       "\n",
       "                                   test_interactions  \\\n",
       "0  [(8584, 2021-08-16, 0), (4181, 2021-08-20, 4),...   \n",
       "1    [(10440, 2021-08-20, 4), (3697, 2021-08-21, 5)]   \n",
       "2  [(4191, 2021-08-17, 1), (7528, 2021-08-19, 3),...   \n",
       "3  [(15051, 2021-08-15, 6), (15423, 2021-08-16, 0...   \n",
       "4  [(4731, 2021-08-17, 1), (5124, 2021-08-17, 1),...   \n",
       "\n",
       "                                     toppopular_recs  \\\n",
       "0  [10440, 15297, 13865, 3734, 4151, 4880, 2657, ...   \n",
       "1  [9728, 10440, 13865, 3734, 4880, 2657, 142, 86...   \n",
       "2  [10440, 15297, 3734, 4151, 4880, 142, 9996, 44...   \n",
       "3  [9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...   \n",
       "4  [9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...   \n",
       "\n",
       "                                        last_popular  ndcg_last_pop  \\\n",
       "0  [2351, 11112, 657, 12623, 1290, 11754, 16361, ...       0.000000   \n",
       "1  [15739, 6965, 10772, 16442, 7102, 2296, 10994,...       0.000000   \n",
       "2  [5311, 7019, 15679, 760, 6033, 5434, 14488, 12...       0.430677   \n",
       "3  [13218, 9628, 1215, 12192, 16152, 7408, 7793, ...       0.000000   \n",
       "4  [4151, 10440, 9728, 3734, 2657, 13865, 9996, 1...       0.000000   \n",
       "\n",
       "   recall_last_pop  ndcg_pop  recall_pop  timediff  \\\n",
       "0              0.0       0.5    0.333333         2   \n",
       "1              0.0       1.0    0.500000         7   \n",
       "2              0.2       0.0    0.000000         3   \n",
       "3              0.0       0.0    0.000000         2   \n",
       "4              0.0       0.0    0.000000         3   \n",
       "\n",
       "                                   last_popular_diff  \\\n",
       "0  [10440, 15297, 13865, 3734, 4151, 4880, 2657, ...   \n",
       "1  [9728, 10440, 13865, 3734, 4880, 2657, 142, 86...   \n",
       "2  [10440, 15297, 3734, 4151, 4880, 142, 9996, 44...   \n",
       "3  [9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...   \n",
       "4  [9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...   \n",
       "\n",
       "                                           w2v_preds  \\\n",
       "0  [760, 4774, 11754, 10214, 5250, 14689, 5693, 1...   \n",
       "1  [8067, 5315, 3695, 7957, 10811, 4621, 5791, 14...   \n",
       "2  [799, 125, 2858, 1769, 6253, 5250, 15399, 2720...   \n",
       "3  [6185, 8391, 8350, 1131, 14717, 3071, 4223, 88...   \n",
       "4  [4880, 4151, 10440, 13865, 2657, 142, 9728, 37...   \n",
       "\n",
       "                                  w2v_modified_preds  \\\n",
       "0  [6443, 7210, 12659, 16197, 10942, 14901, 10119...   \n",
       "1  [9728, 10440, 13865, 3734, 4880, 2657, 142, 86...   \n",
       "2  [3940, 12981, 3182, 13018, 6443, 10440, 1844, ...   \n",
       "3  [9728, 10440, 13865, 3734, 4151, 4880, 2657, 1...   \n",
       "4  [13018, 9728, 16166, 14317, 3734, 6455, 3935, ...   \n",
       "\n",
       "                                       recs_bert4rec  \n",
       "0  [3734, 10440, 15297, 13866, 4153, 8637, 4880, ...  \n",
       "1  [3734, 10440, 9728, 13866, 4880, 2659, 4496, 8...  \n",
       "2  [3734, 15297, 10440, 4153, 4880, 142, 9999, 44...  \n",
       "3  [3734, 9728, 10440, 4153, 13866, 4880, 2659, 1...  \n",
       "4  [3734, 9728, 15297, 13866, 10440, 4153, 4880, ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = MyDataset(ds=joined, num_items=n_items, phase='test',item2idx=item2idx)\n",
    "\n",
    "\n",
    "inference_loader = DataLoader(test_dataset, \n",
    "                              batch_size=joined.shape[0]//100, \n",
    "                              collate_fn=collate_fn_train,)\n",
    "\n",
    "preds = []\n",
    "\n",
    "for prediction in tqdm(runner.predict_loader(loader=inference_loader)):\n",
    "    preds.extend(prediction.detach().cpu().numpy().tolist())\n",
    "    \n",
    "print(len(preds))\n",
    "assert len(preds) == joined.shape[0]\n",
    "\n",
    "joined['preds_bert4rec'] = preds\n",
    "joined['recs_bert4rec'] = joined['preds_bert4rec'].apply(lambda x: np.argsort(-np.array(x))[:30])\n",
    "joined['recs_bert4rec'] = joined['recs_bert4rec'].apply(lambda x: [idx2item[t]-1 for t in x])\n",
    "joined.drop(['preds_bert4rec'],axis=1, inplace=True)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a1a93a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg': 0.15022212457053213, 'recall': 0.0914623246107341}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_recommender(joined, model_preds='recs_bert4rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25a126",
   "metadata": {},
   "source": [
    "небольшой урок из практики по дебага bert4rec. Посмотрите внимательно на head датасета и предположите, почему маленькие метрики?\n",
    "\n",
    "если большие, значит она уже исправлена"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb298f7",
   "metadata": {},
   "source": [
    "## VI. Заглянем внутрь BERT4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71868059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT4Rec(\n",
       "  (item_embedding): Embedding(6592, 64, padding_idx=0)\n",
       "  (position_embedding): Embedding(101, 64)\n",
       "  (trm_encoder): TransformerEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerLayer(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (dense_1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (dense_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerLayer(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (dense_1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (dense_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0ebdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loaders['valid']:\n",
    "    break\n",
    "    \n",
    "model.eval()\n",
    "preds, expl = model.full_sort_predict(batch, return_explanations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35e04031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 6591]),\n",
       " torch.Size([256, 99]),\n",
       " torch.Size([256, 2, 100, 100]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, batch['seq_i'].shape, expl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2421cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_type</th>\n",
       "      <th>title</th>\n",
       "      <th>title_orig</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>for_kids</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>studios</th>\n",
       "      <th>directors</th>\n",
       "      <th>actors</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>film</td>\n",
       "      <td>Поговори с ней</td>\n",
       "      <td>Hable con ella</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>драмы, зарубежные, детективы, мелодрамы</td>\n",
       "      <td>Испания</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Педро Альмодовар</td>\n",
       "      <td>Адольфо Фернандес, Ана Фернандес, Дарио Гранди...</td>\n",
       "      <td>Мелодрама легендарного Педро Альмодовара «Пого...</td>\n",
       "      <td>Поговори, ней, 2002, Испания, друзья, любовь, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2508</td>\n",
       "      <td>film</td>\n",
       "      <td>Голые перцы</td>\n",
       "      <td>Search Party</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>зарубежные, приключения, комедии</td>\n",
       "      <td>США</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Скот Армстронг</td>\n",
       "      <td>Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...</td>\n",
       "      <td>Уморительная современная комедия на популярную...</td>\n",
       "      <td>Голые, перцы, 2014, США, друзья, свадьбы, прео...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10716</td>\n",
       "      <td>film</td>\n",
       "      <td>Тактическая сила</td>\n",
       "      <td>Tactical Force</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>криминал, зарубежные, триллеры, боевики, комедии</td>\n",
       "      <td>Канада</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Адам П. Калтраро</td>\n",
       "      <td>Адриан Холмс, Даррен Шалави, Джерри Вассерман,...</td>\n",
       "      <td>Профессиональный рестлер Стив Остин («Все или ...</td>\n",
       "      <td>Тактическая, сила, 2011, Канада, бандиты, ганг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7868</td>\n",
       "      <td>film</td>\n",
       "      <td>45 лет</td>\n",
       "      <td>45 Years</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>драмы, зарубежные, мелодрамы</td>\n",
       "      <td>Великобритания</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Эндрю Хэй</td>\n",
       "      <td>Александра Риддлстон-Барретт, Джеральдин Джейм...</td>\n",
       "      <td>Шарлотта Рэмплинг, Том Кортни, Джеральдин Джей...</td>\n",
       "      <td>45, лет, 2015, Великобритания, брак, жизнь, лю...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16268</td>\n",
       "      <td>film</td>\n",
       "      <td>Все решает мгновение</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>драмы, спорт, советские, мелодрамы</td>\n",
       "      <td>СССР</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Ленфильм</td>\n",
       "      <td>Виктор Садовский</td>\n",
       "      <td>Александр Абдулов, Александр Демьяненко, Алекс...</td>\n",
       "      <td>Расчетливая чаровница из советского кинохита «...</td>\n",
       "      <td>Все, решает, мгновение, 1978, СССР, сильные, ж...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id content_type                 title      title_orig  release_year  \\\n",
       "0    10711         film        Поговори с ней  Hable con ella        2002.0   \n",
       "1     2508         film           Голые перцы    Search Party        2014.0   \n",
       "2    10716         film      Тактическая сила  Tactical Force        2011.0   \n",
       "3     7868         film                45 лет        45 Years        2015.0   \n",
       "4    16268         film  Все решает мгновение             NaN        1978.0   \n",
       "\n",
       "                                             genres       countries  for_kids  \\\n",
       "0           драмы, зарубежные, детективы, мелодрамы         Испания       NaN   \n",
       "1                  зарубежные, приключения, комедии             США       NaN   \n",
       "2  криминал, зарубежные, триллеры, боевики, комедии          Канада       NaN   \n",
       "3                      драмы, зарубежные, мелодрамы  Великобритания       NaN   \n",
       "4                драмы, спорт, советские, мелодрамы            СССР       NaN   \n",
       "\n",
       "   age_rating   studios         directors  \\\n",
       "0        16.0       NaN  Педро Альмодовар   \n",
       "1        16.0       NaN    Скот Армстронг   \n",
       "2        16.0       NaN  Адам П. Калтраро   \n",
       "3        16.0       NaN         Эндрю Хэй   \n",
       "4        12.0  Ленфильм  Виктор Садовский   \n",
       "\n",
       "                                              actors  \\\n",
       "0  Адольфо Фернандес, Ана Фернандес, Дарио Гранди...   \n",
       "1  Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...   \n",
       "2  Адриан Холмс, Даррен Шалави, Джерри Вассерман,...   \n",
       "3  Александра Риддлстон-Барретт, Джеральдин Джейм...   \n",
       "4  Александр Абдулов, Александр Демьяненко, Алекс...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Мелодрама легендарного Педро Альмодовара «Пого...   \n",
       "1  Уморительная современная комедия на популярную...   \n",
       "2  Профессиональный рестлер Стив Остин («Все или ...   \n",
       "3  Шарлотта Рэмплинг, Том Кортни, Джеральдин Джей...   \n",
       "4  Расчетливая чаровница из советского кинохита «...   \n",
       "\n",
       "                                            keywords  \n",
       "0  Поговори, ней, 2002, Испания, друзья, любовь, ...  \n",
       "1  Голые, перцы, 2014, США, друзья, свадьбы, прео...  \n",
       "2  Тактическая, сила, 2011, Канада, бандиты, ганг...  \n",
       "3  45, лет, 2015, Великобритания, брак, жизнь, лю...  \n",
       "4  Все, решает, мгновение, 1978, СССР, сильные, ж...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv('data/items.csv')\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4f132e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10711: 'Поговори с ней',\n",
       " 2508: 'Голые перцы',\n",
       " 10716: 'Тактическая сила',\n",
       " 7868: '45 лет',\n",
       " 16268: 'Все решает мгновение',\n",
       " 854: 'Северо-Юг',\n",
       " 1468: 'Марья-искусница',\n",
       " 11114: 'Принцесса Лебедь: Пират или принцесса',\n",
       " 9853: 'Лабиринты прошлого',\n",
       " 8604: 'Третья попытка',\n",
       " 3526: 'Код «Красный»',\n",
       " 15056: 'Последний шанс',\n",
       " 4778: 'Три лица',\n",
       " 16429: 'Ярослав Мудрый',\n",
       " 6181: 'Первая встреча, последняя встреча',\n",
       " 15076: 'Бладфест',\n",
       " 2904: 'Первая ведьма',\n",
       " 6881: 'Дитя крови',\n",
       " 14921: 'Баллада о старом оружии',\n",
       " 15261: 'Спящая красавица. Легенда двух королевств: Ледовое шоу',\n",
       " 2635: 'Рождество трех медведей',\n",
       " 3445: 'Смерть девушки',\n",
       " 13729: 'Ангел',\n",
       " 13109: 'Новый парень моей мамы',\n",
       " 15120: 'Зорро',\n",
       " 7325: 'Вдовий пароход',\n",
       " 13910: 'Большая ржака!',\n",
       " 16097: 'Афера века  (с тифлокомментарием)',\n",
       " 2959: 'Любовь зла...',\n",
       " 6318: 'Днепровский ветер. Чары-камыши',\n",
       " 8062: 'Золушка: Полный вперед!',\n",
       " 1705: 'Бабник 2',\n",
       " 7357: 'Выкуп',\n",
       " 15758: 'Караван смерти',\n",
       " 14986: 'Год золотой рыбки',\n",
       " 15702: 'Лев Яшин – Эдуард Стрельцов. Перекрестки…',\n",
       " 41: 'Один шанс из тысячи',\n",
       " 8105: 'Последняя суббота',\n",
       " 1622: 'Тайное окно',\n",
       " 4180: 'Миссия Выполнима 2',\n",
       " 6677: 'Да здравствует Франция!',\n",
       " 701: 'Лара Крофт: Расхитительница гробниц 2 – Колыбель жизни',\n",
       " 6003: 'Рождество',\n",
       " 5133: 'Шлюхи и невесты',\n",
       " 955: 'Веселая ферма',\n",
       " 561: 'План побега',\n",
       " 7308: 'Дивергент',\n",
       " 11619: 'Эд Вуд',\n",
       " 4358: 'Тело',\n",
       " 9787: 'Реинкарнация',\n",
       " 11593: 'Затащи меня в Ад',\n",
       " 10111: 'Андрей Тарковский. Кино как молитва',\n",
       " 13317: 'Бронсон',\n",
       " 5780: 'Теория хаоса',\n",
       " 4066: 'Праздник непослушания',\n",
       " 9141: 'Давай займемся сексом',\n",
       " 8953: 'Битва у Красной скалы',\n",
       " 149: 'Разлом времени',\n",
       " 586: 'Медный всадник России',\n",
       " 6844: 'Голоса за кадром',\n",
       " 830: 'Бетховен 2',\n",
       " 8447: 'Клуб «Кастет»',\n",
       " 9419: 'Скиф',\n",
       " 12245: 'Танцующая в темноте',\n",
       " 722: 'Приятель',\n",
       " 14253: 'Три маленьких кошки',\n",
       " 2110: 'Река Патука. Гондурас',\n",
       " 12894: 'Народ Инуи. Арктика',\n",
       " 4550: 'Страх',\n",
       " 5456: 'Сабрина (субтитры)',\n",
       " 4547: 'КION. Презентация онлайн-кинотеатра. 19 апреля 2021 года.',\n",
       " 10643: 'Я и ты',\n",
       " 6977: 'Чужая ненависть',\n",
       " 10955: 'Три истории',\n",
       " 4365: 'Хэткэт',\n",
       " 10871: 'Женёк',\n",
       " 3965: 'Уайат Сенак разрулит',\n",
       " 4045: 'Босс',\n",
       " 2662: 'Пакт',\n",
       " 5297: 'Папараца',\n",
       " 4084: 'Числа',\n",
       " 8434: 'Застывшие депеши',\n",
       " 11242: 'Так далеко, так близко',\n",
       " 10798: 'Приказ вернуться живым (на казахском языке)',\n",
       " 8324: 'Только о любви',\n",
       " 6175: 'Найти убийцу',\n",
       " 16045: 'The Pingu Show',\n",
       " 1314: 'КТО ТЫ?!',\n",
       " 10519: 'Кто поймал букет невесты',\n",
       " 10950: 'Начни дома',\n",
       " 9821: 'Шпагат с нуля',\n",
       " 9080: 'Сержант милиции',\n",
       " 16139: 'Эшелон',\n",
       " 5845: 'Верь мне',\n",
       " 7749: 'Безумный ноябрь',\n",
       " 8818: 'Не бойся, я с тобой!',\n",
       " 6883: 'Итальянская кухня с Сильвией Коллока',\n",
       " 16172: 'Лишняя кожа',\n",
       " 2074: 'Посредник',\n",
       " 2876: 'Расплата за любовь',\n",
       " 3768: 'Без обид',\n",
       " 15127: 'Две судьбы',\n",
       " 1575: 'Охотники за искусством',\n",
       " 13884: 'Супер Айза',\n",
       " 4573: 'ДаЁшь молодЁжь! Дайджесты',\n",
       " 10340: 'В блюзе только Бесси',\n",
       " 6992: 'Уитни Каммингс. Здравствуйте, я ваша девушка',\n",
       " 14804: 'Криминальное чтиво',\n",
       " 6539: 'Как меня зовут',\n",
       " 7841: 'Седьмой джинн',\n",
       " 14435: 'Инфекция',\n",
       " 13831: 'Крутые яйца',\n",
       " 13815: 'Убежище дьявола',\n",
       " 10453: '45 секунд',\n",
       " 12898: 'Романтики «303»',\n",
       " 1964: 'Занимательная химия',\n",
       " 6914: 'Королева пчел',\n",
       " 6978: '[4k] Дора и Затерянный город',\n",
       " 10017: 'Парадокс Элис',\n",
       " 5317: 'Йога для начинающих. Тренировка дома за 15 минут',\n",
       " 6533: 'Веселые расплюевские дни',\n",
       " 1614: 'Право на выстрел',\n",
       " 10146: 'Танцы на крыше',\n",
       " 1367: 'Огненная Кэссиди',\n",
       " 4069: 'Моя старшая сестра',\n",
       " 16396: 'Однажды в пустыне',\n",
       " 10063: 'Ленивое платье',\n",
       " 2244: 'Невеста монстра',\n",
       " 2153: 'Третья звезда',\n",
       " 12191: 'Назад в будущее. Часть 2',\n",
       " 4661: 'Переполох на районе',\n",
       " 1652: 'Башня смерти',\n",
       " 6232: 'Девять дней одного года',\n",
       " 6521: 'Брачная ночь',\n",
       " 12737: 'Таймлесс. Рубиновая книга (с тифлокомментарием)',\n",
       " 12478: 'Мара. Пожиратель снов',\n",
       " 12409: 'Василиса Прекрасная',\n",
       " 16235: 'Плохие парни',\n",
       " 15562: 'Зависимость',\n",
       " 10974: 'Близнецы',\n",
       " 7114: 'Время быть Жестче',\n",
       " 16492: 'Частный покер',\n",
       " 4363: 'Свадебный угар',\n",
       " 7307: 'Борат',\n",
       " 6699: 'Как отделаться от парня за 10 дней',\n",
       " 2134: 'Маленький принц',\n",
       " 2817: 'Охотники за привидениями',\n",
       " 12439: 'Одноклассники 2',\n",
       " 6570: 'Непристойное воздействие 2',\n",
       " 4723: 'Притяжение',\n",
       " 9179: 'Тренер Картер',\n",
       " 14177: 'Астерикс и тайное зелье',\n",
       " 10994: 'Легенда о коловрате',\n",
       " 3509: 'Комната желаний',\n",
       " 12057: 'Пираты карибского моря: На странных берегах',\n",
       " 1934: 'Атлантида: Затерянный мир',\n",
       " 11585: 'Франкенвини',\n",
       " 9359: 'Большая афера',\n",
       " 13915: 'Вперёд',\n",
       " 12934: 'Чудачества любви не помеха! Положись на меня',\n",
       " 6720: 'Терминатор',\n",
       " 979: 'Братья медведи: Тайна трёх миров',\n",
       " 7460: 'Дорога',\n",
       " 13169: 'Эйфория',\n",
       " 5714: 'Рождественский коттедж',\n",
       " 13479: 'Симпатичное совершенство',\n",
       " 2753: '[4К] Уникальные скульптуры, искусство Асматов. Западное Папуа',\n",
       " 5173: '[4К] Монои Таити. Французская Полинезия',\n",
       " 6731: \"[4К] Спокойные воды Бэ Д'юпи. Новая Каледония\",\n",
       " 14206: 'Под кайфом и в смятении',\n",
       " 16313: 'Я тоже хочу',\n",
       " 747: 'Охотник на монстров',\n",
       " 13500: 'Пипец',\n",
       " 13933: 'Факап или Хуже не бывает',\n",
       " 8822: 'Концерт группа «Чайф» 12.12.2020',\n",
       " 14345: 'Бастард',\n",
       " 4088: 'Спуск',\n",
       " 2041: 'Беги, если дела будут плохи',\n",
       " 258: 'Танец острова Нука Хива. Французская Полинезия',\n",
       " 15463: 'Обучение орангутангов. Индонезия',\n",
       " 11783: 'Ералаш выпуск №18',\n",
       " 8832: 'Медитация орангутана',\n",
       " 8588: 'Рождество в шоколаде',\n",
       " 10879: 'Зов джунглей',\n",
       " 2558: 'Добро пожаловать в капкан',\n",
       " 2563: 'Cirque du Soleil: Сказочный мир',\n",
       " 5494: 'Болеро-17',\n",
       " 5592: 'На дальних рубежах',\n",
       " 15135: 'Служба новостей',\n",
       " 12255: 'Две жизни',\n",
       " 15482: 'Команда Дино',\n",
       " 5552: 'Адвокат дьявола',\n",
       " 16260: 'Подмена в один миг',\n",
       " 3762: 'Счастливый шанс',\n",
       " 1040: 'Миниатюрист',\n",
       " 7846: 'LEGO City представляет: Космические неприятности',\n",
       " 15676: 'Неугомонные цыплята',\n",
       " 12481: 'Здоровая спина',\n",
       " 13609: 'Опыт реконструкции',\n",
       " 5688: 'Дорога домой',\n",
       " 9135: 'Тегеран-43',\n",
       " 15209: 'Реквием для свидетеля',\n",
       " 4880: 'Афера',\n",
       " 7391: 'Игрушки',\n",
       " 14654: 'После правды: Дезинформация и цена фейк ньюс',\n",
       " 3630: 'Любовь – это идеальное преступление',\n",
       " 6197: 'Глаз шторма',\n",
       " 11195: 'Подарок',\n",
       " 15128: 'Вы чье, старичье?',\n",
       " 16467: 'Видеть музыку',\n",
       " 11042: 'Пациент без имени',\n",
       " 8805: 'Отроки во Вселенной',\n",
       " 16354: 'Хит',\n",
       " 8085: 'Дом вверх дном',\n",
       " 2034: '[4k] День сурка',\n",
       " 5205: 'Дрессировщики',\n",
       " 11015: 'Не укради. Возвращение святыни',\n",
       " 7746: 'Говорит Москва',\n",
       " 2111: 'Необыкновенное путешествие Мишки Стрекачева',\n",
       " 14944: 'Дети солнца',\n",
       " 8037: 'Проявление',\n",
       " 15935: 'Жиросжигающий интенсив HIIT. Выпуск 7',\n",
       " 2243: 'Санкт-Петербургская капелла',\n",
       " 10130: 'Встреча с мечтой',\n",
       " 10709: 'Варварины свадьбы',\n",
       " 14351: 'Порочная страсть',\n",
       " 14813: 'Пираты! Банда неудачников',\n",
       " 5010: 'Девушка, которая слишком много знала',\n",
       " 8697: 'Бойфренд на Рождество',\n",
       " 1759: 'Мрачные небеса',\n",
       " 9347: 'После нашей эры',\n",
       " 8451: 'Тень звезды (жестовым языком)',\n",
       " 7907: 'Гусарская баллада',\n",
       " 4916: 'У меня все нормально',\n",
       " 1211: 'Синдром недосказанности',\n",
       " 960: 'Супер Баха',\n",
       " 9914: 'Присягнувшая тьме',\n",
       " 4478: 'Я люблю',\n",
       " 7024: 'Стартрек 2: Гнев Хана',\n",
       " 3902: 'Железная хватка',\n",
       " 4834: 'Уилсон',\n",
       " 14648: 'Команда «А»',\n",
       " 235: 'Дрянные девчонки',\n",
       " 10557: 'Несносный дед',\n",
       " 9518: 'Последний отпуск',\n",
       " 3343: 'Ла-ла ленд',\n",
       " 4967: 'Следи за дорогой',\n",
       " 1735: 'Форсаж 8',\n",
       " 10959: 'Таинственный лес (2004)',\n",
       " 8083: 'Спящая красавица',\n",
       " 10337: 'Тернер и Хуч',\n",
       " 15434: 'Однажды в Ирландии',\n",
       " 6265: 'Святая Джуди',\n",
       " 11017: 'Искусственный интеллект и мы',\n",
       " 11436: 'Моя горячая женушка',\n",
       " 7235: 'Человек дождя',\n",
       " 15587: 'Вестсайдская история',\n",
       " 345: 'Однажды... Тарантино',\n",
       " 624: 'Солнце в ночи',\n",
       " 231: 'Опасная миссия',\n",
       " 247: 'Дворецкий',\n",
       " 12529: 'Горячие сексуальные девушки из женского общества',\n",
       " 15850: '[4К] Вид сверху. ЮАР - На спине дракона',\n",
       " 1155: 'Маленькая Вера',\n",
       " 1836: 'История Дэвида Копперфильда',\n",
       " 14601: 'Штамм Андромеда',\n",
       " 14024: 'Спящая принцесса',\n",
       " 15124: 'Виктория и Абдул',\n",
       " 6609: 'Доза счастья',\n",
       " 5210: 'Альдабра.Путешествие к таинственному острову',\n",
       " 1179: 'Ограбление с ограничениями',\n",
       " 7209: 'Повелитель драконов',\n",
       " 849: 'Дебошир',\n",
       " 15345: 'Быстрее, чем кролики',\n",
       " 11565: 'Ева',\n",
       " 3919: 'Форт Теремба. Новая Каледония',\n",
       " 15726: 'Ералаш выпуск №15',\n",
       " 5091: '[4К] Наветренные острова – жемчужина Полинезии',\n",
       " 6200: 'Зовите меня Мэттью',\n",
       " 4985: 'Реинкарнация: Пришествие дьявола',\n",
       " 1433: 'Судьба диверсанта',\n",
       " 9635: 'В поисках золота',\n",
       " 14477: 'Любить человека',\n",
       " 15321: 'Волшебники двора',\n",
       " 14505: 'Колобанга',\n",
       " 13607: 'Я все помню',\n",
       " 6513: 'Счастливый билет',\n",
       " 12330: 'Звёздный охотник',\n",
       " 6293: 'Год кролика',\n",
       " 9322: 'Красиво жить не запретишь',\n",
       " 5207: 'Техноигрушки',\n",
       " 224: 'Пингу в городе',\n",
       " 9480: 'LEGO City Представляет: Когда каркает ворон',\n",
       " 1868: 'Айдар',\n",
       " 3901: 'Красота лица',\n",
       " 2790: 'Табата на все тело',\n",
       " 1224: 'Вэнди',\n",
       " 4196: 'Припять',\n",
       " 809: 'Красная палатка',\n",
       " 10310: 'Чудо-мелодии',\n",
       " 105: 'Правосудие',\n",
       " 1084: 'Механизмы Да Винчи',\n",
       " 15875: 'Консуни',\n",
       " 10629: 'Сигнал',\n",
       " 13720: 'Дядюшка Ау',\n",
       " 2036: 'Светофор',\n",
       " 13747: 'Буду помнить',\n",
       " 2643: 'Сколько ты стоишь?',\n",
       " 6723: 'Альпинисты',\n",
       " 9847: 'Мафия: Игра на выживание',\n",
       " 343: 'Дневник горничной',\n",
       " 14033: 'Капитан Саблезуб и сокровища Лама Рама',\n",
       " 14785: 'Заклятье. Наши дни',\n",
       " 10603: 'Профессионал',\n",
       " 14765: 'Спасатели Малибу. Расширенная версия',\n",
       " 1943: 'Летняя поездка к морю',\n",
       " 515: 'Кочубей',\n",
       " 14411: 'Соло на саксофоне',\n",
       " 2108: 'Где 042?',\n",
       " 3316: 'Михайло Ломоносов',\n",
       " 6788: 'Варавва',\n",
       " 8640: 'Хрусталев, машину!',\n",
       " 12732: 'Ошибки любви',\n",
       " 11351: 'Любовь и долги',\n",
       " 1074: '[4k] Настоящие боссы',\n",
       " 10417: 'Стукач',\n",
       " 8307: 'Люпен III: Замок Калиостро',\n",
       " 550: 'Hot Wheels. Мегатрасса',\n",
       " 6336: 'Хроника Валаамского монастыря',\n",
       " 8726: '8 комнат. Ключи Есенина',\n",
       " 3674: 'Зоя Космодемьянская',\n",
       " 282: 'Пентхаус (на Киргизском языке)',\n",
       " 14320: 'Коллекционер 2',\n",
       " 15856: 'Новые похождения Швейка',\n",
       " 5843: 'Как Петя Пяточкин слоников считал',\n",
       " 6043: 'Санта Клаус 2',\n",
       " 6604: 'Класс коррекции',\n",
       " 6966: 'Стартрек 7: Поколения',\n",
       " 9665: 'Последний герой',\n",
       " 7311: 'Очень плохие девчонки',\n",
       " 4639: 'Вышибала',\n",
       " 11267: 'Гангста Love',\n",
       " 11244: 'Репортёрша',\n",
       " 12583: 'Арестант no name',\n",
       " 11287: 'Бемби',\n",
       " 9842: 'Невидимый гость',\n",
       " 12463: 'Студентка по вызову',\n",
       " 10226: 'Секс-наркоманы',\n",
       " 7659: 'Крик тишины',\n",
       " 5436: '[4К] Пещеры острова Макатеа. Французская Полинезия',\n",
       " 4276: '[4К] Купание слона. Индонезия',\n",
       " 13289: 'Анаконда 4: Кровавый след',\n",
       " 15343: 'Непропеченный',\n",
       " 8979: 'Любовь в большом городе 2',\n",
       " 8566: 'Малышка с характером',\n",
       " 15196: 'Волки и овцы. Безумное превращение',\n",
       " 13318: 'Добрыня Никитич и Змей Горыныч',\n",
       " 11948: 'Опасный груз',\n",
       " 4801: 'Вспомни меня',\n",
       " 2234: '[4К] Традиционная охота инуитов',\n",
       " 8066: 'Штетл',\n",
       " 1821: 'Спроси у пыли',\n",
       " 11074: 'Галлоуз Хилл',\n",
       " 14214: 'Фитнес. Фильм о фильме',\n",
       " 1596: 'Я ненавижу Сьюзи',\n",
       " 1612: 'Женщина его мечты',\n",
       " 6997: 'Дневник Луизы Ложкиной',\n",
       " 1457: 'Осиное гнездо',\n",
       " 9229: '18-14',\n",
       " 2315: 'Аметистовая сережка',\n",
       " 11723: 'Жизнь рассудит',\n",
       " 7309: 'Допустимый риск',\n",
       " 16311: 'Клондайк',\n",
       " 1977: 'LTC English. Learn. Teach. Create',\n",
       " 10656: 'Медитации для жизни',\n",
       " 11526: 'Психология питания',\n",
       " 2692: 'Клео и Кукин. Видеоклипы',\n",
       " 12049: 'Корея. 5000 лет выживания',\n",
       " 4425: 'Громовы. Дом надежды',\n",
       " 10344: 'Объяснение в любви',\n",
       " 15498: 'Маленькие трагедии',\n",
       " 5058: 'Пингвиненок Пороро',\n",
       " 5116: 'Инспектор Гулл',\n",
       " 1346: 'Инквизитор (жестовым языком)',\n",
       " 11373: 'Ирина Аллегрова - караоке',\n",
       " 3671: 'Google Диск. Знакомство',\n",
       " 3877: 'В поисках капитана Гранта',\n",
       " 14517: 'Ловушка',\n",
       " 4878: 'Эхо террора',\n",
       " 415: 'Приступить к ликвидации',\n",
       " 13964: 'Оденься к свадьбе: Ланкашир',\n",
       " 6950: 'Как закалялась сталь',\n",
       " 7546: 'Это любовь',\n",
       " 7752: 'Приключения Паровозика Шонни',\n",
       " 4713: 'Большая секунда',\n",
       " 10419: 'Крошка Молли',\n",
       " 10965: 'Женюсь на первой встречной',\n",
       " 2996: 'Добро пожаловать в Коллинвуд',\n",
       " 14586: 'Модная штучка',\n",
       " 6045: 'Дорогой мой человек',\n",
       " 3242: '713-й просит посадку',\n",
       " 16214: 'Бегущая по волнам',\n",
       " 4874: 'Наградить (посмертно)',\n",
       " 14527: 'Роковая связь',\n",
       " 2001: 'Молодой Годар',\n",
       " 8973: 'Сельский врач',\n",
       " 7508: 'Леонардо: Миссия Мона Лиза',\n",
       " 11361: 'Приключения мышонка Переса 2',\n",
       " 3579: 'Местные',\n",
       " 3643: 'Спасти рядового Переса',\n",
       " 5685: 'Жизнь на повторе',\n",
       " 5033: 'Верность',\n",
       " 10947: 'Асоциальная сеть',\n",
       " 3529: 'Я не уйду',\n",
       " 4812: 'Без срока давности. Да судимы будете!',\n",
       " 1975: 'В начале игры',\n",
       " 5992: 'Динамический пилатес. Часть 1',\n",
       " 10460: 'Полет домой',\n",
       " 10434: 'Проклятый дом 3',\n",
       " 9868: 'Зависимые',\n",
       " 7370: 'Летний сад. Три эпохи',\n",
       " 7824: 'Сарай',\n",
       " 192: 'Машина, убивающая плохих',\n",
       " 12231: 'Папа-досвидос',\n",
       " 8007: 'Призраки войны (с тифлокомментарием)',\n",
       " 11174: 'Американский психопат',\n",
       " 14542: 'Жених с того света',\n",
       " 1643: 'Сладкий сок внутри травы',\n",
       " 1245: 'В поисках Йети (жестовым языком)',\n",
       " 12499: 'Форсаж 5',\n",
       " 7827: 'Кунг-фу Панда 3',\n",
       " 3222: 'Всегда сияй',\n",
       " 16087: 'Убийство в Восточном экспрессе',\n",
       " 8617: 'Золото',\n",
       " 13653: '102 далматинца',\n",
       " 14916: 'Тёмное наследие',\n",
       " 7665: 'Мольер',\n",
       " 3404: 'РЭД',\n",
       " 11846: 'Если я останусь',\n",
       " 7970: 'Голодные сердца',\n",
       " 7453: 'На линии огня',\n",
       " 12812: 'От семьи не убежишь',\n",
       " 6876: 'Знамение',\n",
       " 7653: 'Внутри меня 2',\n",
       " 7671: 'Джон Уик',\n",
       " 9435: 'Абориген',\n",
       " 13678: 'Медвежатники',\n",
       " 9409: 'Всегда',\n",
       " 11426: 'Шарада',\n",
       " 5408: 'Гангстеры',\n",
       " 6588: 'Сказки Серого Волка',\n",
       " 3141: '4 лица Моны Лизы',\n",
       " 13580: 'Жизнь за год',\n",
       " 11191: 'Про уродов и людей',\n",
       " 9448: '8 новогодних короткометражек',\n",
       " 13000: 'Что скрывает ложь',\n",
       " 12715: 'Она',\n",
       " 1999: 'Метод Гринберри',\n",
       " 9066: 'Верветка и медвежий павиан. Южная Африка',\n",
       " 12506: 'Защита белых носорогов. Южная Африка',\n",
       " 3668: 'Лёгкие Средиземного моря. Корсика',\n",
       " 11796: 'Другое небо',\n",
       " 1646: 'Девушка грез',\n",
       " 12228: 'Волк с Уолл-стрит',\n",
       " 12594: 'Бердэн (субтитры)',\n",
       " 14633: 'Джетт',\n",
       " 669: 'Сумеречная зона',\n",
       " 15186: 'Плоть и кости',\n",
       " 8635: 'Мирт обыкновенный',\n",
       " 6901: 'Десять негритят',\n",
       " 9376: 'Пикник у Висячей скалы',\n",
       " 13983: 'Крепость',\n",
       " 7215: 'Блэк Джек 21',\n",
       " 15586: 'Не хочу тебя терять',\n",
       " 1177: 'Иду на грозу',\n",
       " 14198: 'Моонзунд',\n",
       " 13780: 'Последние дни планеты Земля',\n",
       " 7380: 'Пересекая черту',\n",
       " 11014: '2 Brothers On The 4Th Floor - караоке',\n",
       " 10271: 'Фабрика - караоке',\n",
       " 4951: 'Слушать в отсеках',\n",
       " 2955: 'Сто первый',\n",
       " 9464: 'Суфлер',\n",
       " 8238: 'Приказ',\n",
       " 11106: 'Териус у меня за спиной',\n",
       " 11439: 'Бронзовая птица',\n",
       " 12881: 'Мультипедия времени',\n",
       " 8304: 'Зона дискомфорта',\n",
       " 15399: 'Бывшие',\n",
       " 4226: 'Внимание: смертельно опасно',\n",
       " 12391: 'Вожделенное питье',\n",
       " 373: 'В джазе только девушки',\n",
       " 417: 'Безумные преподы',\n",
       " 12445: 'Третья персона',\n",
       " 4835: 'Танец реальности',\n",
       " 10714: 'Джеки в царстве женщин',\n",
       " 11937: 'Заезжий молодец',\n",
       " 9410: 'Скажи_Лео',\n",
       " 871: 'Девятая',\n",
       " 9735: 'Верьте мне, люди',\n",
       " 10215: 'Спитак',\n",
       " 374: 'Петрович',\n",
       " 7775: 'Колесо любви',\n",
       " 9177: 'Солнце тоже звезда',\n",
       " 1384: 'Город на границе',\n",
       " 7220: 'Темное зеркало',\n",
       " 842: 'Девушки бывают разные',\n",
       " 14401: 'Английский язык для самых маленьких',\n",
       " 10457: 'Оккупация',\n",
       " 5435: 'Иван да Марья',\n",
       " 10923: 'Валера',\n",
       " 13008: 'Если это случится с тобой',\n",
       " 16069: 'Томас и его друзья: Кругосветное путешествие',\n",
       " 6463: 'Мальчики возвращаются',\n",
       " 10998: 'Последний переход',\n",
       " 12384: 'Старики-полковники',\n",
       " 8608: 'К-19',\n",
       " 2532: 'Хантер Киллер',\n",
       " 207: 'Замок с привидениями',\n",
       " 10902: 'Черное воскресенье',\n",
       " 13239: 'Черта',\n",
       " 4816: '[4k] Шафер напрокат',\n",
       " 9971: 'Я объявляю войну',\n",
       " 3505: 'Дети сексу не помеха',\n",
       " 5493: 'Балканский рубеж (с тифлокомментарием)',\n",
       " 33: 'Встречи с учеными',\n",
       " 8035: 'Смеситель',\n",
       " 15129: 'Франц',\n",
       " 1087: 'Что творят мужчины! (с тифлокомментарием)',\n",
       " 7094: 'Агентство «Мечта» (с тифлокомментарием)',\n",
       " 13688: 'Джоди Моди и нескучное лето',\n",
       " 109: 'У холмов есть глаза 2',\n",
       " 8838: 'Я – начало',\n",
       " 4519: 'Эвротико 11',\n",
       " 3189: 'Параллельные миры',\n",
       " 3943: 'Ч/Б',\n",
       " 10055: 'Я буду рядом',\n",
       " 5533: 'Титаник',\n",
       " 10694: 'Арвентур',\n",
       " 6454: 'Неаполитанские истории',\n",
       " 5859: 'Прямая и явная угроза',\n",
       " 15991: 'Собачья жизнь',\n",
       " 11189: 'Гарриет',\n",
       " 12421: 'Аладдин',\n",
       " 10085: 'Геркулес',\n",
       " 13185: 'Хороший динозавр',\n",
       " 8046: 'Сила девяти богов',\n",
       " 3472: 'Не могу сказать прощай',\n",
       " 6468: 'Выжившая',\n",
       " 8278: 'Искусство соблазнения',\n",
       " 1878: 'Конец сезона',\n",
       " 8033: 'Вспомни всё',\n",
       " 7869: 'Полёт длиною в жизнь',\n",
       " 3743: 'Зимняя лягушка',\n",
       " 1142: 'Город призраков (субтитры)',\n",
       " 14836: 'Ералаш выпуск №25',\n",
       " 957: 'Осенью 41-го',\n",
       " 16134: '[4К] Природное богатство Корсики',\n",
       " 14687: 'Опасный элемент',\n",
       " 5081: 'Однажды в Риме',\n",
       " 3011: 'Легенды саванны',\n",
       " 5011: 'Женские грезы',\n",
       " 3917: 'Родина',\n",
       " 4698: 'Новый Папа',\n",
       " 13892: 'Новости маленького городка',\n",
       " 16184: 'История одного преступления',\n",
       " 3425: 'Бибика',\n",
       " 2939: 'Казус Кукоцкого (12 серий)',\n",
       " 11569: 'Маруся (2010)',\n",
       " 6634: 'Территория Йоги',\n",
       " 12895: 'Изабелла',\n",
       " 12886: 'Два силуэта на закате солнца',\n",
       " 11532: 'Йога старт',\n",
       " 63: 'Пробуди силу Духа',\n",
       " 10466: 'Адъютант его превосходительства',\n",
       " 8611: 'Уроки тетушки совы',\n",
       " 6578: 'Три товарища',\n",
       " 15304: 'Граф Монте-Кристо',\n",
       " 6742: 'Пакет тренировок \"hiitовое тело\" от hiitworks',\n",
       " 3457: 'Буду рада, если ты умрешь',\n",
       " 4331: 'Оранжевая корова',\n",
       " 6036: 'Алхимик',\n",
       " 7622: 'Ловушка для полтергейста',\n",
       " 2099: 'Последний из Магикян',\n",
       " 13265: 'Оттенки греха',\n",
       " 1698: 'Бумажки',\n",
       " 3454: 'Луис навсегда',\n",
       " 300: 'Ёлки\\xa03',\n",
       " 9825: 'Остров везения',\n",
       " 10114: 'Кровавый Санта',\n",
       " 13135: 'Откровения',\n",
       " 2246: 'Голубой лед',\n",
       " 204: 'Формула счастья',\n",
       " 3272: 'Аферисты поневоле',\n",
       " 10332: 'Карты, деньги и слова',\n",
       " 3921: 'Мой ангел',\n",
       " 7143: 'Мой сын',\n",
       " 16163: 'Конек-Горбунок',\n",
       " 3183: 'Второй шанс',\n",
       " 2541: 'Импульсо: Больше, чем фламенко',\n",
       " 214: 'Опасные гастроли',\n",
       " 6631: 'Пиковая дама',\n",
       " 4769: 'Это я, это я!',\n",
       " 5594: 'Самира Мустафаева. Техника безопасности и рекомендации',\n",
       " 757: 'Забавы молодых',\n",
       " 5451: 'Медитации и баланс Yoga Meditation. Выпуск 6',\n",
       " 2859: 'Дорога на Бали',\n",
       " 1662: 'Русский балет',\n",
       " 9331: '20-летние старики (на киргизском языке)',\n",
       " 8883: 'Ты меня не бойся',\n",
       " 139: 'Младенец',\n",
       " 13805: 'Дом-монстр',\n",
       " 9009: 'Идеальная жена',\n",
       " 5000: 'Море внутри',\n",
       " 6683: 'Одна',\n",
       " 6070: 'В фокусе',\n",
       " 15222: 'Тебе нужен щенок?',\n",
       " 10431: 'Пластик (жестовым языком)',\n",
       " 1645: 'Глеб Архангельский. Тайм-менеджмент: как заставить себя измениться',\n",
       " 10450: 'Уральская рябинушка',\n",
       " 5216: 'Репетиция оркестра',\n",
       " 10401: 'Стартрек 1: Фильм',\n",
       " 15534: 'Лара Крофт: Расхитительница гробниц',\n",
       " 14567: 'Новый Человек-паук',\n",
       " 10924: 'Песнь дьявола',\n",
       " 16224: 'Ворошиловский стрелок',\n",
       " 14791: 'Тройной форсаж: Токийский дрифт',\n",
       " 6572: 'Седьмой сын',\n",
       " 5847: 'Звёздные войны: Империя наносит ответный удар',\n",
       " 10115: 'Доктор Ноу',\n",
       " 10515: 'Мирай из будущего',\n",
       " 8450: 'Хочу заняться любовью! 2',\n",
       " 7925: 'Сэлинджер',\n",
       " 6365: 'Кошки-мышки',\n",
       " 2861: '[4К] Эскимосская собака киммик, верный товарищ. Арктика',\n",
       " 7572: '[4К] Пироги - символ асматов. Западное Папуа',\n",
       " 2323: 'Форсаж: Хоббс и Шоу',\n",
       " 4823: 'Маменькины сынки (отреставрированная версия)',\n",
       " 10313: 'Куш собачий',\n",
       " 7280: 'Бумер',\n",
       " 14964: 'Суперменеджер, или Мотыга судьбы',\n",
       " 14115: 'Индиго',\n",
       " 11308: 'Какао. Гондурас',\n",
       " 4206: 'Народ тавака. Гондурас',\n",
       " 8187: 'Лазурный берег',\n",
       " 5335: 'Солнцекруг',\n",
       " 11598: '[4К] Страж побережья',\n",
       " 12863: 'Песня Любви (субтитры)',\n",
       " 11408: 'Три товарища',\n",
       " 14257: 'Докопаться до могилы',\n",
       " 8253: 'Питер. Лето. Любовь',\n",
       " 4839: 'Долл',\n",
       " 166: 'Корпорация',\n",
       " 12589: 'Власть в ночном городе. Книга вторая: Призрак',\n",
       " 3963: 'Сплетница (2007)',\n",
       " 5905: 'Умная тарелка',\n",
       " 8944: 'Расплата за счастье',\n",
       " 1914: 'Неравный брак',\n",
       " 7340: 'Лекарство для бабушки',\n",
       " 14857: 'Мать и мачеха (2012)',\n",
       " 7840: 'Рацион на 1400 ккал',\n",
       " 9899: 'Твой рельеф в зале',\n",
       " 3530: 'Господа офицеры',\n",
       " 10839: 'Рокировка',\n",
       " 9883: 'Наводнение',\n",
       " 3726: '1812',\n",
       " 14047: 'Кухня за 1 минуту',\n",
       " 2757: 'World Music Charts',\n",
       " 6722: 'Дурь',\n",
       " 2361: 'Притворщики',\n",
       " 4242: 'Викинги',\n",
       " 14705: 'Таинственный сад',\n",
       " 15262: 'От сердца к сердцу',\n",
       " 4642: 'У реки два берега',\n",
       " 2715: 'Гражданин начальник',\n",
       " 2732: 'Детский сад поэзии',\n",
       " 11281: 'Крыша',\n",
       " 14321: 'Блюбарелла: Супервумен',\n",
       " 7243: 'Виринея',\n",
       " 9504: 'Забытые истории',\n",
       " 2327: 'Жестокие мечты',\n",
       " 6535: 'Александра (Саша)',\n",
       " 5613: 'Фокстрот',\n",
       " 9651: 'ДАГ',\n",
       " 2033: 'Девичий источник',\n",
       " 5477: 'Спасите Колю!',\n",
       " 2668: 'Гараш',\n",
       " 2868: 'Героические лузеры',\n",
       " 13115: '[4k] Маленькие женщины',\n",
       " 3602: 'Всё дело в брате',\n",
       " 15147: 'Имя',\n",
       " 13072: 'Форсаж Диабло',\n",
       " 11326: 'Хищники',\n",
       " 7022: 'Заповедник Кивач',\n",
       " 4439: 'Маленький-маленький ветер',\n",
       " 15817: 'М – убийство',\n",
       " 5548: 'Путешествие в Италию',\n",
       " 6289: 'Рэмбо: Первая кровь',\n",
       " 11534: 'Комета Галлея',\n",
       " 10807: 'Вий (с тифлокомментарием)',\n",
       " 9022: 'Июльский дождь',\n",
       " 15655: 'Экстрасенс 2: Лабиринты разума',\n",
       " 15447: 'Дух живого леса',\n",
       " 12468: 'Рейс первый, рейс последний',\n",
       " 12447: 'Иван Царевич и Серый Волк (жестовым языком)',\n",
       " 2437: 'Мужчины в большом городе\\xa02 (жестовым языком)',\n",
       " 10307: 'Матильда (с тифлокомментарием)',\n",
       " 10760: 'Еще один мальчишник (с тифлокомментарием)',\n",
       " 4953: 'Час призраков',\n",
       " 16102: 'Съемки в Палермо',\n",
       " 12695: 'Мулен Руж',\n",
       " 8757: 'Дежурный папа',\n",
       " 10012: 'Спайдервик: Хроники',\n",
       " 8736: 'Шафер напрокат',\n",
       " 4709: 'Монстры на каникулах',\n",
       " 954: 'Сладкая мачеха',\n",
       " 6751: 'Пошаговая инструкция',\n",
       " 4773: 'Упс... Ной уплыл!',\n",
       " 3594: 'Риддик',\n",
       " 7166: 'Пип и Альба. Рождественское приключение',\n",
       " 1739: 'Холли остается ночевать',\n",
       " 2057: 'Приключения мистера Пибоди и Шермана',\n",
       " 11458: 'Сокровище нации',\n",
       " 6870: 'Красавица и чудовище',\n",
       " 13483: 'Маленькие секреты большой компании',\n",
       " 4505: 'Опасное задание',\n",
       " 12010: 'Жизнь в розовом цвете',\n",
       " 6300: 'Джуно',\n",
       " 935: 'Боксёр',\n",
       " 15000: 'Сердце дракона 3: Проклятье чародея',\n",
       " 2696: 'Восточный ветер 2',\n",
       " 6021: 'Твердая обложка',\n",
       " 4589: 'Молодожены',\n",
       " 12869: 'Доспехи Бога 3: Миссия Зодиак',\n",
       " 8625: 'Бельканто',\n",
       " 2914: 'Земля за стеной',\n",
       " 11770: 'Генуин',\n",
       " 427: 'Тень сомнения',\n",
       " 11359: 'Триумфальная арка',\n",
       " 10949: 'Птицелов',\n",
       " 11155: 'Лошадь мечты',\n",
       " 13733: 'Философы: Урок выживания',\n",
       " 9949: 'Хранители',\n",
       " 2884: 'Жребий судьбы',\n",
       " 13790: 'Сережка Казановы',\n",
       " 11817: 'Дудочка крысолова',\n",
       " 8149: 'Испытание верностью',\n",
       " 14520: 'Ненавижу и люблю',\n",
       " 10377: 'FaceTune преображение',\n",
       " 6780: 'Гибкость, осанка и шпагат',\n",
       " 11551: 'Растяжка для кaждого',\n",
       " 3064: 'Женская интуиция',\n",
       " 4001: '10.5 баллов: Апокалипсис',\n",
       " 6139: 'Особенности национальной маршрутки',\n",
       " 10793: 'Белка и Стрелка: Озорная семейка 2',\n",
       " 2168: 'Документальное кино Леонида Млечина',\n",
       " 1119: 'Первая Мировая',\n",
       " 7927: 'Джокер 2. Операция «Капкан»',\n",
       " 1434: 'Ноты любви',\n",
       " 4862: 'Я тебя никому не отдам',\n",
       " 2423: 'Народные песни',\n",
       " 11180: 'Как построить... что угодно',\n",
       " 13559: 'Торгсин',\n",
       " 7186: 'За лучшей жизнью',\n",
       " 14812: 'Ради тебя',\n",
       " 597: 'Марти – железный мальчик',\n",
       " 15094: 'Футбольные истории',\n",
       " 15297: 'Клиника счастья',\n",
       " 11392: 'Ромка, Фомка и Артос',\n",
       " 7403: 'Уитмер Томас: Золото',\n",
       " 9394: 'Осло',\n",
       " 4176: 'Дом мертвецов',\n",
       " 38: 'Золото',\n",
       " 6252: '[4k] Крестный отец 2',\n",
       " 11751: 'Гнев',\n",
       " 5003: 'Безымянный гангстер',\n",
       " 14736: 'Каникулы мечты',\n",
       " 436: 'Пряники из картошки',\n",
       " 9196: 'Рэкетир',\n",
       " 14319: '12 мелодий любви',\n",
       " 9182: 'Принцесса и воин',\n",
       " 7666: 'Во имя любви',\n",
       " 7816: 'Домовой',\n",
       " 1185: 'Маняшино озеро',\n",
       " 13909: '11+',\n",
       " 16510: 'Вертикаль',\n",
       " 7680: 'Виньяса йога: шаг за шагом. Урок 4',\n",
       " 11922: 'В тылу врага',\n",
       " 14226: 'Командировка',\n",
       " 7892: 'Живая радуга',\n",
       " 1330: 'Все ждут Рождество: Люси против Крампуса',\n",
       " 3849: 'Поезд ужасов',\n",
       " 6654: 'Доживем до понедельника',\n",
       " 8614: 'Таксист',\n",
       " 8731: 'Дураки умирают по пятницам',\n",
       " 12333: 'Нужные люди',\n",
       " 5111: 'Телохранитель для бабушки (жестовым языком)',\n",
       " 11694: 'Ромовый дневник (с тифлокомментарием)',\n",
       " 9275: 'Голем, как он пришел в мир',\n",
       " 4437: 'Абитуриентка',\n",
       " 11588: 'Ловушка времени (с тифлокомментарием)',\n",
       " 9517: 'Железная сотня',\n",
       " 161: 'Драйвер на ночь (жестовым языком)',\n",
       " 11784: 'Супергерои (жестовым языком)',\n",
       " 14948: 'Пока ты спал',\n",
       " 6689: 'Секс-Терапия',\n",
       " 8488: 'Неприкасаемые',\n",
       " 12130: 'Природа женщины (полная версия)',\n",
       " 10560: 'Признание 2 (полная версия)',\n",
       " 11756: 'Анастасия',\n",
       " 3143: 'Думай, как мужчина',\n",
       " 14983: 'Любовники',\n",
       " 6273: 'Неповиновение',\n",
       " 2950: 'На крючке',\n",
       " 1736: 'Смертельная тропа',\n",
       " 12597: 'Эволюция Борна',\n",
       " 7103: 'Халк',\n",
       " 15404: 'Звёздные войны: Атака клонов',\n",
       " 12849: 'Первый мститель',\n",
       " 3044: 'И целого мира мало',\n",
       " 8113: 'Компенсация рабочим',\n",
       " 9000: 'Оз: Возвращение в Изумрудный город',\n",
       " 9052: '[4К] Сокровища планеты. Гондурас. От коралловых садов к таинственному белому городу',\n",
       " 13106: '[4К] Тапа. Французская Полинезия',\n",
       " 1181: 'Побег из Претории',\n",
       " 4562: 'Кошмарный директор, или Школа №5',\n",
       " 9134: 'Анна Франк. Параллельные истории',\n",
       " 7375: 'Карьера через диван',\n",
       " 7577: 'На земле',\n",
       " 16464: 'Маленький сапожник',\n",
       " 6448: 'Манты. Западное Папуа',\n",
       " 1597: 'Агатс, столица народа асмат. Западное Папуа',\n",
       " 1573: 'Гонка на выживание',\n",
       " 15109: 'Красный гром',\n",
       " 1333: 'Мальтийский сокол',\n",
       " 219: 'Убежать, догнать, влюбиться!',\n",
       " 5094: 'Банда Чикаго',\n",
       " 15691: 'Мумий Тролль — Призраки завтра',\n",
       " 773: 'Странный ангел',\n",
       " 7513: 'Годы',\n",
       " 4092: 'Я всё преодолею',\n",
       " 16212: 'Ворон',\n",
       " 2542: 'Сталинград. Победа, изменившая мир',\n",
       " 3094: 'Сломленные судьбы',\n",
       " 4852: 'Джонни и Друзья',\n",
       " 9514: 'Супер Страйкеры',\n",
       " 12524: 'Дан, единственная любовь',\n",
       " 7673: 'Немецкий алфавит для детей',\n",
       " 5954: 'Любка',\n",
       " 1620: 'Петля времени',\n",
       " 15149: 'Библейские тайны',\n",
       " 12691: 'Загадки древней истории',\n",
       " 14513: 'Макс Волга - караоке',\n",
       " 12553: 'Недотрога',\n",
       " 16410: 'Жизнь в наследство',\n",
       " 5899: 'Застольные песни',\n",
       " 15917: 'Романсы',\n",
       " 13338: 'Ария - караоке',\n",
       " 5113: 'Безымянная звезда',\n",
       " 13628: 'Микки Маус (короткометражки)',\n",
       " 7448: 'Розыск',\n",
       " 12510: 'Тропинка вдоль реки',\n",
       " 6253: 'Я приду, если будет хорошая погода',\n",
       " 6171: 'Все возрасты любви',\n",
       " 1582: 'Изобретатель: Жажда крови в Силиконовой долине',\n",
       " 7435: 'Разделяй и властвуй: История Роджера Эйлса',\n",
       " 16275: '537 голосов',\n",
       " 12557: 'Лига чемпионов ФИБА. Нижний Новгород (Россия) против АЕК(Греция)',\n",
       " 9942: 'Ветер усиливается',\n",
       " 2322: 'Голубой патруль',\n",
       " 6833: 'Этот неловкий момент',\n",
       " 11034: 'Багси Мэлоун',\n",
       " 4081: 'Герой',\n",
       " 8713: 'Хочу замуж',\n",
       " 5654: 'Случайно беременна',\n",
       " 9559: 'Имущество с хвостом',\n",
       " 8808: 'Отогрей мое сердце',\n",
       " 14081: 'Еретики',\n",
       " 12007: 'Звонок мертвецу',\n",
       " 6942: 'Оборотень в погонах',\n",
       " 12814: 'Музыка во тьме',\n",
       " 11089: 'Высшая сила',\n",
       " 4246: 'Проклятый лес',\n",
       " 11337: '[4k] SuperПерцы',\n",
       " 8108: 'Хозяйка пещеры',\n",
       " 9215: 'Дружок',\n",
       " 14545: 'Все ждут Рождество 2: Люси и магический кристалл',\n",
       " 4848: 'Маменькины сынки',\n",
       " 3165: 'Револьвер',\n",
       " 7086: 'Ангел пролетел',\n",
       " 4258: 'Чудеса в Решетове',\n",
       " 2603: 'Кровь',\n",
       " 13443: 'Моя собака — Идиот (с тифлокомментарием)',\n",
       " 15375: 'Курьер',\n",
       " 3926: 'Исчезнувшая империя',\n",
       " 3868: 'Законный брак',\n",
       " 10864: 'Их знали только в лицо',\n",
       " 754: 'Крутой',\n",
       " 9002: 'Жених на двоих',\n",
       " 3748: '28 панфиловцев (жестовым языком)',\n",
       " 11488: 'Девочка (жестовым языком)',\n",
       " 762: '7 часов на соблазнение',\n",
       " 344: 'Сувенир для прокурора',\n",
       " 4027: '21 мост (с тифлокомментарием)',\n",
       " 11481: 'Москва слезам не верит (с тифлокомментарием)',\n",
       " 15059: 'Хороший год',\n",
       " 10881: 'Быстрее пули',\n",
       " 6439: 'Генсбур. Любовь хулигана',\n",
       " 9988: 'Ханна. Совершенное оружие',\n",
       " 4636: 'Паранормальное явление 5: Призраки',\n",
       " 13425: 'Терминатор: Генезис',\n",
       " 11364: 'Признание 4',\n",
       " 8593: 'Проект X (полная версия)',\n",
       " 3609: 'Другая Земля',\n",
       " 8590: 'Земное ядро',\n",
       " 8585: 'Дитя тьмы',\n",
       " 9207: 'Отверженные',\n",
       " 14399: 'Багровый Пик',\n",
       " 3491: 'Вольт',\n",
       " 5681: 'Самолеты',\n",
       " 9528: '9 месяцев строгого режима',\n",
       " 4799: 'Нянечка соблазнила хозяина 2',\n",
       " 7211: 'Приговор',\n",
       " 167: '[4К] Медвежий кускус - вовсе не медведь. Индонезия',\n",
       " 16256: '[4К] Акробаты Суматры. Индонезия',\n",
       " 6434: 'Медиум',\n",
       " 11956: 'Побег из тюрьмы Мэйз',\n",
       " 11778: 'Простые сложности',\n",
       " 14129: 'Гипер-интеллект',\n",
       " 7685: 'История любви',\n",
       " 2491: 'Все на борт Тайгер Блю!',\n",
       " 866: 'Ещё по одной',\n",
       " 15741: 'Любовь – это слишком для меня',\n",
       " 16506: 'Джордж из джунглей',\n",
       " 14826: 'Толстяки',\n",
       " 3558: 'Бартон Финк',\n",
       " 8274: 'Поли',\n",
       " 7583: 'Это не я',\n",
       " 4594: 'Романс для валторны',\n",
       " 2053: 'Таймлесс 2: Сапфировая книга',\n",
       " 12102: 'Джона с острова Тонга',\n",
       " 14460: 'Дублинские убийства',\n",
       " 5407: 'Карина Красная',\n",
       " 16310: 'Про Веру',\n",
       " 12834: 'Дом на холодном ключе',\n",
       " 3040: 'Подружки: Миссии в Хартлейк Сити',\n",
       " 12181: 'Последние пантеры',\n",
       " 16042: 'Полоса отчуждения',\n",
       " 4903: 'Снег растает в сентябре',\n",
       " 2809: 'Миссия в Кабуле',\n",
       " 1340: 'Морозов',\n",
       " 12914: 'Владимир Высоцкий - караоке',\n",
       " 11071: 'Забытое преступление',\n",
       " 15364: 'Концерт группы Мы',\n",
       " 4455: 'Как это устроено',\n",
       " 9921: 'Поговори со мною о любви',\n",
       " 12096: 'Апостол',\n",
       " 6222: 'Дан, единственная любовь',\n",
       " 2223: 'Как попасть в «Содержанки»',\n",
       " 5767: 'Найди скрытые объекты',\n",
       " 9423: 'Бреслин и Хэмилл: Мастера дедлайна',\n",
       " 572: 'Искусство слепых фотографов',\n",
       " 10297: 'Бойцы',\n",
       " 7350: 'Ночь в супермаркете',\n",
       " 9730: 'Знакомство с Факерами',\n",
       " 665: 'Маленькая смерть',\n",
       " 11702: 'Воздух',\n",
       " 16206: 'Мой король',\n",
       " 14776: 'Заблудившийся',\n",
       " 10026: 'Сломанный ключ',\n",
       " 27: 'Кружева',\n",
       " 16054: '[4k] Черепашки-ниндзя',\n",
       " 3045: 'Гроссмейстер',\n",
       " 12944: 'Отдача',\n",
       " 3438: 'Небо измеряется милями',\n",
       " 3252: 'Комната прислуги',\n",
       " 10706: 'Посторонним вход разрешен',\n",
       " 4395: 'Хотите — верьте, хотите — нет',\n",
       " 10007: 'Такебай (на киргизском языке с русскими субтитрами)',\n",
       " 11197: 'Пастбище Бакая (на киргизском языке)',\n",
       " 3652: 'Платон',\n",
       " 13440: 'Терминатор 2: Судный день',\n",
       " 12350: 'Комната страха',\n",
       " 15190: 'Так близко',\n",
       " 15026: 'Колония',\n",
       " 9458: 'Дикая вишня',\n",
       " 3732: 'Взрыв',\n",
       " 15391: 'Запретная зона (жестовым языком)',\n",
       " 5798: 'Каштанка',\n",
       " 6092: 'Царевна-лягушка (с тифлокомментарием)',\n",
       " 8637: 'Нянька по вызову (жестовым языком)',\n",
       " 10414: 'Дар',\n",
       " 389: 'Хатико: Самый верный друг',\n",
       " 4890: 'Супер 8',\n",
       " 13068: 'Горько!',\n",
       " 11689: 'Снежная Королева',\n",
       " 8680: '4.3.2.1.',\n",
       " 3905: 'Внеземное эхо',\n",
       " 16499: 'Экстрасенсы',\n",
       " 14459: 'Правила бойни',\n",
       " ...}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemid2name = {x.item_id:x.title for _, x in items.iterrows()}\n",
    "itemid2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c480c6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "interactions\n",
      "recs: ['Прабабушка легкого поведения', 'Гнев человеческий', 'Девятаев', 'Клиника счастья', 'Хрустальный', 'Секреты семейной жизни', 'Афера', 'Подслушано', 'Маша', 'Пальмира']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "\n",
    "def show_recommendations_and_explanations(batch, preds, expl, num_head=0):\n",
    "\n",
    "    \n",
    "    sampled_user = np.random.choice(np.arange(preds.shape[0]))\n",
    "    \n",
    "    user_interactions = [idx2item[t.item()] for t in batch['seq_i'][sampled_user] if t.item() in idx2item \\\n",
    "                     and idx2item[t.item()] != 0]\n",
    "    decoded_interactions = [itemid2name[x] for x in user_interactions]\n",
    "    \n",
    "    while len(decoded_interactions) > 10 or len(decoded_interactions) < 5 :\n",
    "        sampled_user = np.random.choice(np.arange(preds.shape[0]))\n",
    "        \n",
    "        user_interactions = [idx2item[t.item()] for t in batch['seq_i'][sampled_user] if t.item() in idx2item \\\n",
    "                     and idx2item[t.item()] != 0]\n",
    "        decoded_interactions = [itemid2name[x] for x in user_interactions]\n",
    "\n",
    "    print(len(decoded_interactions))\n",
    "    \n",
    "    user_preds = preds[sampled_user].detach().cpu().numpy()\n",
    "    recs_for_user = np.argsort(-user_preds)\n",
    "    recs_for_user_decoded = [idx2item[x-1] for x in np.argsort(-user_preds) if x > 0][:10]\n",
    "    recs_for_user_named = [itemid2name[x] for x in recs_for_user_decoded]\n",
    "    \n",
    "    attention_map = expl[sampled_user].detach().cpu().numpy()[num_head]\n",
    "\n",
    "    attention_map = attention_map[:batch['seq_len'][sampled_user]+1,:batch['seq_len'][sampled_user]+1]\n",
    "    sns.heatmap(attention_map,xticklabels=decoded_interactions+['next'], yticklabels=decoded_interactions+['next'])\n",
    "    \n",
    "    print('interactions')\n",
    "    print('recs:', recs_for_user_named)\n",
    "    \n",
    "    \n",
    "    \n",
    "show_recommendations_and_explanations(batch, preds, expl, num_head=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb52e19",
   "metadata": {},
   "source": [
    "дополнительно про bert4rec полезно послушать свежие две статьи https://www.youtube.com/watch?v=97HVZNB3O5A от Саши Петрова. Там он показывает, что взятая нам имплементация слаба, и можно сделать лучше, что остается за рамками семинара"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b9ba6",
   "metadata": {},
   "source": [
    "в оригинальной статье: \n",
    "\n",
    "<img src='images/5.png'>\n",
    "\n",
    "<b> Вопросы:</b>\n",
    "\n",
    "- Как можно использовать эту матрицу для интерпретации модели?\n",
    "- Какая картинка матрицы внимания будет у необученной модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f6411",
   "metadata": {},
   "source": [
    "## VII. Более качественное моделирование поведение пользователей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a048507",
   "metadata": {},
   "source": [
    "Вернемся к вопросу с начала семинара:\n",
    "    \n",
    "4) Представьте, что вы рекомендуете человеку магазины и видите человека с такой упорядоченной историей:\n",
    "    - зоомагазин, супермаркет, метрополитен, зоомагазин, кофейня, супермаркет, развлекательный сервис, зоомагазин\n",
    "   Порекомендуете ли теперь совершить следующую покупку в зоомагазине?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4253e92",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ca1c0",
   "metadata": {},
   "source": [
    "<img src='images/6.png'>\n",
    "\n",
    "Статья популярная - TiSASRec\n",
    "\n",
    "<img src='images/8.png'>\n",
    "\n",
    "Также важно учитывать, что между соседними событями айтемов из одной категории могут проходить какие-то времени\n",
    "\n",
    "<img src='images/7.png'>\n",
    "\n",
    "Другая статья с моделью KDA\n",
    "\n",
    "Toward Dynamic User Intention: Temporal Evolutionary\n",
    "Effects of Item Relations in Sequential Recommendation\n",
    "\n",
    "Имплементировать мы это сейчас не будем, есть имплементации готовые, например в ReChorus или RecBole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a496893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23103d20",
   "metadata": {},
   "source": [
    "## VIII. Контекстные рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60904c75",
   "metadata": {},
   "source": [
    "Контекст - то, что актуально для пользователя в момент рекомендций\n",
    "\n",
    "Интеракции - то, что известно в пользователе о прошлом. Контекст - в текущий момент\n",
    "\n",
    "<b> Вопрос: </b>\n",
    "\n",
    "1) Какие типы контекста вы можете придумать? Как от них могут изменяться рекомендации?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7c2202f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c78011",
   "metadata": {},
   "source": [
    "Можно выделить следующие типы:\n",
    "\n",
    "1) Время\n",
    "\n",
    "2) Геолокация\n",
    "\n",
    "3) Девайс получения рекомендаций\n",
    "\n",
    "4) Количество денег на счету\n",
    "\n",
    "5) Поисковый запрос недавний\n",
    "\n",
    "6) Межличностные отношения\n",
    "\n",
    "7) Внешние факторы\n",
    "\n",
    "8) Погода на улице\n",
    "\n",
    "<b> Вопросы </b>\n",
    "\n",
    "1) Давайте обсудим, насколько сильное и какое влияние может быть от каждого типа контекста?\n",
    "\n",
    "2) Предложите свои варианты еще других контекстов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53b966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "976888b6",
   "metadata": {},
   "source": [
    "В общем тут можно много говорить, давайте сразу сделаем наш BERT4Rec контекстной моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b7fb0",
   "metadata": {},
   "source": [
    "<img src='images/3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82824db4",
   "metadata": {},
   "source": [
    "Мы можем подставить временной контекст под маску (в последний токен), и варьировать его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4edb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b4c8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContextBERT4Rec(BERT4Rec):\n",
    "\n",
    "    def __init__(self, n_items):\n",
    "        super(BERT4Rec, self).__init__()\n",
    "\n",
    "        self.weekday_embedding = nn.Embedding(7, 64)\n",
    "        \n",
    "        self.n_layers = 2\n",
    "        self.n_heads = 2\n",
    "        self.hidden_size = 64  # same as embedding_size\n",
    "        self.inner_size = 128 # the dimensionality in feed-forward layer\n",
    "        self.hidden_dropout_prob = 0.2\n",
    "        self.attn_dropout_prob = 0.2\n",
    "        self.hidden_act = 'sigmoid'\n",
    "        self.layer_norm_eps = 1e-5\n",
    "        self.ITEM_SEQ = 'seq_i'\n",
    "        self.ITEM_SEQ_LEN = 'seq_len'\n",
    "        self.max_seq_length = 100\n",
    "        \n",
    "\n",
    "        self.mask_ratio = 0.2\n",
    "\n",
    "        self.loss_type =  'CE'\n",
    "        self.initializer_range = 1e-2\n",
    "\n",
    "        # load dataset info\n",
    "        self.n_items = n_items\n",
    "        self.mask_token = self.n_items\n",
    "        self.mask_item_length = int(self.mask_ratio * self.max_seq_length)\n",
    "\n",
    "        # define layers and loss\n",
    "        self.item_embedding = nn.Embedding(self.n_items + 1, self.hidden_size, padding_idx=0)  # mask token add 1\n",
    "        self.position_embedding = nn.Embedding(self.max_seq_length + 1, self.hidden_size)  # add mask_token at the last\n",
    "        self.trm_encoder = TransformerEncoder(\n",
    "            n_layers=self.n_layers,\n",
    "            n_heads=self.n_heads,\n",
    "            hidden_size=self.hidden_size,\n",
    "            inner_size=self.inner_size,\n",
    "            hidden_dropout_prob=self.hidden_dropout_prob,\n",
    "            attn_dropout_prob=self.attn_dropout_prob,\n",
    "            hidden_act=self.hidden_act,\n",
    "            layer_norm_eps=self.layer_norm_eps\n",
    "        )\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(self.hidden_size, eps=self.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(self.hidden_dropout_prob)\n",
    "\n",
    "        # we only need compute the loss at the masked position\n",
    "        try:\n",
    "            assert self.loss_type in ['BPR', 'CE']\n",
    "        except AssertionError:\n",
    "            raise AssertionError(\"Make sure 'loss_type' in ['BPR', 'CE']!\")\n",
    "\n",
    "        # parameters initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "\n",
    "    def reconstruct_test_data(self,\n",
    "                              item_seq,\n",
    "                              item_seq_len,\n",
    "                              dow,\n",
    "                              dow_valid,\n",
    "                              particular_day=-1,\n",
    "                              ):\n",
    "        \"\"\"\n",
    "        Add mask token at the last position according to the lengths of item_seq\n",
    "        \"\"\"\n",
    "        padding = torch.zeros(item_seq.size(0), dtype=torch.long, device=item_seq.device)  # [B]\n",
    "        item_seq = torch.cat((item_seq, padding.unsqueeze(-1)), dim=-1)  # [B max_len+1]\n",
    "        dow = torch.cat((dow, padding.unsqueeze(-1)), dim=-1) \n",
    "        for batch_id, last_position in enumerate(item_seq_len):\n",
    "            item_seq[batch_id][last_position] = self.mask_token\n",
    "            if particular_day == -1:\n",
    "                dow[batch_id][last_position] = dow_valid[batch_id]\n",
    "            else:\n",
    "                dow[batch_id][last_position] = particular_day\n",
    "        return item_seq, dow\n",
    "\n",
    "    def forward(self, item_seq, dow, return_explanations=False):\n",
    "        \n",
    "        \n",
    "        dow_embeddings = self.weekday_embedding(dow.long())\n",
    "        \n",
    "        position_ids = torch.arange(item_seq.size(1), dtype=torch.long, device=item_seq.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(item_seq)\n",
    "        position_embedding = self.position_embedding(position_ids)\n",
    "        item_emb = self.item_embedding(item_seq)\n",
    "        input_emb = item_emb + position_embedding + dow_embeddings\n",
    "        input_emb = self.LayerNorm(input_emb)\n",
    "        input_emb = self.dropout(input_emb)\n",
    "        extended_attention_mask = self.get_attention_mask(item_seq)\n",
    "        if return_explanations:\n",
    "            trm_output, explanations = self.trm_encoder(input_emb, extended_attention_mask, output_all_encoded_layers=True,\n",
    "                                         return_explanations=return_explanations)\n",
    "        else:\n",
    "            trm_output = self.trm_encoder(input_emb, extended_attention_mask, output_all_encoded_layers=True,\n",
    "                                         return_explanations=return_explanations)\n",
    "            \n",
    "        output = trm_output[-1]\n",
    "        \n",
    "        if return_explanations:\n",
    "            return output, explanations\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "\n",
    "    def calculate_loss(self, interaction):\n",
    "        item_seq = interaction[self.ITEM_SEQ].long()\n",
    "        masked_item_seq, pos_items, neg_items, masked_index = self.reconstruct_train_data(item_seq)\n",
    "\n",
    "        seq_output = self.forward(masked_item_seq, dow=interaction['dow'])\n",
    "        pred_index_map = self.multi_hot_embed(masked_index, masked_item_seq.size(-1))  # [B*mask_len max_len]\n",
    "        # [B mask_len] -> [B mask_len max_len] multi hot\n",
    "        pred_index_map = pred_index_map.view(masked_index.size(0), masked_index.size(1), -1)  # [B mask_len max_len]\n",
    "        # [B mask_len max_len] * [B max_len H] -> [B mask_len H]\n",
    "        # only calculate loss for masked position\n",
    "        seq_output = torch.bmm(pred_index_map, seq_output)  # [B mask_len H]\n",
    "\n",
    "        if self.loss_type == 'BPR':\n",
    "            pos_items_emb = self.item_embedding(pos_items)  # [B mask_len H]\n",
    "            neg_items_emb = self.item_embedding(neg_items)  # [B mask_len H]\n",
    "            pos_score = torch.sum(seq_output * pos_items_emb, dim=-1)  # [B mask_len]\n",
    "            neg_score = torch.sum(seq_output * neg_items_emb, dim=-1)  # [B mask_len]\n",
    "            targets = (masked_index > 0).float()\n",
    "            loss = - torch.sum(torch.log(1e-14 + torch.sigmoid(pos_score - neg_score)) * targets) \\\n",
    "                   / torch.sum(targets)\n",
    "            return loss\n",
    "\n",
    "        elif self.loss_type == 'CE':\n",
    "            loss_fct = nn.CrossEntropyLoss(reduction='none')\n",
    "            test_item_emb = self.item_embedding.weight[:self.n_items]  # [item_num H]\n",
    "            logits = torch.matmul(seq_output, test_item_emb.transpose(0, 1))  # [B mask_len item_num]\n",
    "            targets = (masked_index > 0).float().view(-1)  # [B*mask_len]\n",
    "\n",
    "            loss = torch.sum(loss_fct(logits.view(-1, test_item_emb.size(0)), pos_items.view(-1)) * targets) \\\n",
    "                   / torch.sum(targets)\n",
    "            return loss\n",
    "        else:\n",
    "            raise NotImplementedError(\"Make sure 'loss_type' in ['BPR', 'CE']!\")\n",
    "\n",
    "\n",
    "    def full_sort_predict(self, \n",
    "                          interaction,\n",
    "                          return_explanations=False,\n",
    "                          particular_day=-1):\n",
    "        \n",
    "        item_seq = interaction[self.ITEM_SEQ].long()\n",
    "        item_seq_len = interaction[self.ITEM_SEQ_LEN].long()\n",
    "        item_seq, dow = self.reconstruct_test_data(item_seq,\n",
    "                                              item_seq_len,\n",
    "                                              dow=interaction['dow'],\n",
    "                                              dow_valid=interaction['dow_valid'].long(),\n",
    "                                              particular_day=particular_day)\n",
    "        \n",
    "        \n",
    "        if return_explanations:\n",
    "            seq_output, expl = self.forward(item_seq,\n",
    "                                            dow=dow,\n",
    "                                            return_explanations=return_explanations)\n",
    "        else:\n",
    "            seq_output = self.forward(item_seq,\n",
    "                                      dow=dow,\n",
    "                                      return_explanations=return_explanations)\n",
    "            \n",
    "        \n",
    "        seq_output = self.gather_indexes(seq_output, item_seq_len - 1)  # [B H]\n",
    "        test_items_emb = self.item_embedding.weight[:self.n_items]  # delete masked token\n",
    "        scores = torch.matmul(seq_output, test_items_emb.transpose(0, 1))  # [B, item_num]\n",
    "                \n",
    "        idxs = item_seq.nonzero()\n",
    "        item_seq[item_seq==self.n_items] = 0\n",
    "        scores[idxs[:,0], item_seq[idxs[:,0],idxs[:,1]].long()] = -1000\n",
    "\n",
    "        if return_explanations:\n",
    "            return scores, expl\n",
    "        else:\n",
    "            return scores\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8280e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9829b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/catalyst/core/runner.py:638: UserWarning: No ``ISchedulerCallback/SchedulerCallback`` were found while runner.scheduler is not None.Do you make scheduler step during ``runner.handle_batch``?\n",
      "  \"No ``ISchedulerCallback/SchedulerCallback`` were found \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a17c28caa1e49848aaf647e5f8b1739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/5 * Epoch (train):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1/5) loss: 8.459012211608888 | lr: 0.001 | map10: 0.0 | map10/std: 0.0 | momentum: 0.9 | ndcg20: 0.0 | ndcg20/std: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d44662238d418685e76c222e575f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/5 * Epoch (valid):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (1/5) loss: 7.913002435302735 | lr: 0.001 | map10: 0.08979082796573638 | map10/std: 0.015451208284442047 | momentum: 0.9 | ndcg20: 0.09712186888456344 | ndcg20/std: 0.011222024264848545\n",
      "* Epoch (1/5) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0574ed9f984f20a9517e039f189912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/5 * Epoch (train):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (2/5) loss: 7.761012598419189 | lr: 0.001 | map10: 0.0 | map10/std: 0.0 | momentum: 0.9 | ndcg20: 0.0 | ndcg20/std: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870a909c39a24850b63b842ab53c0758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/5 * Epoch (valid):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (2/5) loss: 7.458164292907714 | lr: 0.001 | map10: 0.1076800211429596 | map10/std: 0.014903637205744832 | momentum: 0.9 | ndcg20: 0.10964286289215087 | ndcg20/std: 0.011712100963375896\n",
      "* Epoch (2/5) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58742ed2610643ac840c4b576fef9da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/5 * Epoch (train):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (3/5) loss: 7.505968649291993 | lr: 0.001 | map10: 0.0 | map10/std: 0.0 | momentum: 0.9 | ndcg20: 0.0 | ndcg20/std: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33d91605b764a4496d8c0ec60ea2b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/5 * Epoch (valid):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (3/5) loss: 7.387365798950195 | lr: 0.001 | map10: 0.10781053624153139 | map10/std: 0.01619631917088189 | momentum: 0.9 | ndcg20: 0.1119542230606079 | ndcg20/std: 0.011830521195496739\n",
      "* Epoch (3/5) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48153cb04d24002a7195fba819bd30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4/5 * Epoch (train):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4/5) loss: 7.433365428161621 | lr: 0.001 | map10: 0.0 | map10/std: 0.0 | momentum: 0.9 | ndcg20: 0.0 | ndcg20/std: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ac4911840b4e96ae43192ecee3ed0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4/5 * Epoch (valid):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (4/5) loss: 7.356972218322754 | lr: 0.001 | map10: 0.1260868020296097 | map10/std: 0.018576002719429417 | momentum: 0.9 | ndcg20: 0.11880033075809479 | ndcg20/std: 0.014939629936590204\n",
      "* Epoch (4/5) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609dc1983be941f1b0fcfe2c7adbb6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5/5 * Epoch (train):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (5/5) loss: 7.420101595306396 | lr: 0.001 | map10: 0.0 | map10/std: 0.0 | momentum: 0.9 | ndcg20: 0.0 | ndcg20/std: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cc6f931e904010b959401cd3283e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5/5 * Epoch (valid):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (5/5) loss: 7.3294425895690924 | lr: 0.001 | map10: 0.12527201335430146 | map10/std: 0.01626399883946588 | momentum: 0.9 | ndcg20: 0.11997740316390992 | ndcg20/std: 0.013181571112957178\n",
      "* Epoch (5/5) \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ContextBERT4Rec(n_items=len(item2idx)+1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "engine = dl.DeviceEngine('cpu')\n",
    "hparams = {\n",
    "    \"anneal_cap\": 0.2,\n",
    "    \"total_anneal_steps\": 6000,\n",
    "}\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    dl.NDCGCallback(\"logits\", \"targets\", [20]),\n",
    "    dl.MAPCallback(\"logits\", \"targets\", [10]),\n",
    "    #dl.MRRCallback(\"logits\", \"targets\", [20, 50, 100]),\n",
    "    #dl.HitrateCdallback(\"logits\", \"targets\", [20, 50, 100]),\n",
    "    dl.OptimizerCallback(\"loss\", accumulation_steps=1),\n",
    "    dl.EarlyStoppingCallback(\n",
    "        patience=5, loader_key=\"valid\", metric_key=\"map10\", minimize=False\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "runner = RecSysRunner()\n",
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    engine=engine,\n",
    "    hparams=hparams,\n",
    "    scheduler=lr_scheduler,\n",
    "    loaders=loaders,\n",
    "    num_epochs=5,\n",
    "    verbose=True,\n",
    "    timeit=True,\n",
    "    callbacks=callbacks,\n",
    "    #logdir=\"./logs\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7edc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7c5ba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:50<00:00,  8.38s/it]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "ranks_dow = {}\n",
    "\n",
    "for dow in tqdm(range(6)):\n",
    "\n",
    "    item2rank = defaultdict(list)\n",
    "\n",
    "    for batch in loaders['valid']:\n",
    "\n",
    "        preds = model.full_sort_predict(batch, return_explanations=False, particular_day=dow )\n",
    "        preds = (preds.argsort())[:,-10:]\n",
    "\n",
    "        for j  in range(preds.shape[0]):\n",
    "            for i in range(len(preds[j])):\n",
    "                item2rank[itemid2name[idx2item[preds[j][i].item()-1]]].append(i)\n",
    "\n",
    "    item2rank_averaged = {k: np.mean(item2rank[k]) for k in item2rank if len(item2rank[k]) > 10}\n",
    "    ranks_dow[dow] = item2rank_averaged\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2174084a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_change = pd.DataFrame.from_dict(ranks_dow)\n",
    "\n",
    "res_change['diff_ranks'] =  res_change[4] - res_change[0]\n",
    "res_change.diff_ranks.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2fdde69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>diff_ranks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Маша</th>\n",
       "      <td>2.270838</td>\n",
       "      <td>2.255310</td>\n",
       "      <td>2.279874</td>\n",
       "      <td>2.273549</td>\n",
       "      <td>2.266772</td>\n",
       "      <td>2.270899</td>\n",
       "      <td>-0.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100% волк</th>\n",
       "      <td>1.469565</td>\n",
       "      <td>1.467014</td>\n",
       "      <td>1.469565</td>\n",
       "      <td>1.469565</td>\n",
       "      <td>1.467014</td>\n",
       "      <td>1.469565</td>\n",
       "      <td>-0.002551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Белый снег</th>\n",
       "      <td>1.467756</td>\n",
       "      <td>1.467811</td>\n",
       "      <td>1.465577</td>\n",
       "      <td>1.465577</td>\n",
       "      <td>1.466495</td>\n",
       "      <td>1.465236</td>\n",
       "      <td>-0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Подслушано</th>\n",
       "      <td>3.100786</td>\n",
       "      <td>3.103704</td>\n",
       "      <td>3.099214</td>\n",
       "      <td>3.099888</td>\n",
       "      <td>3.099663</td>\n",
       "      <td>3.099439</td>\n",
       "      <td>-0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Пальмира</th>\n",
       "      <td>1.314042</td>\n",
       "      <td>1.314324</td>\n",
       "      <td>1.313285</td>\n",
       "      <td>1.314183</td>\n",
       "      <td>1.313453</td>\n",
       "      <td>1.313620</td>\n",
       "      <td>-0.000589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Девятаев</th>\n",
       "      <td>6.690096</td>\n",
       "      <td>6.689031</td>\n",
       "      <td>6.690628</td>\n",
       "      <td>6.690628</td>\n",
       "      <td>6.689563</td>\n",
       "      <td>6.690362</td>\n",
       "      <td>-0.000532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Гнев человеческий</th>\n",
       "      <td>8.241564</td>\n",
       "      <td>8.241564</td>\n",
       "      <td>8.241845</td>\n",
       "      <td>8.241282</td>\n",
       "      <td>8.241564</td>\n",
       "      <td>8.241564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Стендап под прикрытием</th>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Радиовспышка</th>\n",
       "      <td>1.470588</td>\n",
       "      <td>1.470588</td>\n",
       "      <td>1.470588</td>\n",
       "      <td>1.470588</td>\n",
       "      <td>1.470588</td>\n",
       "      <td>1.470588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Зверополис</th>\n",
       "      <td>1.030303</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Маленький воин</th>\n",
       "      <td>1.159817</td>\n",
       "      <td>1.164384</td>\n",
       "      <td>1.159817</td>\n",
       "      <td>1.159817</td>\n",
       "      <td>1.159817</td>\n",
       "      <td>1.159817</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067: Петля времени</th>\n",
       "      <td>1.180723</td>\n",
       "      <td>1.180723</td>\n",
       "      <td>1.192771</td>\n",
       "      <td>1.180723</td>\n",
       "      <td>1.180723</td>\n",
       "      <td>1.180723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ральф против Интернета</th>\n",
       "      <td>1.115942</td>\n",
       "      <td>1.115942</td>\n",
       "      <td>1.101449</td>\n",
       "      <td>1.115942</td>\n",
       "      <td>1.115942</td>\n",
       "      <td>1.115942</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Цвет из иных миров</th>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Бывшая с того света</th>\n",
       "      <td>1.290323</td>\n",
       "      <td>1.290323</td>\n",
       "      <td>1.290323</td>\n",
       "      <td>1.290323</td>\n",
       "      <td>1.290323</td>\n",
       "      <td>1.290323</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Веном</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Восемь сотен</th>\n",
       "      <td>1.049180</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Клиника счастья</th>\n",
       "      <td>7.530954</td>\n",
       "      <td>7.530954</td>\n",
       "      <td>7.530954</td>\n",
       "      <td>7.530954</td>\n",
       "      <td>7.530954</td>\n",
       "      <td>7.530954</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Хрустальный</th>\n",
       "      <td>8.931583</td>\n",
       "      <td>8.931304</td>\n",
       "      <td>8.931583</td>\n",
       "      <td>8.931863</td>\n",
       "      <td>8.931583</td>\n",
       "      <td>8.931583</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Секреты семейной жизни</th>\n",
       "      <td>5.164916</td>\n",
       "      <td>5.165155</td>\n",
       "      <td>5.164916</td>\n",
       "      <td>5.164916</td>\n",
       "      <td>5.164916</td>\n",
       "      <td>5.164916</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Афера</th>\n",
       "      <td>4.248241</td>\n",
       "      <td>4.247788</td>\n",
       "      <td>4.248468</td>\n",
       "      <td>4.248241</td>\n",
       "      <td>4.248241</td>\n",
       "      <td>4.248241</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Фемида видит</th>\n",
       "      <td>1.457678</td>\n",
       "      <td>1.457074</td>\n",
       "      <td>1.459215</td>\n",
       "      <td>1.458006</td>\n",
       "      <td>1.457955</td>\n",
       "      <td>1.458838</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Прабабушка легкого поведения</th>\n",
       "      <td>5.958714</td>\n",
       "      <td>5.959703</td>\n",
       "      <td>5.957973</td>\n",
       "      <td>5.958220</td>\n",
       "      <td>5.959209</td>\n",
       "      <td>5.958467</td>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Немцы</th>\n",
       "      <td>1.322013</td>\n",
       "      <td>1.321881</td>\n",
       "      <td>1.322290</td>\n",
       "      <td>1.322699</td>\n",
       "      <td>1.322964</td>\n",
       "      <td>1.322277</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Дочь волка</th>\n",
       "      <td>1.300199</td>\n",
       "      <td>1.302789</td>\n",
       "      <td>1.300199</td>\n",
       "      <td>1.300199</td>\n",
       "      <td>1.304781</td>\n",
       "      <td>1.302187</td>\n",
       "      <td>0.004582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Поступь хаоса</th>\n",
       "      <td>2.133495</td>\n",
       "      <td>2.146250</td>\n",
       "      <td>2.126237</td>\n",
       "      <td>2.131735</td>\n",
       "      <td>2.138333</td>\n",
       "      <td>2.135034</td>\n",
       "      <td>0.004838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0         1         2         3  \\\n",
       "Маша                          2.270838  2.255310  2.279874  2.273549   \n",
       "100% волк                     1.469565  1.467014  1.469565  1.469565   \n",
       "Белый снег                    1.467756  1.467811  1.465577  1.465577   \n",
       "Подслушано                    3.100786  3.103704  3.099214  3.099888   \n",
       "Пальмира                      1.314042  1.314324  1.313285  1.314183   \n",
       "Девятаев                      6.690096  6.689031  6.690628  6.690628   \n",
       "Гнев человеческий             8.241564  8.241564  8.241845  8.241282   \n",
       "Стендап под прикрытием        1.200000  1.200000  1.200000  1.200000   \n",
       "Радиовспышка                  1.470588  1.470588  1.470588  1.470588   \n",
       "Зверополис                    1.030303  1.030303  1.030303  1.030303   \n",
       "Маленький воин                1.159817  1.164384  1.159817  1.159817   \n",
       "2067: Петля времени           1.180723  1.180723  1.192771  1.180723   \n",
       "Ральф против Интернета        1.115942  1.115942  1.101449  1.115942   \n",
       "Цвет из иных миров            1.125000  1.125000  1.125000  1.125000   \n",
       "Бывшая с того света           1.290323  1.290323  1.290323  1.290323   \n",
       "Веном                         0.947368  0.947368  0.947368  0.947368   \n",
       "Восемь сотен                  1.049180  1.049180  1.049180  1.049180   \n",
       "Клиника счастья               7.530954  7.530954  7.530954  7.530954   \n",
       "Хрустальный                   8.931583  8.931304  8.931583  8.931863   \n",
       "Секреты семейной жизни        5.164916  5.165155  5.164916  5.164916   \n",
       "Афера                         4.248241  4.247788  4.248468  4.248241   \n",
       "Фемида видит                  1.457678  1.457074  1.459215  1.458006   \n",
       "Прабабушка легкого поведения  5.958714  5.959703  5.957973  5.958220   \n",
       "Немцы                         1.322013  1.321881  1.322290  1.322699   \n",
       "Дочь волка                    1.300199  1.302789  1.300199  1.300199   \n",
       "Поступь хаоса                 2.133495  2.146250  2.126237  2.131735   \n",
       "\n",
       "                                     4         5  diff_ranks  \n",
       "Маша                          2.266772  2.270899   -0.004066  \n",
       "100% волк                     1.467014  1.469565   -0.002551  \n",
       "Белый снег                    1.466495  1.465236   -0.001261  \n",
       "Подслушано                    3.099663  3.099439   -0.001122  \n",
       "Пальмира                      1.313453  1.313620   -0.000589  \n",
       "Девятаев                      6.689563  6.690362   -0.000532  \n",
       "Гнев человеческий             8.241564  8.241564    0.000000  \n",
       "Стендап под прикрытием        1.200000  1.200000    0.000000  \n",
       "Радиовспышка                  1.470588  1.470588    0.000000  \n",
       "Зверополис                    1.030303  1.030303    0.000000  \n",
       "Маленький воин                1.159817  1.159817    0.000000  \n",
       "2067: Петля времени           1.180723  1.180723    0.000000  \n",
       "Ральф против Интернета        1.115942  1.115942    0.000000  \n",
       "Цвет из иных миров            1.125000  1.125000    0.000000  \n",
       "Бывшая с того света           1.290323  1.290323    0.000000  \n",
       "Веном                         0.947368  0.947368    0.000000  \n",
       "Восемь сотен                  1.049180  1.049180    0.000000  \n",
       "Клиника счастья               7.530954  7.530954    0.000000  \n",
       "Хрустальный                   8.931583  8.931583    0.000000  \n",
       "Секреты семейной жизни        5.164916  5.164916    0.000000  \n",
       "Афера                         4.248241  4.248241    0.000000  \n",
       "Фемида видит                  1.457955  1.458838    0.000277  \n",
       "Прабабушка легкого поведения  5.959209  5.958467    0.000494  \n",
       "Немцы                         1.322964  1.322277    0.000950  \n",
       "Дочь волка                    1.304781  1.302187    0.004582  \n",
       "Поступь хаоса                 2.138333  2.135034    0.004838  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_change.sort_values(by='diff_ranks', ascending=True).tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c78bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7fdf9382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = model.weekday_embedding.weight.detach().cpu().numpy()\n",
    "\n",
    "weight_mat = (embeddings @ embeddings.T)\n",
    "\n",
    "sns.heatmap(weight_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02943ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9795f18c",
   "metadata": {},
   "source": [
    "вставляем контекст в двухуровневые модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c8d33f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>snd_lvl_items</th>\n",
       "      <th>item_col_labels</th>\n",
       "      <th>knn_assym</th>\n",
       "      <th>p3alpha</th>\n",
       "      <th>perspop</th>\n",
       "      <th>knn_dice</th>\n",
       "      <th>ease_score</th>\n",
       "      <th>ease</th>\n",
       "      <th>gfcf</th>\n",
       "      <th>knn_jaccard</th>\n",
       "      <th>multvae</th>\n",
       "      <th>multvae_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001400</td>\n",
       "      <td>11145</td>\n",
       "      <td>11145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>1187.0</td>\n",
       "      <td>-0.003725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.048315</td>\n",
       "      <td>-8.048315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001400</td>\n",
       "      <td>11322</td>\n",
       "      <td>11322</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>758.0</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.001169</td>\n",
       "      <td>-7.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001400</td>\n",
       "      <td>11382</td>\n",
       "      <td>11382</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.775056</td>\n",
       "      <td>-7.775056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001400</td>\n",
       "      <td>1238</td>\n",
       "      <td>1238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.827324</td>\n",
       "      <td>-8.827324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001400</td>\n",
       "      <td>13058</td>\n",
       "      <td>13058</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>737.0</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.859427</td>\n",
       "      <td>-6.859427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  snd_lvl_items  item_col_labels  knn_assym  p3alpha  \\\n",
       "0  1001400    11145          11145                0        0.0      0.0   \n",
       "1  1001400    11322          11322                0        0.0      0.0   \n",
       "2  1001400    11382          11382                0        0.0      0.0   \n",
       "3  1001400     1238           1238                0        0.0      0.0   \n",
       "4  1001400    13058          13058                0        0.0      0.0   \n",
       "\n",
       "   perspop  knn_dice  ease_score    ease      gfcf  knn_jaccard   multvae  \\\n",
       "0      0.0       0.0    0.000068  1187.0 -0.003725          0.0 -8.048315   \n",
       "1      0.0       0.0    0.000097   758.0 -0.001584          0.0 -7.001169   \n",
       "2      0.0       0.0    0.000138   380.0  0.007342          0.0 -7.775056   \n",
       "3      0.0       0.0    0.000072  1121.0  0.009378          0.0 -8.827324   \n",
       "4      0.0       0.0    0.000099   737.0 -0.000888          0.0 -6.859427   \n",
       "\n",
       "   multvae_rank  \n",
       "0     -8.048315  \n",
       "1     -7.001169  \n",
       "2     -7.775056  \n",
       "3     -8.827324  \n",
       "4     -6.859427  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../mts_data_show.csv.gz', nrows=100000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c08620fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>snd_lvl_items</th>\n",
       "      <th>item_col_labels</th>\n",
       "      <th>knn_assym</th>\n",
       "      <th>p3alpha</th>\n",
       "      <th>perspop</th>\n",
       "      <th>knn_dice</th>\n",
       "      <th>ease_score</th>\n",
       "      <th>ease</th>\n",
       "      <th>gfcf</th>\n",
       "      <th>knn_jaccard</th>\n",
       "      <th>multvae</th>\n",
       "      <th>multvae_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1001400</td>\n",
       "      <td>4141</td>\n",
       "      <td>4141</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>578.0</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.197251</td>\n",
       "      <td>-7.197251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1002049</td>\n",
       "      <td>12138</td>\n",
       "      <td>12138</td>\n",
       "      <td>1</td>\n",
       "      <td>0.213457</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021227</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>402.0</td>\n",
       "      <td>0.018966</td>\n",
       "      <td>0.022890</td>\n",
       "      <td>-7.463271</td>\n",
       "      <td>-7.463271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1002049</td>\n",
       "      <td>15994</td>\n",
       "      <td>15994</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>-7.922297</td>\n",
       "      <td>-7.922297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1002049</td>\n",
       "      <td>4457</td>\n",
       "      <td>4457</td>\n",
       "      <td>1</td>\n",
       "      <td>1.696066</td>\n",
       "      <td>0.073237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.529603</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.097332</td>\n",
       "      <td>0.575680</td>\n",
       "      <td>-5.300034</td>\n",
       "      <td>-5.300034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1002049</td>\n",
       "      <td>8221</td>\n",
       "      <td>8221</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227332</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.551929</td>\n",
       "      <td>-8.551929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  snd_lvl_items  item_col_labels  knn_assym   p3alpha  \\\n",
       "13  1001400     4141           4141                1   0.000000  0.000000   \n",
       "27  1002049    12138          12138                1   0.213457  0.016396   \n",
       "34  1002049    15994          15994                1   0.056335  0.000000   \n",
       "39  1002049     4457           4457                1   1.696066  0.073237   \n",
       "45  1002049     8221           8221                1   0.227332  0.011842   \n",
       "\n",
       "    perspop  knn_dice  ease_score    ease      gfcf  knn_jaccard   multvae  \\\n",
       "13      0.0  0.000000    0.000114   578.0  0.001373     0.000000 -7.197251   \n",
       "27      0.0  0.021227    0.000847   402.0  0.018966     0.022890 -7.463271   \n",
       "34      0.0  0.002985    0.000415  1446.0  0.011384     0.003231 -7.922297   \n",
       "39      0.0  0.529603    0.001610    19.0  0.097332     0.575680 -5.300034   \n",
       "45      0.0  0.000000    0.000493  1218.0  0.004946     0.000000 -8.551929   \n",
       "\n",
       "    multvae_rank  \n",
       "13     -7.197251  \n",
       "27     -7.463271  \n",
       "34     -7.922297  \n",
       "39     -5.300034  \n",
       "45     -8.551929  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.item_col_labels==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b035b7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>snd_lvl_items</th>\n",
       "      <th>item_col_labels</th>\n",
       "      <th>knn_assym</th>\n",
       "      <th>p3alpha</th>\n",
       "      <th>perspop</th>\n",
       "      <th>knn_dice</th>\n",
       "      <th>ease_score</th>\n",
       "      <th>ease</th>\n",
       "      <th>gfcf</th>\n",
       "      <th>knn_jaccard</th>\n",
       "      <th>multvae</th>\n",
       "      <th>multvae_rank</th>\n",
       "      <th>device</th>\n",
       "      <th>time_of_recs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001400</td>\n",
       "      <td>11145</td>\n",
       "      <td>11145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>1187.0</td>\n",
       "      <td>-0.003725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.048315</td>\n",
       "      <td>-8.048315</td>\n",
       "      <td>tv</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001400</td>\n",
       "      <td>11322</td>\n",
       "      <td>11322</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>758.0</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.001169</td>\n",
       "      <td>-7.001169</td>\n",
       "      <td>mobile</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001400</td>\n",
       "      <td>11382</td>\n",
       "      <td>11382</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.775056</td>\n",
       "      <td>-7.775056</td>\n",
       "      <td>tv</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001400</td>\n",
       "      <td>1238</td>\n",
       "      <td>1238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.827324</td>\n",
       "      <td>-8.827324</td>\n",
       "      <td>mobile</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001400</td>\n",
       "      <td>13058</td>\n",
       "      <td>13058</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>737.0</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.859427</td>\n",
       "      <td>-6.859427</td>\n",
       "      <td>mobile</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  snd_lvl_items  item_col_labels  knn_assym  p3alpha  \\\n",
       "0  1001400    11145          11145                0        0.0      0.0   \n",
       "1  1001400    11322          11322                0        0.0      0.0   \n",
       "2  1001400    11382          11382                0        0.0      0.0   \n",
       "3  1001400     1238           1238                0        0.0      0.0   \n",
       "4  1001400    13058          13058                0        0.0      0.0   \n",
       "\n",
       "   perspop  knn_dice  ease_score    ease      gfcf  knn_jaccard   multvae  \\\n",
       "0      0.0       0.0    0.000068  1187.0 -0.003725          0.0 -8.048315   \n",
       "1      0.0       0.0    0.000097   758.0 -0.001584          0.0 -7.001169   \n",
       "2      0.0       0.0    0.000138   380.0  0.007342          0.0 -7.775056   \n",
       "3      0.0       0.0    0.000072  1121.0  0.009378          0.0 -8.827324   \n",
       "4      0.0       0.0    0.000099   737.0 -0.000888          0.0 -6.859427   \n",
       "\n",
       "   multvae_rank  device  time_of_recs  \n",
       "0     -8.048315      tv            23  \n",
       "1     -7.001169  mobile            18  \n",
       "2     -7.775056      tv             5  \n",
       "3     -8.827324  mobile            11  \n",
       "4     -6.859427  mobile             6  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['device'] = np.random.choice(['mobile','tv'], size=df.shape[0])\n",
    "df['time_of_recs'] = np.random.choice(np.arange(24), size=df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a600f",
   "metadata": {},
   "source": [
    "на трейне обучаемся на актуальных данных, на тесте можем подставлять контекст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07511abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668e7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "59d7dc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0582, -0.0422, -0.0457,  ..., -0.0530,  0.0737,  0.0708],\n",
       "        [ 0.0294, -0.0212,  0.0024,  ..., -0.0509,  0.0098,  0.0290],\n",
       "        [ 0.0543, -0.0498, -0.0293,  ..., -0.0298,  0.0505,  0.0641],\n",
       "        ...,\n",
       "        [ 0.0293, -0.0368, -0.0229,  ..., -0.0377,  0.0425,  0.0359],\n",
       "        [ 0.0330, -0.0282, -0.0219,  ..., -0.0368,  0.0259,  0.0389],\n",
       "        [-0.0238,  0.0187,  0.0157,  ...,  0.0304, -0.0071, -0.0180]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6538ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6f45f29",
   "metadata": {},
   "source": [
    "## IX. Еще мысли для обсуждения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0da02d",
   "metadata": {},
   "source": [
    "- Не всегда последовательность лучше учитывать. Например корзина продуктов - тут в целом не важно, в какой последовательности вы покупали товары\n",
    "\n",
    "- В некоторых датасетах есть неопределенность с точным порядком (movielens как пример)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275b79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdffc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b928845f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ea6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4367e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./data_ckpt/ -d\n",
    "\n",
    "from slist import SLIST\n",
    "\n",
    "class SLISTRecommender:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.trained = False\n",
    "    \n",
    "    def fit(self, df, col='train_interactions', n_rows=30000):\n",
    "        \n",
    "        df['Time'] = pd.to_datetime(df['last_watch_dt']).astype(int) / 10**9\n",
    "        self.slist = SLIST(session_key='user_id', item_key='item_id',)\n",
    "\n",
    "        self.slist.fit(df[:n_rows])\n",
    "        \n",
    "        self.items = df.item_id.unique()\n",
    "        \n",
    "\n",
    "        self.trained = True\n",
    "        \n",
    "    def predict(self, df, topn=10) -> List[np.ndarray]:\n",
    "        \n",
    "        assert self.trained\n",
    "         \n",
    "        all_recs = []\n",
    "        \n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows()):\n",
    "            \n",
    "            user_recs = []\n",
    "            \n",
    "            user_interactions = [x[0] for x in row['train_interactions']]\n",
    "            user_interactions += [x[0] for x in row['valid_interactions']]\n",
    "            \n",
    "            user_interactions = [x for x in user_interactions if x in set(self.slist.itemidmap.index)]\n",
    "            \n",
    "            if len(user_interactions) == 0:\n",
    "                recs = [10440, 9728, 13865]\n",
    "                all_recs.append(recs[:topn])\n",
    "                continue\n",
    "           # print(user_interactions)\n",
    "            \n",
    "            recs = self.slist.predict_next(user_interactions, topn=10+len(user_interactions))\n",
    "            all_recs.append(recs[:topn])\n",
    "            \n",
    "        return all_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421be84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "slist_r = SLISTRecommender()\n",
    "slist_r.fit(train_df, n_rows=train_df.shape[0])\n",
    "joined['slist_recs'] = slist_r.predict(joined) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_recommender(joined, model_preds='slist_recs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46806e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
