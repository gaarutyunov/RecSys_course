{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63151877",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <center> RecSys. Home Assignment 1</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c581a7d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Один из важных навыков для построения рекомендательных систем - это умение корректно считать метрики качества ранжирования.\n",
    "\n",
    "В этой домашке мы предлагаем вам потренироваться в этом, и имплементировать метрики Precision@k, Recall@k, MNAP@k и NDCG@k по формулам, чтобы дальше переиспользовать при построении рекомендательных моделей. \n",
    "\n",
    "Критерии оценивания:\n",
    "* Что-то пытался сделать, дописал свой код, но ничего не получилось - 1 балл. \n",
    "* Не совсем корректная имплементация одной из 4 метрик, прохождение части тестов - 1 балл. \n",
    "* Корректная имплементация одной из 4 метрик, прохождение всех тестов - 2 балла. \n",
    "* +1 балл, если получится написать Precision@k, Recall@k без циклов.\n",
    "* +1 балл, если получится написать NDCG@k, MNAP@k без циклов.\n",
    "\n",
    "Дедлайн сдачи - **10 октября 23:59**. \n",
    "\n",
    "Формат сдачи - отправить Jupyter notebook на почту ananyeva.me@gmail.com с темой письма \"[RecSys HW1]\" и названием файла Name_Surname_HW1.ipynb.  \n",
    "\n",
    "Удачи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c928452-693b-4a9d-bc66-284765b6ec50",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Union\n",
    "import tests\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c1466c-0e00-42ee-9e6d-f822da820a91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PrepareTargetResult(NamedTuple):\n",
    "    values: torch.Tensor\n",
    "    indices: torch.Tensor\n",
    "\n",
    "\n",
    "def validate_metric_inputs(output: torch.Tensor, target: torch.Tensor) -> None:\n",
    "    if output.size() != target.size():\n",
    "        raise IndexError(\n",
    "            \"Unequal sizes for output and target: \"\n",
    "            f\"output - {output.size()}, target - {target.size()}.\"\n",
    "        )\n",
    "    if not (target.eq(0) | target.eq(1)).all():\n",
    "        raise ValueError(\n",
    "            \"Target contains values outside of 0 and 1.\" f\"\\nTarget:\\n{target}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def prepare_target(\n",
    "    output: torch.Tensor, target: torch.Tensor, return_indices: bool = False\n",
    ") -> Union[torch.Tensor, PrepareTargetResult]:\n",
    "    validate_metric_inputs(output, target)\n",
    "    # Define order by sorted output scores.\n",
    "    indices = output.argsort(dim=-1, descending=True)\n",
    "    sorted_target = torch.gather(target, index=indices, dim=-1)\n",
    "    return (\n",
    "        PrepareTargetResult(sorted_target, indices) if return_indices else sorted_target\n",
    "    )\n",
    "\n",
    "\n",
    "def nan_to_num(tensor: torch.Tensor, nan: float = 0.0) -> torch.Tensor:\n",
    "    return torch.where(\n",
    "        torch.isnan(tensor) | torch.isinf(tensor),\n",
    "        torch.full_like(tensor, fill_value=nan),\n",
    "        tensor,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b41fe1-8811-477d-8908-f1ab0d9547b6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Precision\n",
    "\n",
    "$$ P\\@k = \\frac{\\sum_{i=1}^k [rel_{i}]}{k} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679e4cb5-0fde-43e6-92ff-de003a18057a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def precision(output: torch.Tensor, target: torch.Tensor, topk: int) -> torch.Tensor:\n",
    "    # output, target ~ (users, items)\n",
    "    # target_sorted_by_output ~ (users, items)\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    # YOUR CODE HERE\n",
    "    topk = min(topk, target_sorted_by_output.shape[1])\n",
    "    return (target_sorted_by_output[:, :topk].sum(1) / topk).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a600b149-385b-40ad-b97d-b016426a4e17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tests.run_precision(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a057208-db6d-48cf-b5e1-7203efe94e1c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Recall\n",
    "\n",
    "$$P\\@k = \\frac{\\sum_{i=1}^k [rel_{i}]}{|rel_k|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67da32b-2e3a-4e1d-a3df-1f32d117b95b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def recall(output: torch.Tensor, target: torch.Tensor, topk: int) -> torch.Tensor:\n",
    "    # output, target ~ (users, items)\n",
    "    # target_sorted_by_output ~ (users, items)\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    # YOUR CODE HERE\n",
    "    topk = min(topk, target_sorted_by_output.shape[1])\n",
    "    nrel = target_sorted_by_output.sum(1)\n",
    "    res = torch.zeros((target_sorted_by_output.shape[0],))\n",
    "    res[nrel != 0] = target_sorted_by_output[:, :topk].sum(1) / nrel\n",
    "    return res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77cb6cc-2ca7-483a-abe9-75cbaf92539c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tests.run_recall(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6362e92-6ad3-441e-ab38-bd931348e920",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Mean (Normalized) Average Precision\n",
    "\n",
    "\n",
    "$$AP\\@k = \\frac{\\sum_{i=1}^{k} P\\@i \\cdot [rel\\@ i]} {\\sum_{i=1}^{k}[rel\\@i]}$$\n",
    "$$MNAP\\@k = \\frac{1}{N} \\sum_{k=1}^{N} \\frac{1}{min(k, m_u)} AP\\@k,$$\n",
    "\n",
    "где $m_u$ - количество items с интеракциями у пользователя $u$ в тестовый период, <br>\n",
    "$N$ - количество пользователей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1daf876a-4b0b-48af-a38d-57423e5ff46d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mnap(output: torch.Tensor, target: torch.Tensor, topk: int, normalized: bool = True) -> torch.Tensor:\n",
    "    # output, target ~ (users, items)\n",
    "    # target_sorted_by_output ~ (users, items)\n",
    "    target_sorted_by_output, indices = prepare_target(output, target, return_indices=True)\n",
    "    sorted_output = torch.gather(output, index=indices, dim=-1)\n",
    "    # YOUR CODE HERE\n",
    "    topk = min(topk, target_sorted_by_output.shape[1])\n",
    "    target_sorted_by_output = target_sorted_by_output[:, :topk]\n",
    "    p_i = torch.zeros_like(target_sorted_by_output)\n",
    "    for k in range(1, topk + 1):\n",
    "        p_i[:, k-1] = (target_sorted_by_output[:, :k].sum(1) / k) * target_sorted_by_output[:, k-1]\n",
    "\n",
    "    ap_k = p_i.sum(1) / (p_i != 0).sum(1)\n",
    "    ap_k[torch.isnan(ap_k)] = 0\n",
    "\n",
    "    if normalized:\n",
    "        m_u = (sorted_output != 0).sum(1)\n",
    "        k = torch.full_like(m_u, topk)\n",
    "        return (ap_k / torch.where(k < m_u, k, m_u)).mean()\n",
    "\n",
    "    return ap_k.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39353a96-0ce9-493d-a56c-29c85759bf7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Inputs:{\n  \"output\": [\n    [\n      0.5,\n      0.4000000059604645,\n      0.30000001192092896,\n      0.20000000298023224\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ]\n  ],\n  \"topk\": 3\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=0.2777777910232544, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=0.5, max_rel_diff_idx=0, rtol=1.3e-06)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5f/tg63xq8x6jl7df71n9v3_g9c0000gn/T/ipykernel_75659/2147114909.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_map\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmnap\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36mrun_map\u001B[0;34m(func)\u001B[0m\n\u001B[1;32m    276\u001B[0m         },\n\u001B[1;32m    277\u001B[0m     ]\n\u001B[0;32m--> 278\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_run_tests\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpartial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnormalized\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcases\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    279\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mrun_catalyst_map\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mCallable\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36m_run_tests\u001B[0;34m(func, cases)\u001B[0m\n\u001B[1;32m    682\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"topk\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    683\u001B[0m             \u001B[0mactual\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mcase\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopk\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 684\u001B[0;31m             torch.testing.assert_close(\n\u001B[0m\u001B[1;32m    685\u001B[0m                 \u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    686\u001B[0m                 \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/ftiad/venv/lib/python3.9/site-packages/torch/testing/_asserts.py\u001B[0m in \u001B[0;36massert_close\u001B[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_stride, check_is_coalesced, msg)\u001B[0m\n\u001B[1;32m    969\u001B[0m     )\n\u001B[1;32m    970\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 971\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m: Inputs:{\n  \"output\": [\n    [\n      0.5,\n      0.4000000059604645,\n      0.30000001192092896,\n      0.20000000298023224\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ]\n  ],\n  \"topk\": 3\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=0.2777777910232544, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=0.5, max_rel_diff_idx=0, rtol=1.3e-06)"
     ]
    }
   ],
   "source": [
    "tests.run_map(mnap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/germanarutunov/Projects/ftiad/venv/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Inputs:{\n  \"output\": [\n    [\n      0.5,\n      0.4000000059604645,\n      0.30000001192092896,\n      0.20000000298023224\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ]\n  ],\n  \"topk\": 3\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=0.2777777910232544, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=0.5, max_rel_diff_idx=0, rtol=1.3e-06)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5f/tg63xq8x6jl7df71n9v3_g9c0000gn/T/ipykernel_75659/95873426.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmean_average_precision\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopk\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtopk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mtests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_catalyst_map\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcatalyst_map\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36mrun_catalyst_map\u001B[0;34m(func)\u001B[0m\n\u001B[1;32m    371\u001B[0m         },\n\u001B[1;32m    372\u001B[0m     ]\n\u001B[0;32m--> 373\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_run_catalyst_tests\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpartial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcases\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    374\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    375\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36m_run_catalyst_tests\u001B[0;34m(func, cases)\u001B[0m\n\u001B[1;32m    694\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"topk\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    695\u001B[0m             \u001B[0mactual\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mactuals\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 696\u001B[0;31m             torch.testing.assert_close(\n\u001B[0m\u001B[1;32m    697\u001B[0m                 \u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    698\u001B[0m                 \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/ftiad/venv/lib/python3.9/site-packages/torch/testing/_asserts.py\u001B[0m in \u001B[0;36massert_close\u001B[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_stride, check_is_coalesced, msg)\u001B[0m\n\u001B[1;32m    969\u001B[0m     )\n\u001B[1;32m    970\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 971\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m: Inputs:{\n  \"output\": [\n    [\n      0.5,\n      0.4000000059604645,\n      0.30000001192092896,\n      0.20000000298023224\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ]\n  ],\n  \"topk\": 3\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=0.2777777910232544, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=0.5, max_rel_diff_idx=0, rtol=1.3e-06)"
     ]
    }
   ],
   "source": [
    "from catalyst.metrics import mean_average_precision\n",
    "\n",
    "def catalyst_map(output, target, topk):\n",
    "    return mean_average_precision(outputs=output, targets=target, topk=topk)\n",
    "\n",
    "tests.run_catalyst_map(catalyst_map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Inputs:{\n  \"output\": [\n    [\n      0.0,\n      0.0,\n      0.0,\n      0.0\n    ]\n  ],\n  \"target\": [\n    [\n      0.0,\n      0.0,\n      0.0,\n      0.0\n    ]\n  ],\n  \"topk\": 1\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=nan, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=nan, max_rel_diff_idx=0, rtol=1.3e-06)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5f/tg63xq8x6jl7df71n9v3_g9c0000gn/T/ipykernel_75659/1431163165.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_mnap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmnap\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36mrun_mnap\u001B[0;34m(func)\u001B[0m\n\u001B[1;32m    472\u001B[0m         },\n\u001B[1;32m    473\u001B[0m     ]\n\u001B[0;32m--> 474\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_run_tests\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpartial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnormalized\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcases\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    475\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    476\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36m_run_tests\u001B[0;34m(func, cases)\u001B[0m\n\u001B[1;32m    682\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"topk\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    683\u001B[0m             \u001B[0mactual\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mcase\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopk\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 684\u001B[0;31m             torch.testing.assert_close(\n\u001B[0m\u001B[1;32m    685\u001B[0m                 \u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    686\u001B[0m                 \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/ftiad/venv/lib/python3.9/site-packages/torch/testing/_asserts.py\u001B[0m in \u001B[0;36massert_close\u001B[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_stride, check_is_coalesced, msg)\u001B[0m\n\u001B[1;32m    969\u001B[0m     )\n\u001B[1;32m    970\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 971\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m: Inputs:{\n  \"output\": [\n    [\n      0.0,\n      0.0,\n      0.0,\n      0.0\n    ]\n  ],\n  \"target\": [\n    [\n      0.0,\n      0.0,\n      0.0,\n      0.0\n    ]\n  ],\n  \"topk\": 1\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=nan, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=nan, max_rel_diff_idx=0, rtol=1.3e-06)"
     ]
    }
   ],
   "source": [
    "tests.run_mnap(mnap)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "aed91757-0350-4c0b-bd1f-6943793074ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Normalized Dicsounted Cumulative Gain\n",
    "\n",
    "\n",
    "$$ NDCG \\@k = \\frac{DCG\\@k}{IDCG\\@k},$$ где\n",
    "$$DCG\\@k = \\sum_{i=1}^{k} \\frac{2^{rel_{i}} - 1}{log_2 (i + 1)}$$\n",
    "$$IDCG\\@k = \\sum_{i=1}^{|rel_{k}|} \\frac{2^{rel_{i}} - 1}{log_2 (i + 1)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72610077-102a-4860-b65e-8f59e0a618e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dcg(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    gains = (2**tensor) - 1\n",
    "    return gains / torch.log2(torch.arange(0, tensor.size(-1), dtype=torch.float, device=tensor.device) + 2.0)\n",
    "\n",
    "\n",
    "def ndcg(output: torch.Tensor, target: torch.Tensor, topk: int) -> torch.Tensor:\n",
    "    # output, target ~ (users, items)\n",
    "    # target_sorted_by_output ~ (users, items)\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    sorted_target = prepare_target(target, target)\n",
    "    a = dcg(target_sorted_by_output[:, :topk]).sum(1)\n",
    "    b = dcg(sorted_target[:, :topk]).sum(1)\n",
    "    rel = b != 0\n",
    "    a[~rel] = 0\n",
    "    a[rel] /= b[rel]\n",
    "\n",
    "    return a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44fa9a52-19e5-4a15-8bb0-7c034655a689",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Inputs:{\n  \"output\": [\n    [\n      9.0,\n      5.0,\n      3.0,\n      0.0,\n      7.0,\n      4.0,\n      0.0,\n      0.0,\n      6.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      8.0,\n      2.0,\n      0.0,\n      10.0\n    ],\n    [\n      0.0,\n      0.0,\n      1.0,\n      5.0,\n      9.0,\n      3.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      4.0,\n      0.0,\n      0.0,\n      10.0,\n      7.0,\n      0.0,\n      2.0,\n      8.0,\n      6.0\n    ],\n    [\n      0.0,\n      1.0,\n      4.0,\n      8.0,\n      6.0,\n      5.0,\n      3.0,\n      7.0,\n      10.0,\n      0.0,\n      9.0,\n      0.0,\n      0.0,\n      2.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0\n    ],\n    [\n      7.0,\n      8.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      4.0,\n      0.0,\n      10.0,\n      0.0,\n      0.0,\n      6.0,\n      0.0,\n      0.0,\n      0.0,\n      9.0,\n      2.0,\n      3.0,\n      5.0,\n      0.0\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ],\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0\n    ],\n    [\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0\n    ],\n    [\n      0.0,\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0\n    ]\n  ],\n  \"topk\": 100\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=0.0005332827568054199, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=0.0007621685659262179, max_rel_diff_idx=0, rtol=1.3e-06)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5f/tg63xq8x6jl7df71n9v3_g9c0000gn/T/ipykernel_75659/3612833989.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_ndcg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mndcg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36mrun_ndcg\u001B[0;34m(func)\u001B[0m\n\u001B[1;32m    573\u001B[0m         },\n\u001B[1;32m    574\u001B[0m     ]\n\u001B[0;32m--> 575\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_run_tests\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcases\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    576\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    577\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36m_run_tests\u001B[0;34m(func, cases)\u001B[0m\n\u001B[1;32m    682\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"topk\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    683\u001B[0m             \u001B[0mactual\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mcase\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopk\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 684\u001B[0;31m             torch.testing.assert_close(\n\u001B[0m\u001B[1;32m    685\u001B[0m                 \u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    686\u001B[0m                 \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/ftiad/venv/lib/python3.9/site-packages/torch/testing/_asserts.py\u001B[0m in \u001B[0;36massert_close\u001B[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_stride, check_is_coalesced, msg)\u001B[0m\n\u001B[1;32m    969\u001B[0m     )\n\u001B[1;32m    970\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 971\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m: Inputs:{\n  \"output\": [\n    [\n      9.0,\n      5.0,\n      3.0,\n      0.0,\n      7.0,\n      4.0,\n      0.0,\n      0.0,\n      6.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      8.0,\n      2.0,\n      0.0,\n      10.0\n    ],\n    [\n      0.0,\n      0.0,\n      1.0,\n      5.0,\n      9.0,\n      3.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      4.0,\n      0.0,\n      0.0,\n      10.0,\n      7.0,\n      0.0,\n      2.0,\n      8.0,\n      6.0\n    ],\n    [\n      0.0,\n      1.0,\n      4.0,\n      8.0,\n      6.0,\n      5.0,\n      3.0,\n      7.0,\n      10.0,\n      0.0,\n      9.0,\n      0.0,\n      0.0,\n      2.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0\n    ],\n    [\n      7.0,\n      8.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      4.0,\n      0.0,\n      10.0,\n      0.0,\n      0.0,\n      6.0,\n      0.0,\n      0.0,\n      0.0,\n      9.0,\n      2.0,\n      3.0,\n      5.0,\n      0.0\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ],\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0\n    ],\n    [\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0\n    ],\n    [\n      0.0,\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0\n    ]\n  ],\n  \"topk\": 100\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=0.0005332827568054199, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=0.0007621685659262179, max_rel_diff_idx=0, rtol=1.3e-06)"
     ]
    }
   ],
   "source": [
    "tests.run_ndcg(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11c69c08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Inputs:{\n  \"output\": [\n    [\n      9.0,\n      5.0,\n      3.0,\n      0.0,\n      7.0,\n      4.0,\n      0.0,\n      0.0,\n      6.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      8.0,\n      2.0,\n      0.0,\n      10.0\n    ],\n    [\n      0.0,\n      0.0,\n      1.0,\n      5.0,\n      9.0,\n      3.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      4.0,\n      0.0,\n      0.0,\n      10.0,\n      7.0,\n      0.0,\n      2.0,\n      8.0,\n      6.0\n    ],\n    [\n      0.0,\n      1.0,\n      4.0,\n      8.0,\n      6.0,\n      5.0,\n      3.0,\n      7.0,\n      10.0,\n      0.0,\n      9.0,\n      0.0,\n      0.0,\n      2.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0\n    ],\n    [\n      7.0,\n      8.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      4.0,\n      0.0,\n      10.0,\n      0.0,\n      0.0,\n      6.0,\n      0.0,\n      0.0,\n      0.0,\n      9.0,\n      2.0,\n      3.0,\n      5.0,\n      0.0\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ],\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0\n    ],\n    [\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0\n    ],\n    [\n      0.0,\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0\n    ]\n  ],\n  \"topk\": 100\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=0.0005332827568054199, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=0.0007621685659262179, max_rel_diff_idx=0, rtol=1.3e-06)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5f/tg63xq8x6jl7df71n9v3_g9c0000gn/T/ipykernel_75659/902836793.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mcndcg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mtests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_catalyst_ndcg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcatalyst_ndcg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36mrun_catalyst_ndcg\u001B[0;34m(func)\u001B[0m\n\u001B[1;32m    674\u001B[0m         },\n\u001B[1;32m    675\u001B[0m     ]\n\u001B[0;32m--> 676\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_run_catalyst_tests\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcases\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    677\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    678\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/RecSys_course/hw/hw1/tests.py\u001B[0m in \u001B[0;36m_run_catalyst_tests\u001B[0;34m(func, cases)\u001B[0m\n\u001B[1;32m    694\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"topk\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    695\u001B[0m             \u001B[0mactual\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mactuals\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 696\u001B[0;31m             torch.testing.assert_close(\n\u001B[0m\u001B[1;32m    697\u001B[0m                 \u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    698\u001B[0m                 \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactual\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mexpected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/ftiad/venv/lib/python3.9/site-packages/torch/testing/_asserts.py\u001B[0m in \u001B[0;36massert_close\u001B[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_stride, check_is_coalesced, msg)\u001B[0m\n\u001B[1;32m    969\u001B[0m     )\n\u001B[1;32m    970\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 971\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0merror_meta\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m: Inputs:{\n  \"output\": [\n    [\n      9.0,\n      5.0,\n      3.0,\n      0.0,\n      7.0,\n      4.0,\n      0.0,\n      0.0,\n      6.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      8.0,\n      2.0,\n      0.0,\n      10.0\n    ],\n    [\n      0.0,\n      0.0,\n      1.0,\n      5.0,\n      9.0,\n      3.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      4.0,\n      0.0,\n      0.0,\n      10.0,\n      7.0,\n      0.0,\n      2.0,\n      8.0,\n      6.0\n    ],\n    [\n      0.0,\n      1.0,\n      4.0,\n      8.0,\n      6.0,\n      5.0,\n      3.0,\n      7.0,\n      10.0,\n      0.0,\n      9.0,\n      0.0,\n      0.0,\n      2.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0\n    ],\n    [\n      7.0,\n      8.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      4.0,\n      0.0,\n      10.0,\n      0.0,\n      0.0,\n      6.0,\n      0.0,\n      0.0,\n      0.0,\n      9.0,\n      2.0,\n      3.0,\n      5.0,\n      0.0\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ],\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      0.0\n    ],\n    [\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      1.0,\n      0.0\n    ],\n    [\n      0.0,\n      1.0,\n      1.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0,\n      1.0,\n      0.0,\n      0.0\n    ]\n  ],\n  \"topk\": 100\n}\nnamespace(number_of_elements=1, total_mismatches=1, max_abs_diff=0.0005332827568054199, max_abs_diff_idx=0, atol=1e-05, max_rel_diff=0.0007621685659262179, max_rel_diff_idx=0, rtol=1.3e-06)"
     ]
    }
   ],
   "source": [
    "from catalyst.metrics import ndcg as cndcg\n",
    "\n",
    "def catalyst_ndcg(output, target, topk):\n",
    "    return cndcg(output, target, topk)\n",
    "\n",
    "tests.run_catalyst_ndcg(catalyst_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "afdf057ef1ef2906fc2cc2ffd617646692fe5d919d63b76727650bd7046d9edf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}